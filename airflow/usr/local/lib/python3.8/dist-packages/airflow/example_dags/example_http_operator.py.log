[2020-05-31 21:01:55,551] {scheduler_job.py:153} INFO - Started process (PID=6120) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:01:55,556] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:01:55,556] {logging_mixin.py:112} INFO - [2020-05-31 21:01:55,556] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:01:55,612] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:01:55,747] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:02:43,625] {scheduler_job.py:153} INFO - Started process (PID=6148) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:02:43,630] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:02:43,630] {logging_mixin.py:112} INFO - [2020-05-31 21:02:43,630] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:02:43,649] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:02:43,789] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.164 seconds
[2020-05-31 21:03:31,651] {scheduler_job.py:153} INFO - Started process (PID=6180) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:03:31,656] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:03:31,657] {logging_mixin.py:112} INFO - [2020-05-31 21:03:31,656] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:03:31,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:03:31,800] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.150 seconds
[2020-05-31 21:04:19,658] {scheduler_job.py:153} INFO - Started process (PID=6208) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:04:19,663] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:04:19,664] {logging_mixin.py:112} INFO - [2020-05-31 21:04:19,664] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:04:19,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:04:19,810] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.152 seconds
[2020-05-31 21:05:07,644] {scheduler_job.py:153} INFO - Started process (PID=6240) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:07,649] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:05:07,650] {logging_mixin.py:112} INFO - [2020-05-31 21:05:07,650] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:07,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:07,790] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:05:55,671] {scheduler_job.py:153} INFO - Started process (PID=6268) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:55,676] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:05:55,677] {logging_mixin.py:112} INFO - [2020-05-31 21:05:55,677] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:55,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:05:55,821] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.150 seconds
[2020-05-31 21:06:43,693] {scheduler_job.py:153} INFO - Started process (PID=6300) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:06:43,698] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:06:43,699] {logging_mixin.py:112} INFO - [2020-05-31 21:06:43,698] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:06:43,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:06:43,856] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:07:31,716] {scheduler_job.py:153} INFO - Started process (PID=6332) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:07:31,721] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:07:31,722] {logging_mixin.py:112} INFO - [2020-05-31 21:07:31,722] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:07:31,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:07:31,878] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:08:19,743] {scheduler_job.py:153} INFO - Started process (PID=6360) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:08:19,748] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:08:19,749] {logging_mixin.py:112} INFO - [2020-05-31 21:08:19,749] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:08:19,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:08:19,922] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:07,767] {scheduler_job.py:153} INFO - Started process (PID=6392) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:07,772] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:09:07,772] {logging_mixin.py:112} INFO - [2020-05-31 21:09:07,772] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:07,794] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:07,955] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:55,792] {scheduler_job.py:153} INFO - Started process (PID=6420) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:55,797] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:09:55,798] {logging_mixin.py:112} INFO - [2020-05-31 21:09:55,798] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:55,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:09:55,989] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:10:43,814] {scheduler_job.py:153} INFO - Started process (PID=6452) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:10:43,819] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:10:43,820] {logging_mixin.py:112} INFO - [2020-05-31 21:10:43,820] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:10:43,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:10:43,998] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:11:31,837] {scheduler_job.py:153} INFO - Started process (PID=6480) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:11:31,848] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:11:31,849] {logging_mixin.py:112} INFO - [2020-05-31 21:11:31,848] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:11:31,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:11:31,987] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:12:19,864] {scheduler_job.py:153} INFO - Started process (PID=6512) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:12:19,869] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:12:19,870] {logging_mixin.py:112} INFO - [2020-05-31 21:12:19,870] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:12:19,888] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:12:20,031] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:13:07,886] {scheduler_job.py:153} INFO - Started process (PID=6540) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:07,891] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:13:07,892] {logging_mixin.py:112} INFO - [2020-05-31 21:13:07,892] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:07,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:08,053] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:13:55,909] {scheduler_job.py:153} INFO - Started process (PID=6572) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:55,915] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:13:55,915] {logging_mixin.py:112} INFO - [2020-05-31 21:13:55,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:55,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:13:56,074] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.164 seconds
[2020-05-31 21:14:43,933] {scheduler_job.py:153} INFO - Started process (PID=6600) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:14:43,939] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:14:43,939] {logging_mixin.py:112} INFO - [2020-05-31 21:14:43,939] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:14:43,960] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:14:44,074] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.141 seconds
[2020-05-31 21:15:31,984] {scheduler_job.py:153} INFO - Started process (PID=6632) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:15:31,989] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:15:31,990] {logging_mixin.py:112} INFO - [2020-05-31 21:15:31,990] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:15:32,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:15:32,152] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:16:20,013] {scheduler_job.py:153} INFO - Started process (PID=6660) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:16:20,018] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:16:20,019] {logging_mixin.py:112} INFO - [2020-05-31 21:16:20,019] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:16:20,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:16:20,161] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.149 seconds
[2020-05-31 21:17:08,039] {scheduler_job.py:153} INFO - Started process (PID=6692) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:08,046] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:17:08,046] {logging_mixin.py:112} INFO - [2020-05-31 21:17:08,046] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:08,065] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:08,218] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:17:56,062] {scheduler_job.py:153} INFO - Started process (PID=6720) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:56,068] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:17:56,068] {logging_mixin.py:112} INFO - [2020-05-31 21:17:56,068] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:56,087] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:17:56,216] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:18:44,090] {scheduler_job.py:153} INFO - Started process (PID=6752) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:18:44,095] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:18:44,096] {logging_mixin.py:112} INFO - [2020-05-31 21:18:44,096] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:18:44,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:18:44,273] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:19:32,133] {scheduler_job.py:153} INFO - Started process (PID=6784) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:19:32,141] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:19:32,142] {logging_mixin.py:112} INFO - [2020-05-31 21:19:32,142] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:19:32,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:19:32,629] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:20:20,151] {scheduler_job.py:153} INFO - Started process (PID=6812) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:20:20,156] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:20:20,157] {logging_mixin.py:112} INFO - [2020-05-31 21:20:20,157] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:20:20,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:20:20,350] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:21:08,205] {scheduler_job.py:153} INFO - Started process (PID=6844) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:08,213] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:21:08,214] {logging_mixin.py:112} INFO - [2020-05-31 21:21:08,213] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:08,247] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:08,471] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.266 seconds
[2020-05-31 21:21:56,215] {scheduler_job.py:153} INFO - Started process (PID=6872) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:56,220] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:21:56,221] {logging_mixin.py:112} INFO - [2020-05-31 21:21:56,221] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:56,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:21:56,370] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.155 seconds
[2020-05-31 21:22:44,238] {scheduler_job.py:153} INFO - Started process (PID=6904) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:22:44,245] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:22:44,246] {logging_mixin.py:112} INFO - [2020-05-31 21:22:44,246] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:22:44,265] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:22:44,394] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:23:32,265] {scheduler_job.py:153} INFO - Started process (PID=6932) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:23:32,270] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:23:32,271] {logging_mixin.py:112} INFO - [2020-05-31 21:23:32,271] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:23:32,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:23:32,415] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:24:20,289] {scheduler_job.py:153} INFO - Started process (PID=6964) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:24:20,295] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:24:20,295] {logging_mixin.py:112} INFO - [2020-05-31 21:24:20,295] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:24:20,314] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:24:20,471] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:08,318] {scheduler_job.py:153} INFO - Started process (PID=6992) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:08,323] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:25:08,324] {logging_mixin.py:112} INFO - [2020-05-31 21:25:08,324] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:08,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:08,459] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:56,343] {scheduler_job.py:153} INFO - Started process (PID=7024) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:56,349] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:25:56,350] {logging_mixin.py:112} INFO - [2020-05-31 21:25:56,349] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:56,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:25:56,526] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:26:44,369] {scheduler_job.py:153} INFO - Started process (PID=7052) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:26:44,374] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:26:44,375] {logging_mixin.py:112} INFO - [2020-05-31 21:26:44,375] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:26:44,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:26:44,559] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:27:32,394] {scheduler_job.py:153} INFO - Started process (PID=7084) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:27:32,400] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:27:32,400] {logging_mixin.py:112} INFO - [2020-05-31 21:27:32,400] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:27:32,419] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:27:32,580] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:28:20,420] {scheduler_job.py:153} INFO - Started process (PID=7112) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:28:20,427] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:28:20,428] {logging_mixin.py:112} INFO - [2020-05-31 21:28:20,427] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:28:20,447] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:28:20,547] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:08,443] {scheduler_job.py:153} INFO - Started process (PID=7144) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:08,448] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:29:08,449] {logging_mixin.py:112} INFO - [2020-05-31 21:29:08,449] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:08,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:08,602] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:56,467] {scheduler_job.py:153} INFO - Started process (PID=7172) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:56,473] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:29:56,473] {logging_mixin.py:112} INFO - [2020-05-31 21:29:56,473] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:56,491] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:29:56,669] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:30:44,494] {scheduler_job.py:153} INFO - Started process (PID=7204) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:30:44,500] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:30:44,500] {logging_mixin.py:112} INFO - [2020-05-31 21:30:44,500] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:30:44,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:30:44,690] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:31:32,523] {scheduler_job.py:153} INFO - Started process (PID=7232) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:31:32,528] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:31:32,528] {logging_mixin.py:112} INFO - [2020-05-31 21:31:32,528] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:31:32,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:31:32,724] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:32:20,549] {scheduler_job.py:153} INFO - Started process (PID=7264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:32:20,554] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:32:20,555] {logging_mixin.py:112} INFO - [2020-05-31 21:32:20,555] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:32:20,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:32:20,734] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:33:08,575] {scheduler_job.py:153} INFO - Started process (PID=7292) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:08,580] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:33:08,581] {logging_mixin.py:112} INFO - [2020-05-31 21:33:08,581] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:08,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:08,800] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:33:56,594] {scheduler_job.py:153} INFO - Started process (PID=7324) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:56,600] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:33:56,601] {logging_mixin.py:112} INFO - [2020-05-31 21:33:56,601] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:56,618] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:33:56,878] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:34:44,622] {scheduler_job.py:153} INFO - Started process (PID=7356) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:34:44,632] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:34:44,633] {logging_mixin.py:112} INFO - [2020-05-31 21:34:44,632] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:34:44,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:34:44,801] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.179 seconds
[2020-05-31 21:35:32,640] {scheduler_job.py:153} INFO - Started process (PID=7384) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:35:32,646] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:35:32,646] {logging_mixin.py:112} INFO - [2020-05-31 21:35:32,646] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:35:32,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:35:32,811] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:36:20,663] {scheduler_job.py:153} INFO - Started process (PID=7416) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:36:20,668] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:36:20,669] {logging_mixin.py:112} INFO - [2020-05-31 21:36:20,669] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:36:20,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:36:20,833] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:37:08,683] {scheduler_job.py:153} INFO - Started process (PID=7444) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:08,688] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:37:08,688] {logging_mixin.py:112} INFO - [2020-05-31 21:37:08,688] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:08,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:08,854] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:37:56,705] {scheduler_job.py:153} INFO - Started process (PID=7476) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:56,710] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:37:56,711] {logging_mixin.py:112} INFO - [2020-05-31 21:37:56,711] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:56,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:37:56,876] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:38:44,728] {scheduler_job.py:153} INFO - Started process (PID=7504) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:38:44,733] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:38:44,734] {logging_mixin.py:112} INFO - [2020-05-31 21:38:44,734] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:38:44,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:38:44,920] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:39:32,753] {scheduler_job.py:153} INFO - Started process (PID=7536) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:39:32,758] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:39:32,759] {logging_mixin.py:112} INFO - [2020-05-31 21:39:32,759] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:39:32,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:39:32,953] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:40:20,775] {scheduler_job.py:153} INFO - Started process (PID=7564) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:40:20,781] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:40:20,782] {logging_mixin.py:112} INFO - [2020-05-31 21:40:20,782] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:40:20,799] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:40:20,986] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:08,796] {scheduler_job.py:153} INFO - Started process (PID=7596) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:08,801] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:41:08,802] {logging_mixin.py:112} INFO - [2020-05-31 21:41:08,802] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:08,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:08,974] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:56,821] {scheduler_job.py:153} INFO - Started process (PID=7624) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:56,826] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:41:56,827] {logging_mixin.py:112} INFO - [2020-05-31 21:41:56,827] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:56,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:41:56,974] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:42:44,840] {scheduler_job.py:153} INFO - Started process (PID=7656) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:42:44,845] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:42:44,846] {logging_mixin.py:112} INFO - [2020-05-31 21:42:44,846] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:42:44,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:42:45,006] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.166 seconds
[2020-05-31 21:43:32,865] {scheduler_job.py:153} INFO - Started process (PID=7684) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:43:32,871] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:43:32,871] {logging_mixin.py:112} INFO - [2020-05-31 21:43:32,871] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:43:32,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:43:33,018] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:44:20,889] {scheduler_job.py:153} INFO - Started process (PID=7716) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:44:20,894] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:44:20,895] {logging_mixin.py:112} INFO - [2020-05-31 21:44:20,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:44:20,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:44:21,028] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.139 seconds
[2020-05-31 21:45:08,910] {scheduler_job.py:153} INFO - Started process (PID=7744) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:08,915] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:45:08,916] {logging_mixin.py:112} INFO - [2020-05-31 21:45:08,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:08,935] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:09,040] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:45:56,934] {scheduler_job.py:153} INFO - Started process (PID=7776) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:56,940] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:45:56,941] {logging_mixin.py:112} INFO - [2020-05-31 21:45:56,941] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:56,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:45:57,083] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.149 seconds
[2020-05-31 21:46:44,958] {scheduler_job.py:153} INFO - Started process (PID=7804) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:46:44,963] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:46:44,964] {logging_mixin.py:112} INFO - [2020-05-31 21:46:44,963] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:46:44,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:46:45,239] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:47:32,979] {scheduler_job.py:153} INFO - Started process (PID=7836) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:47:32,984] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:47:32,985] {logging_mixin.py:112} INFO - [2020-05-31 21:47:32,985] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:47:33,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:47:33,150] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:48:21,024] {scheduler_job.py:153} INFO - Started process (PID=7868) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:48:21,029] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:48:21,029] {logging_mixin.py:112} INFO - [2020-05-31 21:48:21,029] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:48:21,048] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:48:21,228] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:09,058] {scheduler_job.py:153} INFO - Started process (PID=7896) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:09,063] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:49:09,063] {logging_mixin.py:112} INFO - [2020-05-31 21:49:09,063] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:09,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:09,249] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:57,116] {scheduler_job.py:153} INFO - Started process (PID=7928) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:57,121] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:49:57,122] {logging_mixin.py:112} INFO - [2020-05-31 21:49:57,122] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:57,140] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:49:57,327] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:50:45,158] {scheduler_job.py:153} INFO - Started process (PID=7956) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:50:45,163] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:50:45,164] {logging_mixin.py:112} INFO - [2020-05-31 21:50:45,164] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:50:45,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:50:45,327] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:51:33,202] {scheduler_job.py:153} INFO - Started process (PID=7988) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:51:33,208] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:51:33,209] {logging_mixin.py:112} INFO - [2020-05-31 21:51:33,208] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:51:33,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:51:33,415] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:52:21,244] {scheduler_job.py:153} INFO - Started process (PID=8016) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:52:21,250] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:52:21,250] {logging_mixin.py:112} INFO - [2020-05-31 21:52:21,250] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:52:21,268] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:52:21,416] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:09,290] {scheduler_job.py:153} INFO - Started process (PID=8048) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:09,295] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:53:09,296] {logging_mixin.py:112} INFO - [2020-05-31 21:53:09,295] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:09,315] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:09,493] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:57,333] {scheduler_job.py:153} INFO - Started process (PID=8076) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:57,338] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:53:57,338] {logging_mixin.py:112} INFO - [2020-05-31 21:53:57,338] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:57,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:53:57,503] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:54:45,379] {scheduler_job.py:153} INFO - Started process (PID=8108) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:54:45,384] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:54:45,384] {logging_mixin.py:112} INFO - [2020-05-31 21:54:45,384] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:54:45,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:54:45,549] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:55:33,431] {scheduler_job.py:153} INFO - Started process (PID=8136) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:55:33,436] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:55:33,436] {logging_mixin.py:112} INFO - [2020-05-31 21:55:33,436] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:55:33,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:55:33,646] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.215 seconds
[2020-05-31 21:56:21,464] {scheduler_job.py:153} INFO - Started process (PID=8168) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:56:21,471] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:56:21,472] {logging_mixin.py:112} INFO - [2020-05-31 21:56:21,472] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:56:21,490] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:56:21,659] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:57:09,510] {scheduler_job.py:153} INFO - Started process (PID=8196) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:09,517] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:57:09,517] {logging_mixin.py:112} INFO - [2020-05-31 21:57:09,517] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:09,535] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:09,670] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:57:57,556] {scheduler_job.py:153} INFO - Started process (PID=8228) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:57,562] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:57:57,563] {logging_mixin.py:112} INFO - [2020-05-31 21:57:57,562] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:57,581] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:57:57,714] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:58:45,602] {scheduler_job.py:153} INFO - Started process (PID=8256) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:58:45,608] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:58:45,609] {logging_mixin.py:112} INFO - [2020-05-31 21:58:45,608] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:58:45,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:58:45,759] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:59:33,657] {scheduler_job.py:153} INFO - Started process (PID=8288) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:59:33,662] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 21:59:33,662] {logging_mixin.py:112} INFO - [2020-05-31 21:59:33,662] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:59:33,680] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 21:59:33,880] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.223 seconds
[2020-05-31 22:00:21,688] {scheduler_job.py:153} INFO - Started process (PID=8316) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:00:21,693] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 22:00:21,694] {logging_mixin.py:112} INFO - [2020-05-31 22:00:21,694] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:00:21,713] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:00:21,891] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:01:09,734] {scheduler_job.py:153} INFO - Started process (PID=8348) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:09,739] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 22:01:09,740] {logging_mixin.py:112} INFO - [2020-05-31 22:01:09,740] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:09,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:09,901] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.168 seconds
[2020-05-31 22:01:57,789] {scheduler_job.py:153} INFO - Started process (PID=8376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:57,796] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 22:01:57,796] {logging_mixin.py:112} INFO - [2020-05-31 22:01:57,796] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:57,814] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:01:57,991] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:02:45,836] {scheduler_job.py:153} INFO - Started process (PID=8408) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:02:45,843] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 22:02:45,843] {logging_mixin.py:112} INFO - [2020-05-31 22:02:45,843] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:02:45,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:02:45,991] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:03:34,020] {scheduler_job.py:153} INFO - Started process (PID=8436) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:03:34,025] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-05-31 22:03:34,026] {logging_mixin.py:112} INFO - [2020-05-31 22:03:34,026] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:03:34,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-05-31 22:33:40,418] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 1806.398 seconds
[2020-06-01 14:33:26,673] {scheduler_job.py:153} INFO - Started process (PID=97) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:33:26,695] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:33:26,696] {logging_mixin.py:112} INFO - [2020-06-01 14:33:26,696] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:33:26,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:33:27,020] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.347 seconds
[2020-06-01 14:34:14,828] {scheduler_job.py:153} INFO - Started process (PID=125) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:34:14,837] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:34:14,838] {logging_mixin.py:112} INFO - [2020-06-01 14:34:14,838] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:34:14,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:34:15,468] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.640 seconds
[2020-06-01 14:35:02,987] {scheduler_job.py:153} INFO - Started process (PID=153) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:03,241] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:35:03,241] {logging_mixin.py:112} INFO - [2020-06-01 14:35:03,241] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:03,263] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:04,090] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 1.103 seconds
[2020-06-01 14:35:51,098] {scheduler_job.py:153} INFO - Started process (PID=181) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:51,105] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:35:51,108] {logging_mixin.py:112} INFO - [2020-06-01 14:35:51,108] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:51,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:35:51,701] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.603 seconds
[2020-06-01 14:36:41,353] {scheduler_job.py:153} INFO - Started process (PID=209) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:36:41,364] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:36:41,365] {logging_mixin.py:112} INFO - [2020-06-01 14:36:41,365] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:36:41,442] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:36:41,906] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.554 seconds
[2020-06-01 14:37:29,218] {scheduler_job.py:153} INFO - Started process (PID=241) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:37:29,224] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:37:29,224] {logging_mixin.py:112} INFO - [2020-06-01 14:37:29,224] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:37:29,252] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:37:29,504] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.287 seconds
[2020-06-01 14:38:17,285] {scheduler_job.py:153} INFO - Started process (PID=269) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:38:17,292] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:38:17,292] {logging_mixin.py:112} INFO - [2020-06-01 14:38:17,292] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:38:17,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:38:17,878] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.593 seconds
[2020-06-01 14:39:05,382] {scheduler_job.py:153} INFO - Started process (PID=301) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:05,388] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:39:05,389] {logging_mixin.py:112} INFO - [2020-06-01 14:39:05,389] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:05,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:05,669] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.287 seconds
[2020-06-01 14:39:53,437] {scheduler_job.py:153} INFO - Started process (PID=329) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:53,443] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 14:39:53,443] {logging_mixin.py:112} INFO - [2020-06-01 14:39:53,443] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:53,468] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 14:39:53,608] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.171 seconds
[2020-06-01 15:15:47,681] {scheduler_job.py:153} INFO - Started process (PID=1128) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:15:47,766] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:15:47,766] {logging_mixin.py:112} INFO - [2020-06-01 15:15:47,766] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:15:47,785] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:15:47,898] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.218 seconds
[2020-06-01 15:16:37,716] {scheduler_job.py:153} INFO - Started process (PID=1157) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:16:37,721] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:16:37,722] {logging_mixin.py:112} INFO - [2020-06-01 15:16:37,722] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:16:37,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:16:37,909] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:17:27,784] {scheduler_job.py:153} INFO - Started process (PID=1190) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:17:27,789] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:17:27,790] {logging_mixin.py:112} INFO - [2020-06-01 15:17:27,789] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:17:27,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:17:27,932] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.148 seconds
[2020-06-01 15:18:17,834] {scheduler_job.py:153} INFO - Started process (PID=1219) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:18:17,842] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:18:17,842] {logging_mixin.py:112} INFO - [2020-06-01 15:18:17,842] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:18:17,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:18:18,007] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.173 seconds
[2020-06-01 15:19:07,867] {scheduler_job.py:153} INFO - Started process (PID=1252) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:07,872] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:19:07,872] {logging_mixin.py:112} INFO - [2020-06-01 15:19:07,872] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:07,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:08,029] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.163 seconds
[2020-06-01 15:19:57,894] {scheduler_job.py:153} INFO - Started process (PID=1285) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:57,899] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:19:57,900] {logging_mixin.py:112} INFO - [2020-06-01 15:19:57,900] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:57,924] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:19:58,041] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.147 seconds
[2020-06-01 15:20:47,915] {scheduler_job.py:153} INFO - Started process (PID=1314) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:20:47,920] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:20:47,921] {logging_mixin.py:112} INFO - [2020-06-01 15:20:47,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:20:47,944] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:20:48,100] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.184 seconds
[2020-06-01 15:21:37,957] {scheduler_job.py:153} INFO - Started process (PID=1347) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:21:37,962] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:21:37,963] {logging_mixin.py:112} INFO - [2020-06-01 15:21:37,963] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:21:37,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:21:38,174] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:26:42,026] {scheduler_job.py:153} INFO - Started process (PID=1404) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:26:42,032] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:26:42,032] {logging_mixin.py:112} INFO - [2020-06-01 15:26:42,032] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:26:42,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:26:42,751] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.725 seconds
[2020-06-01 15:27:03,090] {scheduler_job.py:153} INFO - Started process (PID=1429) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:27:03,096] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 15:27:03,096] {logging_mixin.py:112} INFO - [2020-06-01 15:27:03,096] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:27:03,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 15:27:03,391] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.301 seconds
[2020-06-01 17:42:52,258] {scheduler_job.py:153} INFO - Started process (PID=102) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:42:52,283] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:42:52,283] {logging_mixin.py:112} INFO - [2020-06-01 17:42:52,283] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:42:52,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:42:52,469] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.211 seconds
[2020-06-01 17:43:42,337] {scheduler_job.py:153} INFO - Started process (PID=135) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:43:42,342] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:43:42,343] {logging_mixin.py:112} INFO - [2020-06-01 17:43:42,343] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:43:42,364] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:43:42,483] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.147 seconds
[2020-06-01 17:44:32,370] {scheduler_job.py:153} INFO - Started process (PID=164) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:44:32,375] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:44:32,376] {logging_mixin.py:112} INFO - [2020-06-01 17:44:32,376] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:44:32,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:44:32,526] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.156 seconds
[2020-06-01 17:45:22,417] {scheduler_job.py:153} INFO - Started process (PID=197) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:45:22,422] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:45:22,422] {logging_mixin.py:112} INFO - [2020-06-01 17:45:22,422] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:45:22,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:45:22,548] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.132 seconds
[2020-06-01 17:46:12,440] {scheduler_job.py:153} INFO - Started process (PID=230) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:46:12,445] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:46:12,446] {logging_mixin.py:112} INFO - [2020-06-01 17:46:12,446] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:46:12,470] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:46:12,617] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.177 seconds
[2020-06-01 17:47:02,477] {scheduler_job.py:153} INFO - Started process (PID=259) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:02,484] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:47:02,486] {logging_mixin.py:112} INFO - [2020-06-01 17:47:02,485] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:02,510] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:02,641] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.163 seconds
[2020-06-01 17:47:52,530] {scheduler_job.py:153} INFO - Started process (PID=292) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:52,535] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:47:52,536] {logging_mixin.py:112} INFO - [2020-06-01 17:47:52,536] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:52,560] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:47:52,724] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.193 seconds
[2020-06-01 17:48:42,584] {scheduler_job.py:153} INFO - Started process (PID=321) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:48:42,589] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:48:42,590] {logging_mixin.py:112} INFO - [2020-06-01 17:48:42,590] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:48:42,615] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:48:42,794] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:49:32,665] {scheduler_job.py:153} INFO - Started process (PID=354) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:49:32,676] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:49:32,676] {logging_mixin.py:112} INFO - [2020-06-01 17:49:32,676] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:49:32,708] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:49:32,858] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.192 seconds
[2020-06-01 17:50:22,740] {scheduler_job.py:153} INFO - Started process (PID=383) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:50:22,745] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:50:22,746] {logging_mixin.py:112} INFO - [2020-06-01 17:50:22,746] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:50:22,770] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:50:22,924] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.184 seconds
[2020-06-01 17:51:12,867] {scheduler_job.py:153} INFO - Started process (PID=416) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:51:12,877] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:51:12,877] {logging_mixin.py:112} INFO - [2020-06-01 17:51:12,877] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:51:12,915] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:51:13,066] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.199 seconds
[2020-06-01 17:52:02,908] {scheduler_job.py:153} INFO - Started process (PID=449) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:02,923] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:52:02,923] {logging_mixin.py:112} INFO - [2020-06-01 17:52:02,923] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:02,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:03,123] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.215 seconds
[2020-06-01 17:52:52,971] {scheduler_job.py:153} INFO - Started process (PID=478) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:52,978] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:52:52,978] {logging_mixin.py:112} INFO - [2020-06-01 17:52:52,978] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:52,998] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:52:53,158] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.186 seconds
[2020-06-01 17:53:43,085] {scheduler_job.py:153} INFO - Started process (PID=511) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:53:43,090] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:53:43,091] {logging_mixin.py:112} INFO - [2020-06-01 17:53:43,091] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:53:43,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:53:43,279] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:54:33,177] {scheduler_job.py:153} INFO - Started process (PID=540) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:54:33,183] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:54:33,184] {logging_mixin.py:112} INFO - [2020-06-01 17:54:33,183] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:54:33,212] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:54:33,344] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.167 seconds
[2020-06-01 17:55:23,275] {scheduler_job.py:153} INFO - Started process (PID=573) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:55:23,280] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:55:23,280] {logging_mixin.py:112} INFO - [2020-06-01 17:55:23,280] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:55:23,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:55:23,443] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.169 seconds
[2020-06-01 17:56:13,366] {scheduler_job.py:153} INFO - Started process (PID=602) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:56:13,372] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:56:13,373] {logging_mixin.py:112} INFO - [2020-06-01 17:56:13,373] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:56:13,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:56:13,556] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:57:03,452] {scheduler_job.py:153} INFO - Started process (PID=635) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:03,459] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:57:03,462] {logging_mixin.py:112} INFO - [2020-06-01 17:57:03,460] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:03,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:03,644] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.192 seconds
[2020-06-01 17:57:53,524] {scheduler_job.py:153} INFO - Started process (PID=664) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:53,529] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:57:53,530] {logging_mixin.py:112} INFO - [2020-06-01 17:57:53,529] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:53,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:57:53,721] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.197 seconds
[2020-06-01 17:58:43,623] {scheduler_job.py:153} INFO - Started process (PID=697) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:58:43,629] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:58:43,629] {logging_mixin.py:112} INFO - [2020-06-01 17:58:43,629] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:58:43,649] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:58:43,856] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:59:33,724] {scheduler_job.py:153} INFO - Started process (PID=730) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:59:33,729] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 17:59:33,730] {logging_mixin.py:112} INFO - [2020-06-01 17:59:33,730] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:59:33,754] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 17:59:34,112] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.388 seconds
[2020-06-01 18:00:23,875] {scheduler_job.py:153} INFO - Started process (PID=759) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:00:23,880] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:00:23,881] {logging_mixin.py:112} INFO - [2020-06-01 18:00:23,881] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:00:23,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:00:24,076] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.201 seconds
[2020-06-01 18:01:13,948] {scheduler_job.py:153} INFO - Started process (PID=792) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:01:13,954] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:01:13,954] {logging_mixin.py:112} INFO - [2020-06-01 18:01:13,954] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:01:13,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:01:14,119] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:02:04,018] {scheduler_job.py:153} INFO - Started process (PID=821) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:04,025] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:02:04,025] {logging_mixin.py:112} INFO - [2020-06-01 18:02:04,025] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:04,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:04,188] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.169 seconds
[2020-06-01 18:02:54,044] {scheduler_job.py:153} INFO - Started process (PID=854) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:54,049] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:02:54,050] {logging_mixin.py:112} INFO - [2020-06-01 18:02:54,049] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:54,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:02:54,208] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.164 seconds
[2020-06-01 18:03:44,065] {scheduler_job.py:153} INFO - Started process (PID=883) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:03:44,070] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:03:44,071] {logging_mixin.py:112} INFO - [2020-06-01 18:03:44,070] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:03:44,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:03:44,230] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:04:34,135] {scheduler_job.py:153} INFO - Started process (PID=916) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:04:34,143] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:04:34,144] {logging_mixin.py:112} INFO - [2020-06-01 18:04:34,144] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:04:34,169] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:04:34,366] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.232 seconds
[2020-06-01 18:05:24,130] {scheduler_job.py:153} INFO - Started process (PID=949) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:05:24,136] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:05:24,136] {logging_mixin.py:112} INFO - [2020-06-01 18:05:24,136] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:05:24,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:05:24,277] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.148 seconds
[2020-06-01 18:06:51,026] {scheduler_job.py:153} INFO - Started process (PID=1000) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:06:51,032] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:06:51,033] {logging_mixin.py:112} INFO - [2020-06-01 18:06:51,033] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:06:51,053] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:06:51,185] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:08:20,439] {scheduler_job.py:153} INFO - Started process (PID=1072) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:08:20,445] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:08:20,446] {logging_mixin.py:112} INFO - [2020-06-01 18:08:20,446] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:08:20,464] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:08:20,617] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:09:10,486] {scheduler_job.py:153} INFO - Started process (PID=1101) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:09:10,492] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:09:10,493] {logging_mixin.py:112} INFO - [2020-06-01 18:09:10,493] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:09:10,520] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:09:11,017] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.531 seconds
[2020-06-01 18:10:00,913] {scheduler_job.py:153} INFO - Started process (PID=1134) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:00,919] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:10:00,919] {logging_mixin.py:112} INFO - [2020-06-01 18:10:00,919] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:00,939] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:01,062] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.149 seconds
[2020-06-01 18:10:50,948] {scheduler_job.py:153} INFO - Started process (PID=1163) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:50,953] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:10:50,954] {logging_mixin.py:112} INFO - [2020-06-01 18:10:50,954] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:50,972] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:10:51,123] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.176 seconds
[2020-06-01 18:11:40,927] {scheduler_job.py:153} INFO - Started process (PID=1196) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:11:40,933] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:11:40,933] {logging_mixin.py:112} INFO - [2020-06-01 18:11:40,933] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:11:40,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:11:41,072] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.145 seconds
[2020-06-01 18:12:30,945] {scheduler_job.py:153} INFO - Started process (PID=1225) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:12:30,950] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:12:30,951] {logging_mixin.py:112} INFO - [2020-06-01 18:12:30,951] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:12:30,969] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:12:31,106] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.161 seconds
[2020-06-01 18:13:20,969] {scheduler_job.py:153} INFO - Started process (PID=1258) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:13:20,975] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:13:20,976] {logging_mixin.py:112} INFO - [2020-06-01 18:13:20,976] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:13:20,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:13:21,160] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:14:11,003] {scheduler_job.py:153} INFO - Started process (PID=1291) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:14:11,009] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:14:11,010] {logging_mixin.py:112} INFO - [2020-06-01 18:14:11,009] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:14:11,027] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:14:11,161] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.158 seconds
[2020-06-01 18:15:01,019] {scheduler_job.py:153} INFO - Started process (PID=1320) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:01,025] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:15:01,025] {logging_mixin.py:112} INFO - [2020-06-01 18:15:01,025] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:01,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:01,311] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.292 seconds
[2020-06-01 18:15:51,044] {scheduler_job.py:153} INFO - Started process (PID=1353) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:51,049] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:15:51,049] {logging_mixin.py:112} INFO - [2020-06-01 18:15:51,049] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:51,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:15:51,248] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:16:41,076] {scheduler_job.py:153} INFO - Started process (PID=1382) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:16:41,083] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:16:41,084] {logging_mixin.py:112} INFO - [2020-06-01 18:16:41,084] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:16:41,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:16:41,253] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.177 seconds
[2020-06-01 18:17:31,110] {scheduler_job.py:153} INFO - Started process (PID=1415) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:17:31,116] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:17:31,117] {logging_mixin.py:112} INFO - [2020-06-01 18:17:31,117] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:17:31,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:17:31,271] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.161 seconds
[2020-06-01 18:18:21,133] {scheduler_job.py:153} INFO - Started process (PID=1445) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:18:21,139] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:18:21,139] {logging_mixin.py:112} INFO - [2020-06-01 18:18:21,139] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:18:21,160] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:18:21,380] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:19:11,201] {scheduler_job.py:153} INFO - Started process (PID=1478) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:19:11,209] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:19:11,210] {logging_mixin.py:112} INFO - [2020-06-01 18:19:11,210] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:19:11,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:19:11,486] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.285 seconds
[2020-06-01 18:20:01,237] {scheduler_job.py:153} INFO - Started process (PID=1507) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:01,244] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:20:01,245] {logging_mixin.py:112} INFO - [2020-06-01 18:20:01,245] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:01,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:01,464] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.227 seconds
[2020-06-01 18:20:51,400] {scheduler_job.py:153} INFO - Started process (PID=1540) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:51,405] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:20:51,406] {logging_mixin.py:112} INFO - [2020-06-01 18:20:51,406] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:51,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:20:51,666] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:21:41,620] {scheduler_job.py:153} INFO - Started process (PID=1572) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:21:41,625] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:21:41,626] {logging_mixin.py:112} INFO - [2020-06-01 18:21:41,626] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:21:41,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:21:41,835] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.215 seconds
[2020-06-01 18:22:31,655] {scheduler_job.py:153} INFO - Started process (PID=1605) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:22:31,661] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:22:31,662] {logging_mixin.py:112} INFO - [2020-06-01 18:22:31,662] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:22:31,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:22:31,837] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.182 seconds
[2020-06-01 18:23:21,685] {scheduler_job.py:153} INFO - Started process (PID=1638) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:23:21,691] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:23:21,692] {logging_mixin.py:112} INFO - [2020-06-01 18:23:21,692] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:23:21,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:23:21,899] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:24:11,732] {scheduler_job.py:153} INFO - Started process (PID=1667) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:24:11,739] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:24:11,740] {logging_mixin.py:112} INFO - [2020-06-01 18:24:11,740] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:24:11,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:24:11,893] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.161 seconds
[2020-06-01 18:25:01,735] {scheduler_job.py:153} INFO - Started process (PID=1700) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:01,776] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:25:01,778] {logging_mixin.py:112} INFO - [2020-06-01 18:25:01,777] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:01,824] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:02,059] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.323 seconds
[2020-06-01 18:25:51,770] {scheduler_job.py:153} INFO - Started process (PID=1733) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:51,777] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:25:51,778] {logging_mixin.py:112} INFO - [2020-06-01 18:25:51,778] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:51,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:25:52,076] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:26:41,804] {scheduler_job.py:153} INFO - Started process (PID=1791) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:26:41,810] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:26:41,810] {logging_mixin.py:112} INFO - [2020-06-01 18:26:41,810] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:26:41,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:26:42,068] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.264 seconds
[2020-06-01 18:27:31,874] {scheduler_job.py:153} INFO - Started process (PID=1820) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:27:31,881] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:27:31,882] {logging_mixin.py:112} INFO - [2020-06-01 18:27:31,882] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:27:31,911] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:27:32,149] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.275 seconds
[2020-06-01 18:28:21,993] {scheduler_job.py:153} INFO - Started process (PID=1853) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:28:22,000] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:28:22,000] {logging_mixin.py:112} INFO - [2020-06-01 18:28:22,000] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:28:22,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:28:22,375] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:29:12,042] {scheduler_job.py:153} INFO - Started process (PID=1882) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:29:12,050] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:29:12,051] {logging_mixin.py:112} INFO - [2020-06-01 18:29:12,050] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:29:12,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:29:12,206] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.164 seconds
[2020-06-01 18:30:02,047] {scheduler_job.py:153} INFO - Started process (PID=1915) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:02,056] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:30:02,057] {logging_mixin.py:112} INFO - [2020-06-01 18:30:02,057] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:02,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:02,498] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.452 seconds
[2020-06-01 18:30:52,092] {scheduler_job.py:153} INFO - Started process (PID=1944) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:52,098] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:30:52,099] {logging_mixin.py:112} INFO - [2020-06-01 18:30:52,098] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:52,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:30:52,363] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:31:42,128] {scheduler_job.py:153} INFO - Started process (PID=1977) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:31:42,135] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:31:42,136] {logging_mixin.py:112} INFO - [2020-06-01 18:31:42,136] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:31:42,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:31:42,400] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.272 seconds
[2020-06-01 18:32:32,164] {scheduler_job.py:153} INFO - Started process (PID=2006) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:32:32,170] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:32:32,171] {logging_mixin.py:112} INFO - [2020-06-01 18:32:32,171] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:32:32,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:32:32,296] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.133 seconds
[2020-06-01 18:33:22,174] {scheduler_job.py:153} INFO - Started process (PID=2039) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:33:22,180] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:33:22,180] {logging_mixin.py:112} INFO - [2020-06-01 18:33:22,180] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:33:22,201] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:33:22,463] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:34:12,236] {scheduler_job.py:153} INFO - Started process (PID=2072) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:34:12,247] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:34:12,249] {logging_mixin.py:112} INFO - [2020-06-01 18:34:12,248] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:34:12,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:34:12,496] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.260 seconds
[2020-06-01 18:35:02,233] {scheduler_job.py:153} INFO - Started process (PID=2101) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:02,239] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:35:02,240] {logging_mixin.py:112} INFO - [2020-06-01 18:35:02,240] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:02,262] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:02,487] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.254 seconds
[2020-06-01 18:35:52,274] {scheduler_job.py:153} INFO - Started process (PID=2134) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:52,279] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:35:52,280] {logging_mixin.py:112} INFO - [2020-06-01 18:35:52,280] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:52,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:35:52,718] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:36:42,306] {scheduler_job.py:153} INFO - Started process (PID=2163) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:36:42,312] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:36:42,314] {logging_mixin.py:112} INFO - [2020-06-01 18:36:42,313] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:36:42,334] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:36:42,488] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.182 seconds
[2020-06-01 18:37:32,352] {scheduler_job.py:153} INFO - Started process (PID=2196) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:37:32,357] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:37:32,358] {logging_mixin.py:112} INFO - [2020-06-01 18:37:32,358] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:37:32,381] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:37:32,531] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.180 seconds
[2020-06-01 18:38:22,364] {scheduler_job.py:153} INFO - Started process (PID=2225) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:38:22,370] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:38:22,371] {logging_mixin.py:112} INFO - [2020-06-01 18:38:22,371] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:38:22,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:38:22,626] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:39:12,424] {scheduler_job.py:153} INFO - Started process (PID=2258) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:39:12,430] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:39:12,431] {logging_mixin.py:112} INFO - [2020-06-01 18:39:12,431] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:39:12,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:39:12,683] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.258 seconds
[2020-06-01 18:40:02,443] {scheduler_job.py:153} INFO - Started process (PID=2287) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:02,450] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:40:02,450] {logging_mixin.py:112} INFO - [2020-06-01 18:40:02,450] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:02,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:02,628] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.185 seconds
[2020-06-01 18:40:52,455] {scheduler_job.py:153} INFO - Started process (PID=2320) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:52,461] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:40:52,461] {logging_mixin.py:112} INFO - [2020-06-01 18:40:52,461] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:52,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:40:52,760] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:41:42,486] {scheduler_job.py:153} INFO - Started process (PID=2349) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:41:42,491] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:41:42,492] {logging_mixin.py:112} INFO - [2020-06-01 18:41:42,492] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:41:42,512] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:41:42,974] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.488 seconds
[2020-06-01 18:42:32,528] {scheduler_job.py:153} INFO - Started process (PID=2382) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:42:32,534] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:42:32,535] {logging_mixin.py:112} INFO - [2020-06-01 18:42:32,535] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:42:32,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:42:32,966] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.438 seconds
[2020-06-01 18:43:22,548] {scheduler_job.py:153} INFO - Started process (PID=2411) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:43:22,553] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:43:22,554] {logging_mixin.py:112} INFO - [2020-06-01 18:43:22,554] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:43:22,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:43:23,057] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:44:12,672] {scheduler_job.py:153} INFO - Started process (PID=2444) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:44:12,678] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:44:12,679] {logging_mixin.py:112} INFO - [2020-06-01 18:44:12,679] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:44:12,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:44:13,019] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.347 seconds
[2020-06-01 18:45:02,819] {scheduler_job.py:153} INFO - Started process (PID=2477) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:02,827] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:45:02,828] {logging_mixin.py:112} INFO - [2020-06-01 18:45:02,828] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:02,859] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:03,167] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.348 seconds
[2020-06-01 18:45:53,056] {scheduler_job.py:153} INFO - Started process (PID=2506) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:53,062] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:45:53,063] {logging_mixin.py:112} INFO - [2020-06-01 18:45:53,063] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:53,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:45:53,903] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:46:43,076] {scheduler_job.py:153} INFO - Started process (PID=2539) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:46:43,083] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:46:43,084] {logging_mixin.py:112} INFO - [2020-06-01 18:46:43,084] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:46:43,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:46:43,612] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.536 seconds
[2020-06-01 18:47:33,104] {scheduler_job.py:153} INFO - Started process (PID=2568) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:47:33,112] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:47:33,114] {logging_mixin.py:112} INFO - [2020-06-01 18:47:33,112] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:47:33,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:47:33,415] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.312 seconds
[2020-06-01 18:48:23,129] {scheduler_job.py:153} INFO - Started process (PID=2601) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:48:23,136] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:48:23,137] {logging_mixin.py:112} INFO - [2020-06-01 18:48:23,137] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:48:23,156] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:48:23,613] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:49:22,890] {scheduler_job.py:153} INFO - Started process (PID=2634) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:49:22,896] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:49:22,897] {logging_mixin.py:112} INFO - [2020-06-01 18:49:22,897] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:49:22,924] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:49:23,279] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.389 seconds
[2020-06-01 18:50:12,917] {scheduler_job.py:153} INFO - Started process (PID=2663) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:50:12,923] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:50:12,924] {logging_mixin.py:112} INFO - [2020-06-01 18:50:12,923] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:50:12,947] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:50:13,123] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.206 seconds
[2020-06-01 18:51:02,950] {scheduler_job.py:153} INFO - Started process (PID=2696) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:51:02,955] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:51:02,956] {logging_mixin.py:112} INFO - [2020-06-01 18:51:02,956] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:51:02,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:51:03,756] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:51:59,330] {scheduler_job.py:153} INFO - Started process (PID=2725) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:51:59,336] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:51:59,337] {logging_mixin.py:112} INFO - [2020-06-01 18:51:59,336] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:51:59,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:52:00,740] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 1.410 seconds
[2020-06-01 18:52:49,576] {scheduler_job.py:153} INFO - Started process (PID=2758) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:52:49,583] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:52:49,584] {logging_mixin.py:112} INFO - [2020-06-01 18:52:49,584] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:52:49,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:52:50,205] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.629 seconds
[2020-06-01 18:53:39,881] {scheduler_job.py:153} INFO - Started process (PID=2787) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:53:39,888] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:53:39,888] {logging_mixin.py:112} INFO - [2020-06-01 18:53:39,888] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:53:39,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:53:40,400] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:54:29,908] {scheduler_job.py:153} INFO - Started process (PID=2820) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:54:29,914] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:54:29,915] {logging_mixin.py:112} INFO - [2020-06-01 18:54:29,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:54:29,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:54:30,241] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.333 seconds
[2020-06-01 18:55:19,952] {scheduler_job.py:153} INFO - Started process (PID=2853) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:55:19,958] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:55:19,959] {logging_mixin.py:112} INFO - [2020-06-01 18:55:19,959] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:55:19,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:55:20,254] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.303 seconds
[2020-06-01 18:56:11,014] {scheduler_job.py:153} INFO - Started process (PID=2882) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:56:11,019] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:56:11,020] {logging_mixin.py:112} INFO - [2020-06-01 18:56:11,020] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:56:11,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:56:11,288] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:57:10,514] {scheduler_job.py:153} INFO - Started process (PID=2915) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:57:10,520] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:57:10,521] {logging_mixin.py:112} INFO - [2020-06-01 18:57:10,520] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:57:10,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:57:10,766] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.252 seconds
[2020-06-01 18:58:01,021] {scheduler_job.py:153} INFO - Started process (PID=2944) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:01,026] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:58:01,027] {logging_mixin.py:112} INFO - [2020-06-01 18:58:01,027] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:01,047] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:01,220] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.199 seconds
[2020-06-01 18:58:51,027] {scheduler_job.py:153} INFO - Started process (PID=2977) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:51,049] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:58:51,050] {logging_mixin.py:112} INFO - [2020-06-01 18:58:51,050] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:51,140] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:58:51,354] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:59:41,046] {scheduler_job.py:153} INFO - Started process (PID=3006) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:59:41,052] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 18:59:41,053] {logging_mixin.py:112} INFO - [2020-06-01 18:59:41,052] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:59:41,072] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 18:59:41,287] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.240 seconds
[2020-06-01 19:00:31,082] {scheduler_job.py:153} INFO - Started process (PID=3039) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:00:31,087] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:00:31,088] {logging_mixin.py:112} INFO - [2020-06-01 19:00:31,088] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:00:31,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:00:31,232] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.151 seconds
[2020-06-01 19:01:21,110] {scheduler_job.py:153} INFO - Started process (PID=3068) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:01:21,116] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:01:21,117] {logging_mixin.py:112} INFO - [2020-06-01 19:01:21,117] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:01:21,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:01:21,308] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:02:11,140] {scheduler_job.py:153} INFO - Started process (PID=3101) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:02:11,145] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:02:11,146] {logging_mixin.py:112} INFO - [2020-06-01 19:02:11,146] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:02:11,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:02:11,354] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.214 seconds
[2020-06-01 19:03:01,176] {scheduler_job.py:153} INFO - Started process (PID=3130) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:01,182] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:03:01,182] {logging_mixin.py:112} INFO - [2020-06-01 19:03:01,182] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:01,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:01,386] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.210 seconds
[2020-06-01 19:03:51,193] {scheduler_job.py:153} INFO - Started process (PID=3163) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:51,198] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:03:51,199] {logging_mixin.py:112} INFO - [2020-06-01 19:03:51,199] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:51,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:03:51,452] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:04:41,222] {scheduler_job.py:153} INFO - Started process (PID=3192) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:04:41,229] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:04:41,230] {logging_mixin.py:112} INFO - [2020-06-01 19:04:41,230] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:04:41,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:04:41,440] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.218 seconds
[2020-06-01 19:05:31,252] {scheduler_job.py:153} INFO - Started process (PID=3225) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:05:31,258] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:05:31,259] {logging_mixin.py:112} INFO - [2020-06-01 19:05:31,258] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:05:31,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:05:31,430] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.178 seconds
[2020-06-01 19:06:21,282] {scheduler_job.py:153} INFO - Started process (PID=3254) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:06:21,287] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:06:21,288] {logging_mixin.py:112} INFO - [2020-06-01 19:06:21,288] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:06:21,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:06:21,551] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.270 seconds
[2020-06-01 19:07:11,310] {scheduler_job.py:153} INFO - Started process (PID=3287) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:07:11,315] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:07:11,316] {logging_mixin.py:112} INFO - [2020-06-01 19:07:11,316] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:07:11,335] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:07:11,484] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.175 seconds
[2020-06-01 19:08:01,361] {scheduler_job.py:153} INFO - Started process (PID=3320) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:08:01,366] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:08:01,367] {logging_mixin.py:112} INFO - [2020-06-01 19:08:01,367] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:08:01,390] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:08:01,527] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.167 seconds
[2020-06-01 19:51:13,423] {scheduler_job.py:153} INFO - Started process (PID=3365) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:51:13,430] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:51:13,430] {logging_mixin.py:112} INFO - [2020-06-01 19:51:13,430] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:51:13,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:51:14,131] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.709 seconds
[2020-06-01 19:52:05,356] {scheduler_job.py:153} INFO - Started process (PID=3390) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:05,363] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:52:05,364] {logging_mixin.py:112} INFO - [2020-06-01 19:52:05,364] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:05,390] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:05,913] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.557 seconds
[2020-06-01 19:52:55,379] {scheduler_job.py:153} INFO - Started process (PID=3415) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:55,385] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:52:55,386] {logging_mixin.py:112} INFO - [2020-06-01 19:52:55,385] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:55,405] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:52:55,542] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.163 seconds
[2020-06-01 19:53:45,409] {scheduler_job.py:153} INFO - Started process (PID=3440) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:53:45,415] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:53:45,416] {logging_mixin.py:112} INFO - [2020-06-01 19:53:45,415] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:53:45,434] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:53:45,609] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:54:35,436] {scheduler_job.py:153} INFO - Started process (PID=3465) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:54:35,442] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:54:35,443] {logging_mixin.py:112} INFO - [2020-06-01 19:54:35,442] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:54:35,462] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:54:35,731] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.294 seconds
[2020-06-01 19:55:25,465] {scheduler_job.py:153} INFO - Started process (PID=3490) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:55:25,470] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:55:25,471] {logging_mixin.py:112} INFO - [2020-06-01 19:55:25,471] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:55:25,490] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:55:25,707] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.243 seconds
[2020-06-01 19:56:15,513] {scheduler_job.py:153} INFO - Started process (PID=3516) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:56:15,519] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:56:15,520] {logging_mixin.py:112} INFO - [2020-06-01 19:56:15,520] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:56:15,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:56:15,718] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:57:05,559] {scheduler_job.py:153} INFO - Started process (PID=3541) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:05,568] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:57:05,570] {logging_mixin.py:112} INFO - [2020-06-01 19:57:05,569] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:05,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:06,339] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.780 seconds
[2020-06-01 19:57:55,586] {scheduler_job.py:153} INFO - Started process (PID=3566) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:55,593] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:57:55,594] {logging_mixin.py:112} INFO - [2020-06-01 19:57:55,594] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:55,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:57:55,786] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.201 seconds
[2020-06-01 19:58:45,632] {scheduler_job.py:153} INFO - Started process (PID=3591) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:58:45,640] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:58:45,641] {logging_mixin.py:112} INFO - [2020-06-01 19:58:45,641] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:58:45,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:58:46,028] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:59:35,641] {scheduler_job.py:153} INFO - Started process (PID=3616) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:59:35,647] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 19:59:35,647] {logging_mixin.py:112} INFO - [2020-06-01 19:59:35,647] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:59:35,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 19:59:35,815] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.174 seconds
[2020-06-01 20:00:25,676] {scheduler_job.py:153} INFO - Started process (PID=3641) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:00:25,682] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 20:00:25,682] {logging_mixin.py:112} INFO - [2020-06-01 20:00:25,682] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:00:25,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:00:25,863] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.187 seconds
[2020-06-01 20:01:15,696] {scheduler_job.py:153} INFO - Started process (PID=3667) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:01:15,702] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-01 20:01:15,703] {logging_mixin.py:112} INFO - [2020-06-01 20:01:15,702] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:01:15,723] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-01 20:01:15,948] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:16:06,263] {scheduler_job.py:153} INFO - Started process (PID=252) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:16:06,286] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:16:06,286] {logging_mixin.py:112} INFO - [2020-06-02 15:16:06,286] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:16:06,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:16:06,580] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.318 seconds
[2020-06-02 15:17:20,870] {scheduler_job.py:153} INFO - Started process (PID=292) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:17:20,876] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:17:20,877] {logging_mixin.py:112} INFO - [2020-06-02 15:17:20,877] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:17:21,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:17:21,149] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.279 seconds
[2020-06-02 15:18:10,887] {scheduler_job.py:153} INFO - Started process (PID=318) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:18:10,893] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:18:10,894] {logging_mixin.py:112} INFO - [2020-06-02 15:18:10,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:18:11,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:18:11,211] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.324 seconds
[2020-06-02 15:19:00,941] {scheduler_job.py:153} INFO - Started process (PID=364) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:00,947] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:19:00,947] {logging_mixin.py:112} INFO - [2020-06-02 15:19:00,947] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:01,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:01,232] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.291 seconds
[2020-06-02 15:19:50,934] {scheduler_job.py:153} INFO - Started process (PID=408) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:50,940] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:19:50,941] {logging_mixin.py:112} INFO - [2020-06-02 15:19:50,941] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:51,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:19:51,213] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.279 seconds
[2020-06-02 15:20:40,957] {scheduler_job.py:153} INFO - Started process (PID=435) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:20:40,962] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:20:40,963] {logging_mixin.py:112} INFO - [2020-06-02 15:20:40,963] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:20:40,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:20:41,147] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:21:30,993] {scheduler_job.py:153} INFO - Started process (PID=461) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:21:30,998] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:21:30,999] {logging_mixin.py:112} INFO - [2020-06-02 15:21:30,999] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:21:31,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:21:31,145] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.153 seconds
[2020-06-02 15:22:45,521] {scheduler_job.py:153} INFO - Started process (PID=501) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:22:45,527] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:22:45,528] {logging_mixin.py:112} INFO - [2020-06-02 15:22:45,528] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:22:45,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:22:45,680] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.158 seconds
[2020-06-02 15:23:35,545] {scheduler_job.py:153} INFO - Started process (PID=527) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:23:35,552] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:23:35,552] {logging_mixin.py:112} INFO - [2020-06-02 15:23:35,552] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:23:35,565] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:23:35,713] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:24:25,581] {scheduler_job.py:153} INFO - Started process (PID=554) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:24:25,588] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:24:25,589] {logging_mixin.py:112} INFO - [2020-06-02 15:24:25,589] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:24:25,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:24:25,722] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.141 seconds
[2020-06-02 15:25:34,192] {scheduler_job.py:153} INFO - Started process (PID=597) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:25:34,203] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:25:34,204] {logging_mixin.py:112} INFO - [2020-06-02 15:25:34,204] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:25:34,216] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:25:34,493] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.301 seconds
[2020-06-02 15:26:36,457] {scheduler_job.py:153} INFO - Started process (PID=628) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:26:36,461] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:26:36,462] {logging_mixin.py:112} INFO - [2020-06-02 15:26:36,462] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:26:36,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:26:36,818] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.361 seconds
[2020-06-02 15:27:26,501] {scheduler_job.py:153} INFO - Started process (PID=653) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:27:26,507] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:27:26,507] {logging_mixin.py:112} INFO - [2020-06-02 15:27:26,507] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:27:26,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:27:26,784] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.283 seconds
[2020-06-02 15:28:16,498] {scheduler_job.py:153} INFO - Started process (PID=678) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:28:16,503] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:28:16,503] {logging_mixin.py:112} INFO - [2020-06-02 15:28:16,503] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:28:16,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:28:16,811] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.314 seconds
[2020-06-02 15:29:06,520] {scheduler_job.py:153} INFO - Started process (PID=703) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:06,525] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:29:06,525] {logging_mixin.py:112} INFO - [2020-06-02 15:29:06,525] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:06,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:06,773] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.254 seconds
[2020-06-02 15:29:56,544] {scheduler_job.py:153} INFO - Started process (PID=728) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:56,550] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:29:56,550] {logging_mixin.py:112} INFO - [2020-06-02 15:29:56,550] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:56,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:29:56,825] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.281 seconds
[2020-06-02 15:30:46,587] {scheduler_job.py:153} INFO - Started process (PID=753) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:30:46,592] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:30:46,593] {logging_mixin.py:112} INFO - [2020-06-02 15:30:46,592] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:30:46,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:30:46,739] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.153 seconds
[2020-06-02 15:31:48,298] {scheduler_job.py:153} INFO - Started process (PID=784) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:31:48,303] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:31:48,304] {logging_mixin.py:112} INFO - [2020-06-02 15:31:48,303] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:31:48,315] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:31:48,430] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.132 seconds
[2020-06-02 15:32:38,320] {scheduler_job.py:153} INFO - Started process (PID=809) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:32:38,325] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:32:38,326] {logging_mixin.py:112} INFO - [2020-06-02 15:32:38,325] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:32:38,337] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:32:38,475] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:33:28,342] {scheduler_job.py:153} INFO - Started process (PID=834) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:33:28,348] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:33:28,349] {logging_mixin.py:112} INFO - [2020-06-02 15:33:28,348] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:33:28,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:33:28,509] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.166 seconds
[2020-06-02 15:34:18,366] {scheduler_job.py:153} INFO - Started process (PID=859) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:34:18,372] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:34:18,372] {logging_mixin.py:112} INFO - [2020-06-02 15:34:18,372] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:34:18,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:34:18,552] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.186 seconds
[2020-06-02 15:35:08,391] {scheduler_job.py:153} INFO - Started process (PID=884) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:08,397] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:35:08,397] {logging_mixin.py:112} INFO - [2020-06-02 15:35:08,397] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:08,409] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:08,562] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:35:58,413] {scheduler_job.py:153} INFO - Started process (PID=929) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:58,418] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:35:58,419] {logging_mixin.py:112} INFO - [2020-06-02 15:35:58,419] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:58,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:35:58,598] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.185 seconds
[2020-06-02 15:36:48,436] {scheduler_job.py:153} INFO - Started process (PID=954) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:36:48,441] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:36:48,442] {logging_mixin.py:112} INFO - [2020-06-02 15:36:48,442] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:36:48,454] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:36:48,606] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.170 seconds
[2020-06-02 15:37:38,461] {scheduler_job.py:153} INFO - Started process (PID=979) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:37:38,466] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:37:38,467] {logging_mixin.py:112} INFO - [2020-06-02 15:37:38,467] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:37:38,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:37:38,606] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:38:28,485] {scheduler_job.py:153} INFO - Started process (PID=1015) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:38:28,494] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:38:28,495] {logging_mixin.py:112} INFO - [2020-06-02 15:38:28,495] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:38:28,506] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:38:28,763] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.278 seconds
[2020-06-02 15:39:18,507] {scheduler_job.py:153} INFO - Started process (PID=1040) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:39:18,512] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:39:18,513] {logging_mixin.py:112} INFO - [2020-06-02 15:39:18,513] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:39:18,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:39:18,695] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.189 seconds
[2020-06-02 15:40:08,543] {scheduler_job.py:153} INFO - Started process (PID=1065) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:08,549] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:40:08,549] {logging_mixin.py:112} INFO - [2020-06-02 15:40:08,549] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:08,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:08,716] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:40:58,560] {scheduler_job.py:153} INFO - Started process (PID=1090) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:58,566] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:40:58,566] {logging_mixin.py:112} INFO - [2020-06-02 15:40:58,566] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:58,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:40:58,728] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.169 seconds
[2020-06-02 15:42:44,353] {scheduler_job.py:153} INFO - Started process (PID=1157) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:42:44,358] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:42:44,359] {logging_mixin.py:112} INFO - [2020-06-02 15:42:44,359] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:42:44,370] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:42:44,647] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.294 seconds
[2020-06-02 15:43:34,372] {scheduler_job.py:153} INFO - Started process (PID=1183) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:43:34,382] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:43:34,383] {logging_mixin.py:112} INFO - [2020-06-02 15:43:34,383] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:43:34,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:43:34,684] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.312 seconds
[2020-06-02 15:44:24,391] {scheduler_job.py:153} INFO - Started process (PID=1208) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:44:24,397] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:44:24,397] {logging_mixin.py:112} INFO - [2020-06-02 15:44:24,397] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:44:24,543] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:44:24,643] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.252 seconds
[2020-06-02 15:45:26,178] {scheduler_job.py:153} INFO - Started process (PID=1239) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:45:26,183] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:45:26,184] {logging_mixin.py:112} INFO - [2020-06-02 15:45:26,184] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:45:26,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:45:26,443] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.265 seconds
[2020-06-02 15:46:33,524] {scheduler_job.py:153} INFO - Started process (PID=1270) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:46:33,529] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:46:33,530] {logging_mixin.py:112} INFO - [2020-06-02 15:46:33,529] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:46:33,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:46:33,778] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.254 seconds
[2020-06-02 15:47:35,388] {scheduler_job.py:153} INFO - Started process (PID=1301) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:47:35,393] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:47:35,394] {logging_mixin.py:112} INFO - [2020-06-02 15:47:35,394] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:47:35,405] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:47:35,535] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.147 seconds
[2020-06-02 15:48:25,412] {scheduler_job.py:153} INFO - Started process (PID=1326) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:48:25,418] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:48:25,419] {logging_mixin.py:112} INFO - [2020-06-02 15:48:25,419] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:48:25,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:48:25,612] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:49:15,437] {scheduler_job.py:153} INFO - Started process (PID=1351) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:49:15,443] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:49:15,443] {logging_mixin.py:112} INFO - [2020-06-02 15:49:15,443] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:49:15,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:49:15,568] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.131 seconds
[2020-06-02 15:50:05,461] {scheduler_job.py:153} INFO - Started process (PID=1376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:05,466] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:50:05,467] {logging_mixin.py:112} INFO - [2020-06-02 15:50:05,467] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:05,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:05,622] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.162 seconds
[2020-06-02 15:50:55,510] {scheduler_job.py:153} INFO - Started process (PID=1401) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:55,516] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:50:55,517] {logging_mixin.py:112} INFO - [2020-06-02 15:50:55,517] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:55,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:50:55,689] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:51:45,589] {scheduler_job.py:153} INFO - Started process (PID=1426) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:51:45,594] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:51:45,595] {logging_mixin.py:112} INFO - [2020-06-02 15:51:45,594] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:51:45,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:51:45,711] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.123 seconds
[2020-06-02 15:52:35,556] {scheduler_job.py:153} INFO - Started process (PID=1451) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:52:35,561] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:52:35,562] {logging_mixin.py:112} INFO - [2020-06-02 15:52:35,562] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:52:35,573] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:52:35,677] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.122 seconds
[2020-06-02 15:53:25,580] {scheduler_job.py:153} INFO - Started process (PID=1476) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:53:25,585] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:53:25,586] {logging_mixin.py:112} INFO - [2020-06-02 15:53:25,586] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:53:25,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:53:25,785] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:54:15,603] {scheduler_job.py:153} INFO - Started process (PID=1501) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:54:15,609] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:54:15,609] {logging_mixin.py:112} INFO - [2020-06-02 15:54:15,609] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:54:15,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:54:15,810] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.207 seconds
[2020-06-02 15:55:05,627] {scheduler_job.py:153} INFO - Started process (PID=1526) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:05,633] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:55:05,634] {logging_mixin.py:112} INFO - [2020-06-02 15:55:05,633] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:05,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:05,765] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.138 seconds
[2020-06-02 15:55:55,656] {scheduler_job.py:153} INFO - Started process (PID=1551) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:55,661] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:55:55,662] {logging_mixin.py:112} INFO - [2020-06-02 15:55:55,662] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:55,675] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:55:55,886] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:56:45,687] {scheduler_job.py:153} INFO - Started process (PID=1576) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:56:45,693] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:56:45,694] {logging_mixin.py:112} INFO - [2020-06-02 15:56:45,694] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:56:45,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:56:45,863] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.176 seconds
[2020-06-02 15:57:35,700] {scheduler_job.py:153} INFO - Started process (PID=1601) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:57:35,705] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:57:35,706] {logging_mixin.py:112} INFO - [2020-06-02 15:57:35,705] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:57:35,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:57:35,874] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.175 seconds
[2020-06-02 15:58:25,723] {scheduler_job.py:153} INFO - Started process (PID=1626) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:58:25,729] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:58:25,730] {logging_mixin.py:112} INFO - [2020-06-02 15:58:25,730] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:58:25,744] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:58:25,985] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:59:15,745] {scheduler_job.py:153} INFO - Started process (PID=1651) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:59:15,750] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 15:59:15,751] {logging_mixin.py:112} INFO - [2020-06-02 15:59:15,751] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:59:15,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 15:59:15,929] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.184 seconds
[2020-06-02 16:00:05,871] {scheduler_job.py:153} INFO - Started process (PID=1676) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:05,877] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:00:05,877] {logging_mixin.py:112} INFO - [2020-06-02 16:00:05,877] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:05,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:06,042] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.171 seconds
[2020-06-02 16:00:55,913] {scheduler_job.py:153} INFO - Started process (PID=1701) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:55,919] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:00:55,920] {logging_mixin.py:112} INFO - [2020-06-02 16:00:55,920] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:55,931] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:00:56,139] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:01:45,920] {scheduler_job.py:153} INFO - Started process (PID=1726) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:01:45,926] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:01:45,927] {logging_mixin.py:112} INFO - [2020-06-02 16:01:45,927] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:01:45,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:01:46,139] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.220 seconds
[2020-06-02 16:02:35,946] {scheduler_job.py:153} INFO - Started process (PID=1751) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:02:35,951] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:02:35,952] {logging_mixin.py:112} INFO - [2020-06-02 16:02:35,951] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:02:35,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:02:36,073] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.127 seconds
[2020-06-02 16:03:25,971] {scheduler_job.py:153} INFO - Started process (PID=1776) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:03:25,977] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:03:25,977] {logging_mixin.py:112} INFO - [2020-06-02 16:03:25,977] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:03:25,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:03:26,117] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:04:15,990] {scheduler_job.py:153} INFO - Started process (PID=1801) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:04:15,995] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:04:15,996] {logging_mixin.py:112} INFO - [2020-06-02 16:04:15,995] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:04:16,007] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:04:16,149] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.160 seconds
[2020-06-02 16:05:06,012] {scheduler_job.py:153} INFO - Started process (PID=1826) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:06,018] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:05:06,018] {logging_mixin.py:112} INFO - [2020-06-02 16:05:06,018] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:06,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:06,149] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.137 seconds
[2020-06-02 16:05:56,057] {scheduler_job.py:153} INFO - Started process (PID=1851) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:56,063] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:05:56,064] {logging_mixin.py:112} INFO - [2020-06-02 16:05:56,064] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:56,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:05:56,226] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:06:46,066] {scheduler_job.py:153} INFO - Started process (PID=1876) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:06:46,072] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:06:46,073] {logging_mixin.py:112} INFO - [2020-06-02 16:06:46,073] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:06:46,085] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:06:46,204] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.138 seconds
[2020-06-02 16:07:36,091] {scheduler_job.py:153} INFO - Started process (PID=1901) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:07:36,098] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:07:36,098] {logging_mixin.py:112} INFO - [2020-06-02 16:07:36,098] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:07:36,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:07:36,225] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.134 seconds
[2020-06-02 16:08:26,117] {scheduler_job.py:153} INFO - Started process (PID=1926) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:08:26,123] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:08:26,123] {logging_mixin.py:112} INFO - [2020-06-02 16:08:26,123] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:08:26,134] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:08:26,336] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.219 seconds
[2020-06-02 16:09:16,141] {scheduler_job.py:153} INFO - Started process (PID=1951) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:09:16,147] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:09:16,147] {logging_mixin.py:112} INFO - [2020-06-02 16:09:16,147] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:09:16,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:09:16,302] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.161 seconds
[2020-06-02 16:10:06,175] {scheduler_job.py:153} INFO - Started process (PID=1976) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:06,181] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:10:06,182] {logging_mixin.py:112} INFO - [2020-06-02 16:10:06,182] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:06,196] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:06,372] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.197 seconds
[2020-06-02 16:10:56,245] {scheduler_job.py:153} INFO - Started process (PID=2001) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:56,253] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:10:56,254] {logging_mixin.py:112} INFO - [2020-06-02 16:10:56,253] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:56,271] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:10:56,403] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.158 seconds
[2020-06-02 16:11:46,262] {scheduler_job.py:153} INFO - Started process (PID=2026) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:11:46,267] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:11:46,268] {logging_mixin.py:112} INFO - [2020-06-02 16:11:46,268] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:11:46,280] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:11:46,436] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.175 seconds
[2020-06-02 16:12:36,292] {scheduler_job.py:153} INFO - Started process (PID=2051) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:12:36,298] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:12:36,299] {logging_mixin.py:112} INFO - [2020-06-02 16:12:36,299] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:12:36,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:12:36,424] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.132 seconds
[2020-06-02 16:13:26,321] {scheduler_job.py:153} INFO - Started process (PID=2076) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:13:26,328] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:13:26,329] {logging_mixin.py:112} INFO - [2020-06-02 16:13:26,329] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:13:26,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:13:26,500] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:14:16,375] {scheduler_job.py:153} INFO - Started process (PID=2101) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:14:16,381] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:14:16,381] {logging_mixin.py:112} INFO - [2020-06-02 16:14:16,381] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:14:16,393] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:14:16,568] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.193 seconds
[2020-06-02 16:15:06,377] {scheduler_job.py:153} INFO - Started process (PID=2126) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:06,383] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:15:06,383] {logging_mixin.py:112} INFO - [2020-06-02 16:15:06,383] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:06,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:06,512] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.135 seconds
[2020-06-02 16:15:56,410] {scheduler_job.py:153} INFO - Started process (PID=2151) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:56,415] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:15:56,416] {logging_mixin.py:112} INFO - [2020-06-02 16:15:56,416] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:56,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:15:56,655] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:16:46,434] {scheduler_job.py:153} INFO - Started process (PID=2176) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:16:46,440] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:16:46,440] {logging_mixin.py:112} INFO - [2020-06-02 16:16:46,440] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:16:46,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:16:46,581] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.147 seconds
[2020-06-02 16:17:36,462] {scheduler_job.py:153} INFO - Started process (PID=2201) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:17:36,467] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:17:36,468] {logging_mixin.py:112} INFO - [2020-06-02 16:17:36,468] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:17:36,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:17:36,633] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.171 seconds
[2020-06-02 16:18:26,490] {scheduler_job.py:153} INFO - Started process (PID=2226) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:18:26,496] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:18:26,497] {logging_mixin.py:112} INFO - [2020-06-02 16:18:26,496] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:18:26,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:18:26,676] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:19:16,546] {scheduler_job.py:153} INFO - Started process (PID=2251) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:19:16,553] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:19:16,553] {logging_mixin.py:112} INFO - [2020-06-02 16:19:16,553] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:19:16,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:19:16,677] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.131 seconds
[2020-06-02 16:20:06,549] {scheduler_job.py:153} INFO - Started process (PID=2276) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:06,555] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:20:06,555] {logging_mixin.py:112} INFO - [2020-06-02 16:20:06,555] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:06,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:06,732] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.184 seconds
[2020-06-02 16:20:56,579] {scheduler_job.py:153} INFO - Started process (PID=2301) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:56,585] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:20:56,586] {logging_mixin.py:112} INFO - [2020-06-02 16:20:56,586] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:56,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:20:56,763] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:21:46,607] {scheduler_job.py:153} INFO - Started process (PID=2326) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:21:46,613] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:21:46,613] {logging_mixin.py:112} INFO - [2020-06-02 16:21:46,613] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:21:46,625] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:21:46,764] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.157 seconds
[2020-06-02 16:22:36,633] {scheduler_job.py:153} INFO - Started process (PID=2351) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:22:36,639] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:22:36,639] {logging_mixin.py:112} INFO - [2020-06-02 16:22:36,639] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:22:36,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:22:36,785] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.152 seconds
[2020-06-02 16:23:26,660] {scheduler_job.py:153} INFO - Started process (PID=2376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:23:26,666] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:23:26,666] {logging_mixin.py:112} INFO - [2020-06-02 16:23:26,666] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:23:26,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:23:26,829] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:24:16,716] {scheduler_job.py:153} INFO - Started process (PID=2401) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:24:16,722] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:24:16,723] {logging_mixin.py:112} INFO - [2020-06-02 16:24:16,723] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:24:16,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:24:16,852] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.136 seconds
[2020-06-02 16:25:06,714] {scheduler_job.py:153} INFO - Started process (PID=2426) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:06,720] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:25:06,721] {logging_mixin.py:112} INFO - [2020-06-02 16:25:06,721] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:06,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:06,841] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.127 seconds
[2020-06-02 16:25:56,745] {scheduler_job.py:153} INFO - Started process (PID=2451) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:56,751] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:25:56,751] {logging_mixin.py:112} INFO - [2020-06-02 16:25:56,751] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:56,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:25:56,908] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.163 seconds
[2020-06-02 16:26:46,775] {scheduler_job.py:153} INFO - Started process (PID=2476) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:26:46,781] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:26:46,781] {logging_mixin.py:112} INFO - [2020-06-02 16:26:46,781] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:26:46,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:26:46,919] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.144 seconds
[2020-06-02 16:27:36,799] {scheduler_job.py:153} INFO - Started process (PID=2501) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:27:36,805] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:27:36,805] {logging_mixin.py:112} INFO - [2020-06-02 16:27:36,805] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:27:36,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:27:36,942] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.143 seconds
[2020-06-02 16:28:26,829] {scheduler_job.py:153} INFO - Started process (PID=2526) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:28:26,835] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:28:26,836] {logging_mixin.py:112} INFO - [2020-06-02 16:28:26,836] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:28:26,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:28:27,004] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:29:16,898] {scheduler_job.py:153} INFO - Started process (PID=2551) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:29:16,903] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:29:16,904] {logging_mixin.py:112} INFO - [2020-06-02 16:29:16,904] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:29:16,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:29:17,028] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.130 seconds
[2020-06-02 16:30:06,886] {scheduler_job.py:153} INFO - Started process (PID=2576) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:06,893] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:30:06,894] {logging_mixin.py:112} INFO - [2020-06-02 16:30:06,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:06,905] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:07,076] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.189 seconds
[2020-06-02 16:30:56,912] {scheduler_job.py:153} INFO - Started process (PID=2601) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:56,917] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:30:56,918] {logging_mixin.py:112} INFO - [2020-06-02 16:30:56,918] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:56,930] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:30:57,170] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:31:46,941] {scheduler_job.py:153} INFO - Started process (PID=2626) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:31:46,947] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:31:46,948] {logging_mixin.py:112} INFO - [2020-06-02 16:31:46,947] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:31:46,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:31:47,137] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.196 seconds
[2020-06-02 16:32:36,967] {scheduler_job.py:153} INFO - Started process (PID=2651) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:32:36,972] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:32:36,973] {logging_mixin.py:112} INFO - [2020-06-02 16:32:36,973] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:32:36,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:32:37,106] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.139 seconds
[2020-06-02 16:33:26,996] {scheduler_job.py:153} INFO - Started process (PID=2676) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:33:27,002] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:33:27,003] {logging_mixin.py:112} INFO - [2020-06-02 16:33:27,003] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:33:27,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:33:27,170] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:34:17,066] {scheduler_job.py:153} INFO - Started process (PID=2701) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:34:17,071] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:34:17,072] {logging_mixin.py:112} INFO - [2020-06-02 16:34:17,072] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:34:17,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:34:17,203] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.137 seconds
[2020-06-02 16:35:07,056] {scheduler_job.py:153} INFO - Started process (PID=2726) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:07,061] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:35:07,062] {logging_mixin.py:112} INFO - [2020-06-02 16:35:07,062] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:07,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:07,285] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.229 seconds
[2020-06-02 16:35:57,090] {scheduler_job.py:153} INFO - Started process (PID=2751) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:57,097] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:35:57,097] {logging_mixin.py:112} INFO - [2020-06-02 16:35:57,097] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:57,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:35:57,280] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:36:47,119] {scheduler_job.py:153} INFO - Started process (PID=2776) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:36:47,125] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:36:47,126] {logging_mixin.py:112} INFO - [2020-06-02 16:36:47,125] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:36:47,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:36:47,337] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.217 seconds
[2020-06-02 16:37:37,150] {scheduler_job.py:153} INFO - Started process (PID=2801) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:37:37,155] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:37:37,156] {logging_mixin.py:112} INFO - [2020-06-02 16:37:37,156] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:37:37,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:37:37,305] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.156 seconds
[2020-06-02 16:38:27,176] {scheduler_job.py:153} INFO - Started process (PID=2826) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:38:27,181] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:38:27,182] {logging_mixin.py:112} INFO - [2020-06-02 16:38:27,182] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:38:27,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:38:27,335] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:39:17,239] {scheduler_job.py:153} INFO - Started process (PID=2851) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:39:17,244] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:39:17,245] {logging_mixin.py:112} INFO - [2020-06-02 16:39:17,245] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:39:17,257] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:39:17,380] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.142 seconds
[2020-06-02 16:40:07,228] {scheduler_job.py:153} INFO - Started process (PID=2876) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:07,233] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:40:07,234] {logging_mixin.py:112} INFO - [2020-06-02 16:40:07,234] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:07,247] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:07,393] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.166 seconds
[2020-06-02 16:40:57,256] {scheduler_job.py:153} INFO - Started process (PID=2901) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:57,263] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:40:57,263] {logging_mixin.py:112} INFO - [2020-06-02 16:40:57,263] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:57,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:40:57,445] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:41:47,295] {scheduler_job.py:153} INFO - Started process (PID=2926) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:41:47,302] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:41:47,303] {logging_mixin.py:112} INFO - [2020-06-02 16:41:47,303] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:41:47,315] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:41:47,690] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.395 seconds
[2020-06-02 16:45:11,851] {scheduler_job.py:153} INFO - Started process (PID=2955) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:45:11,857] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-02 16:45:11,857] {logging_mixin.py:112} INFO - [2020-06-02 16:45:11,857] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:45:11,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-02 16:45:12,130] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 14:51:42,208] {scheduler_job.py:153} INFO - Started process (PID=154) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:51:42,224] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:51:42,225] {logging_mixin.py:112} INFO - [2020-06-03 14:51:42,225] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:51:42,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:51:42,498] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.290 seconds
[2020-06-03 14:52:32,278] {scheduler_job.py:153} INFO - Started process (PID=181) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:52:32,284] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:52:32,284] {logging_mixin.py:112} INFO - [2020-06-03 14:52:32,284] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:52:32,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:52:32,550] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.272 seconds
[2020-06-03 14:54:02,860] {scheduler_job.py:153} INFO - Started process (PID=233) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:54:02,868] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:54:02,869] {logging_mixin.py:112} INFO - [2020-06-03 14:54:02,869] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:54:03,072] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:54:03,181] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.321 seconds
[2020-06-03 14:55:17,540] {scheduler_job.py:153} INFO - Started process (PID=272) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:55:17,545] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:55:17,545] {logging_mixin.py:112} INFO - [2020-06-03 14:55:17,545] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:55:17,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:55:17,791] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.251 seconds
[2020-06-03 14:56:42,163] {scheduler_job.py:153} INFO - Started process (PID=312) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:56:42,169] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:56:42,169] {logging_mixin.py:112} INFO - [2020-06-03 14:56:42,169] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:56:42,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:56:42,413] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.250 seconds
[2020-06-03 14:58:02,471] {scheduler_job.py:153} INFO - Started process (PID=351) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:02,495] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:58:02,496] {logging_mixin.py:112} INFO - [2020-06-03 14:58:02,495] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:02,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:03,091] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.620 seconds
[2020-06-03 14:58:52,807] {scheduler_job.py:153} INFO - Started process (PID=378) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:52,813] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:58:52,813] {logging_mixin.py:112} INFO - [2020-06-03 14:58:52,813] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:52,827] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:58:53,144] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 14:59:42,945] {scheduler_job.py:153} INFO - Started process (PID=404) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:59:42,973] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 14:59:42,974] {logging_mixin.py:112} INFO - [2020-06-03 14:59:42,974] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:59:42,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 14:59:43,222] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.277 seconds
[2020-06-03 15:00:34,931] {scheduler_job.py:153} INFO - Started process (PID=431) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:00:35,178] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:00:35,179] {logging_mixin.py:112} INFO - [2020-06-03 15:00:35,179] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:00:35,240] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:00:36,415] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 1.484 seconds
[2020-06-03 15:01:25,087] {scheduler_job.py:153} INFO - Started process (PID=457) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:01:25,093] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:01:25,094] {logging_mixin.py:112} INFO - [2020-06-03 15:01:25,093] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:01:25,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:01:25,715] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:02:16,237] {scheduler_job.py:153} INFO - Started process (PID=483) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:02:16,243] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:02:16,245] {logging_mixin.py:112} INFO - [2020-06-03 15:02:16,244] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:02:16,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:02:16,652] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.415 seconds
[2020-06-03 15:03:06,329] {scheduler_job.py:153} INFO - Started process (PID=510) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:06,346] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:03:06,347] {logging_mixin.py:112} INFO - [2020-06-03 15:03:06,347] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:06,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:06,815] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.486 seconds
[2020-06-03 15:03:56,974] {scheduler_job.py:153} INFO - Started process (PID=536) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:56,984] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:03:56,985] {logging_mixin.py:112} INFO - [2020-06-03 15:03:56,984] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:57,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:03:57,218] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.244 seconds
[2020-06-03 15:04:47,041] {scheduler_job.py:153} INFO - Started process (PID=563) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:04:47,048] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:04:47,049] {logging_mixin.py:112} INFO - [2020-06-03 15:04:47,049] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:04:47,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:04:47,316] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.276 seconds
[2020-06-03 15:05:37,123] {scheduler_job.py:153} INFO - Started process (PID=589) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:05:37,129] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:05:37,130] {logging_mixin.py:112} INFO - [2020-06-03 15:05:37,130] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:05:37,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:05:37,284] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.162 seconds
[2020-06-03 15:06:27,286] {scheduler_job.py:153} INFO - Started process (PID=616) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:06:27,292] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:06:27,293] {logging_mixin.py:112} INFO - [2020-06-03 15:06:27,293] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:06:27,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:06:27,448] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.162 seconds
[2020-06-03 15:07:17,373] {scheduler_job.py:153} INFO - Started process (PID=642) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:07:17,380] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:07:17,381] {logging_mixin.py:112} INFO - [2020-06-03 15:07:17,381] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:07:17,393] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:07:17,524] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.151 seconds
[2020-06-03 15:08:07,445] {scheduler_job.py:153} INFO - Started process (PID=669) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:07,452] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:08:07,453] {logging_mixin.py:112} INFO - [2020-06-03 15:08:07,452] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:07,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:07,608] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.163 seconds
[2020-06-03 15:08:57,560] {scheduler_job.py:153} INFO - Started process (PID=695) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:57,566] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:08:57,567] {logging_mixin.py:112} INFO - [2020-06-03 15:08:57,567] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:57,580] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:08:57,746] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:10:23,834] {scheduler_job.py:153} INFO - Started process (PID=732) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:10:23,846] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:10:23,847] {logging_mixin.py:112} INFO - [2020-06-03 15:10:23,846] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:10:23,859] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:10:24,157] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.323 seconds
[2020-06-03 15:11:13,908] {scheduler_job.py:153} INFO - Started process (PID=759) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:11:13,915] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:11:13,915] {logging_mixin.py:112} INFO - [2020-06-03 15:11:13,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:11:14,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:11:14,202] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.294 seconds
[2020-06-03 15:12:03,991] {scheduler_job.py:153} INFO - Started process (PID=785) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:12:03,997] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:12:03,998] {logging_mixin.py:112} INFO - [2020-06-03 15:12:03,998] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:12:04,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:12:04,342] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.350 seconds
[2020-06-03 15:13:19,650] {scheduler_job.py:153} INFO - Started process (PID=825) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:13:19,655] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:13:19,656] {logging_mixin.py:112} INFO - [2020-06-03 15:13:19,655] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:13:19,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:13:19,931] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.281 seconds
[2020-06-03 15:14:44,493] {scheduler_job.py:153} INFO - Started process (PID=864) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:14:44,498] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:14:44,498] {logging_mixin.py:112} INFO - [2020-06-03 15:14:44,498] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:14:44,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:14:44,775] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.283 seconds
[2020-06-03 15:15:34,557] {scheduler_job.py:153} INFO - Started process (PID=891) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:15:34,562] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:15:34,563] {logging_mixin.py:112} INFO - [2020-06-03 15:15:34,563] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:15:34,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:15:34,731] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.174 seconds
[2020-06-03 15:16:58,125] {scheduler_job.py:153} INFO - Started process (PID=931) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:16:58,131] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:16:58,132] {logging_mixin.py:112} INFO - [2020-06-03 15:16:58,132] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:16:58,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:16:58,283] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.157 seconds
[2020-06-03 15:17:48,142] {scheduler_job.py:153} INFO - Started process (PID=957) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:17:48,149] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:17:48,149] {logging_mixin.py:112} INFO - [2020-06-03 15:17:48,149] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:17:48,160] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:17:48,287] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.145 seconds
[2020-06-03 15:18:38,181] {scheduler_job.py:153} INFO - Started process (PID=984) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:18:38,186] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:18:38,187] {logging_mixin.py:112} INFO - [2020-06-03 15:18:38,187] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:18:38,199] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:18:38,331] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:19:28,193] {scheduler_job.py:153} INFO - Started process (PID=1010) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:19:28,198] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:19:28,199] {logging_mixin.py:112} INFO - [2020-06-03 15:19:28,199] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:19:28,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:19:28,347] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.155 seconds
[2020-06-03 15:20:18,214] {scheduler_job.py:153} INFO - Started process (PID=1037) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:20:18,219] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:20:18,220] {logging_mixin.py:112} INFO - [2020-06-03 15:20:18,220] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:20:18,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:20:18,364] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.150 seconds
[2020-06-03 15:21:08,271] {scheduler_job.py:153} INFO - Started process (PID=1064) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:08,276] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:21:08,277] {logging_mixin.py:112} INFO - [2020-06-03 15:21:08,277] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:08,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:08,453] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:21:32,434] {scheduler_job.py:153} INFO - Started process (PID=1080) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:32,439] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:21:32,440] {logging_mixin.py:112} INFO - [2020-06-03 15:21:32,440] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:32,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:21:32,752] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.319 seconds
[2020-06-03 15:22:22,522] {scheduler_job.py:153} INFO - Started process (PID=1107) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:22:22,527] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:22:22,527] {logging_mixin.py:112} INFO - [2020-06-03 15:22:22,527] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:22:22,672] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:22:22,784] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.262 seconds
[2020-06-03 15:23:12,609] {scheduler_job.py:153} INFO - Started process (PID=1134) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:23:12,615] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:23:12,616] {logging_mixin.py:112} INFO - [2020-06-03 15:23:12,616] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:23:12,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:23:12,908] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.299 seconds
[2020-06-03 15:24:14,609] {scheduler_job.py:153} INFO - Started process (PID=1167) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:24:14,616] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:24:14,617] {logging_mixin.py:112} INFO - [2020-06-03 15:24:14,617] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:24:14,813] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:24:14,936] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.327 seconds
[2020-06-03 15:25:22,014] {scheduler_job.py:153} INFO - Started process (PID=1200) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:25:22,019] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:25:22,020] {logging_mixin.py:112} INFO - [2020-06-03 15:25:22,020] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:25:22,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:25:22,284] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.270 seconds
[2020-06-03 15:26:24,340] {scheduler_job.py:153} INFO - Started process (PID=1233) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:26:24,347] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:26:24,347] {logging_mixin.py:112} INFO - [2020-06-03 15:26:24,347] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:26:24,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:26:24,487] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.147 seconds
[2020-06-03 15:27:14,251] {scheduler_job.py:153} INFO - Started process (PID=1259) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:27:14,256] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:27:14,257] {logging_mixin.py:112} INFO - [2020-06-03 15:27:14,257] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:27:14,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:27:14,438] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.187 seconds
[2020-06-03 15:28:04,318] {scheduler_job.py:153} INFO - Started process (PID=1286) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:04,327] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:28:04,328] {logging_mixin.py:112} INFO - [2020-06-03 15:28:04,328] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:04,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:04,630] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.311 seconds
[2020-06-03 15:28:54,322] {scheduler_job.py:153} INFO - Started process (PID=1312) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:54,327] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:28:54,328] {logging_mixin.py:112} INFO - [2020-06-03 15:28:54,328] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:54,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:28:54,517] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:29:44,372] {scheduler_job.py:153} INFO - Started process (PID=1339) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:29:44,377] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py for tasks to queue
[2020-06-03 15:29:44,378] {logging_mixin.py:112} INFO - [2020-06-03 15:29:44,378] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:29:44,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_http_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py
[2020-06-03 15:29:44,506] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_http_operator.py took 0.134 seconds
