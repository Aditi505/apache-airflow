[2020-05-31 21:01:13,601] {scheduler_job.py:153} INFO - Started process (PID=6091) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:01:13,607] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:01:13,607] {logging_mixin.py:112} INFO - [2020-05-31 21:01:13,607] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:01:13,618] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:01:13,792] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.191 seconds
[2020-05-31 21:02:01,564] {scheduler_job.py:153} INFO - Started process (PID=6123) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:01,569] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:02:01,569] {logging_mixin.py:112} INFO - [2020-05-31 21:02:01,569] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:01,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:01,739] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:02:49,638] {scheduler_job.py:153} INFO - Started process (PID=6155) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:49,643] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:02:49,644] {logging_mixin.py:112} INFO - [2020-05-31 21:02:49,644] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:49,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:02:49,767] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.130 seconds
[2020-05-31 21:03:37,609] {scheduler_job.py:153} INFO - Started process (PID=6183) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:03:37,614] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:03:37,615] {logging_mixin.py:112} INFO - [2020-05-31 21:03:37,614] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:03:37,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:03:37,780] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:04:25,632] {scheduler_job.py:153} INFO - Started process (PID=6215) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:04:25,637] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:04:25,637] {logging_mixin.py:112} INFO - [2020-05-31 21:04:25,637] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:04:25,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:04:25,824] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:05:13,655] {scheduler_job.py:153} INFO - Started process (PID=6243) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:05:13,660] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:05:13,660] {logging_mixin.py:112} INFO - [2020-05-31 21:05:13,660] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:05:13,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:05:13,834] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:06:01,680] {scheduler_job.py:153} INFO - Started process (PID=6275) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:01,686] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:06:01,687] {logging_mixin.py:112} INFO - [2020-05-31 21:06:01,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:01,695] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:01,890] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:06:49,704] {scheduler_job.py:153} INFO - Started process (PID=6303) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:49,709] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:06:49,709] {logging_mixin.py:112} INFO - [2020-05-31 21:06:49,709] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:49,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:06:49,889] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:07:37,727] {scheduler_job.py:153} INFO - Started process (PID=6335) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:07:37,732] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:07:37,733] {logging_mixin.py:112} INFO - [2020-05-31 21:07:37,733] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:07:37,746] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:07:37,922] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:08:25,755] {scheduler_job.py:153} INFO - Started process (PID=6363) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:08:25,760] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:08:25,760] {logging_mixin.py:112} INFO - [2020-05-31 21:08:25,760] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:08:25,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:08:25,967] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:13,778] {scheduler_job.py:153} INFO - Started process (PID=6395) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:09:13,783] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:09:13,784] {logging_mixin.py:112} INFO - [2020-05-31 21:09:13,784] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:09:13,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:09:13,920] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.142 seconds
[2020-05-31 21:10:01,801] {scheduler_job.py:153} INFO - Started process (PID=6423) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:01,806] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:10:01,806] {logging_mixin.py:112} INFO - [2020-05-31 21:10:01,806] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:01,820] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:01,966] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:10:49,825] {scheduler_job.py:153} INFO - Started process (PID=6455) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:49,830] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:10:49,831] {logging_mixin.py:112} INFO - [2020-05-31 21:10:49,831] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:49,845] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:10:50,010] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:11:37,852] {scheduler_job.py:153} INFO - Started process (PID=6483) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:11:37,857] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:11:37,858] {logging_mixin.py:112} INFO - [2020-05-31 21:11:37,858] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:11:37,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:11:38,009] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:12:25,875] {scheduler_job.py:153} INFO - Started process (PID=6515) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:12:25,880] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:12:25,881] {logging_mixin.py:112} INFO - [2020-05-31 21:12:25,881] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:12:25,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:12:26,008] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.133 seconds
[2020-05-31 21:13:13,898] {scheduler_job.py:153} INFO - Started process (PID=6543) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:13:13,903] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:13:13,903] {logging_mixin.py:112} INFO - [2020-05-31 21:13:13,903] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:13:13,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:13:14,088] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:14:01,922] {scheduler_job.py:153} INFO - Started process (PID=6575) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:01,927] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:14:01,927] {logging_mixin.py:112} INFO - [2020-05-31 21:14:01,927] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:01,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:02,085] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.164 seconds
[2020-05-31 21:14:49,948] {scheduler_job.py:153} INFO - Started process (PID=6604) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:49,955] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:14:49,956] {logging_mixin.py:112} INFO - [2020-05-31 21:14:49,956] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:49,968] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:14:50,130] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:15:37,995] {scheduler_job.py:153} INFO - Started process (PID=6635) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:15:38,001] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:15:38,002] {logging_mixin.py:112} INFO - [2020-05-31 21:15:38,002] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:15:38,012] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:15:38,152] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:16:26,025] {scheduler_job.py:153} INFO - Started process (PID=6667) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:16:26,031] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:16:26,032] {logging_mixin.py:112} INFO - [2020-05-31 21:16:26,032] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:16:26,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:16:26,208] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:17:14,051] {scheduler_job.py:153} INFO - Started process (PID=6695) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:17:14,058] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:17:14,059] {logging_mixin.py:112} INFO - [2020-05-31 21:17:14,058] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:17:14,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:17:14,183] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.132 seconds
[2020-05-31 21:18:02,076] {scheduler_job.py:153} INFO - Started process (PID=6727) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:02,082] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:18:02,082] {logging_mixin.py:112} INFO - [2020-05-31 21:18:02,082] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:02,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:02,251] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:18:50,102] {scheduler_job.py:153} INFO - Started process (PID=6755) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:50,108] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:18:50,109] {logging_mixin.py:112} INFO - [2020-05-31 21:18:50,109] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:50,118] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:18:50,285] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:19:38,136] {scheduler_job.py:153} INFO - Started process (PID=6787) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:19:38,142] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:19:38,143] {logging_mixin.py:112} INFO - [2020-05-31 21:19:38,143] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:19:38,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:19:38,429] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:20:26,185] {scheduler_job.py:153} INFO - Started process (PID=6815) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:20:26,193] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:20:26,194] {logging_mixin.py:112} INFO - [2020-05-31 21:20:26,194] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:20:26,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:20:26,376] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.191 seconds
[2020-05-31 21:21:14,233] {scheduler_job.py:153} INFO - Started process (PID=6847) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:21:14,244] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:21:14,244] {logging_mixin.py:112} INFO - [2020-05-31 21:21:14,244] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:21:14,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:21:14,411] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.177 seconds
[2020-05-31 21:22:02,217] {scheduler_job.py:153} INFO - Started process (PID=6875) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:02,222] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:22:02,224] {logging_mixin.py:112} INFO - [2020-05-31 21:22:02,223] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:02,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:02,505] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:22:50,256] {scheduler_job.py:153} INFO - Started process (PID=6907) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:50,264] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:22:50,266] {logging_mixin.py:112} INFO - [2020-05-31 21:22:50,265] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:50,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:22:50,427] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:23:38,268] {scheduler_job.py:153} INFO - Started process (PID=6935) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:23:38,273] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:23:38,273] {logging_mixin.py:112} INFO - [2020-05-31 21:23:38,273] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:23:38,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:23:38,545] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:24:26,293] {scheduler_job.py:153} INFO - Started process (PID=6967) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:24:26,298] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:24:26,299] {logging_mixin.py:112} INFO - [2020-05-31 21:24:26,299] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:24:26,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:24:26,437] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:14,320] {scheduler_job.py:153} INFO - Started process (PID=6995) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:25:14,325] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:25:14,326] {logging_mixin.py:112} INFO - [2020-05-31 21:25:14,326] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:25:14,336] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:25:14,481] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:26:02,346] {scheduler_job.py:153} INFO - Started process (PID=7027) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:02,352] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:26:02,352] {logging_mixin.py:112} INFO - [2020-05-31 21:26:02,352] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:02,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:02,514] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:26:50,373] {scheduler_job.py:153} INFO - Started process (PID=7055) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:50,379] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:26:50,379] {logging_mixin.py:112} INFO - [2020-05-31 21:26:50,379] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:50,389] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:26:50,525] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:27:38,399] {scheduler_job.py:153} INFO - Started process (PID=7087) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:27:38,405] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:27:38,405] {logging_mixin.py:112} INFO - [2020-05-31 21:27:38,405] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:27:38,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:27:38,569] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:28:26,422] {scheduler_job.py:153} INFO - Started process (PID=7115) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:28:26,428] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:28:26,429] {logging_mixin.py:112} INFO - [2020-05-31 21:28:26,429] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:28:26,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:28:26,569] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:14,445] {scheduler_job.py:153} INFO - Started process (PID=7147) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:29:14,451] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:29:14,452] {logging_mixin.py:112} INFO - [2020-05-31 21:29:14,451] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:29:14,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:29:14,601] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:30:02,482] {scheduler_job.py:153} INFO - Started process (PID=7179) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:02,489] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:30:02,490] {logging_mixin.py:112} INFO - [2020-05-31 21:30:02,490] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:02,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:02,867] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:30:50,499] {scheduler_job.py:153} INFO - Started process (PID=7207) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:50,504] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:30:50,524] {logging_mixin.py:112} INFO - [2020-05-31 21:30:50,524] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:50,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:30:50,701] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:31:38,528] {scheduler_job.py:153} INFO - Started process (PID=7239) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:31:38,534] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:31:38,534] {logging_mixin.py:112} INFO - [2020-05-31 21:31:38,534] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:31:38,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:31:38,679] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:32:26,552] {scheduler_job.py:153} INFO - Started process (PID=7267) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:32:26,557] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:32:26,558] {logging_mixin.py:112} INFO - [2020-05-31 21:32:26,558] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:32:26,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:32:26,700] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.148 seconds
[2020-05-31 21:33:14,575] {scheduler_job.py:153} INFO - Started process (PID=7299) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:33:14,580] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:33:14,581] {logging_mixin.py:112} INFO - [2020-05-31 21:33:14,580] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:33:14,591] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:33:14,722] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:34:02,598] {scheduler_job.py:153} INFO - Started process (PID=7327) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:02,604] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:34:02,605] {logging_mixin.py:112} INFO - [2020-05-31 21:34:02,605] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:02,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:02,776] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:34:50,622] {scheduler_job.py:153} INFO - Started process (PID=7359) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:50,627] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:34:50,627] {logging_mixin.py:112} INFO - [2020-05-31 21:34:50,627] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:50,637] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:34:50,778] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:35:38,643] {scheduler_job.py:153} INFO - Started process (PID=7387) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:35:38,649] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:35:38,649] {logging_mixin.py:112} INFO - [2020-05-31 21:35:38,649] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:35:38,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:35:38,788] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:36:26,665] {scheduler_job.py:153} INFO - Started process (PID=7419) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:36:26,670] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:36:26,671] {logging_mixin.py:112} INFO - [2020-05-31 21:36:26,671] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:36:26,681] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:36:26,832] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:37:14,686] {scheduler_job.py:153} INFO - Started process (PID=7447) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:37:14,691] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:37:14,691] {logging_mixin.py:112} INFO - [2020-05-31 21:37:14,691] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:37:14,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:37:14,843] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:38:02,710] {scheduler_job.py:153} INFO - Started process (PID=7479) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:02,715] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:38:02,716] {logging_mixin.py:112} INFO - [2020-05-31 21:38:02,716] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:02,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:02,876] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:38:50,731] {scheduler_job.py:153} INFO - Started process (PID=7507) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:50,736] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:38:50,737] {logging_mixin.py:112} INFO - [2020-05-31 21:38:50,737] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:50,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:38:50,865] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:39:38,756] {scheduler_job.py:153} INFO - Started process (PID=7539) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:39:38,762] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:39:38,763] {logging_mixin.py:112} INFO - [2020-05-31 21:39:38,763] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:39:38,772] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:39:38,909] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:40:26,778] {scheduler_job.py:153} INFO - Started process (PID=7567) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:40:26,784] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:40:26,785] {logging_mixin.py:112} INFO - [2020-05-31 21:40:26,785] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:40:26,794] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:40:26,952] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:14,820] {scheduler_job.py:153} INFO - Started process (PID=7599) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:41:14,826] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:41:14,826] {logging_mixin.py:112} INFO - [2020-05-31 21:41:14,826] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:41:14,836] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:41:14,995] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.175 seconds
[2020-05-31 21:42:02,822] {scheduler_job.py:153} INFO - Started process (PID=7627) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:02,827] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:42:02,828] {logging_mixin.py:112} INFO - [2020-05-31 21:42:02,827] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:02,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:03,007] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:42:50,843] {scheduler_job.py:153} INFO - Started process (PID=7659) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:50,849] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:42:50,849] {logging_mixin.py:112} INFO - [2020-05-31 21:42:50,849] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:50,859] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:42:51,007] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:43:38,868] {scheduler_job.py:153} INFO - Started process (PID=7691) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:43:38,874] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:43:38,874] {logging_mixin.py:112} INFO - [2020-05-31 21:43:38,874] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:43:38,884] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:43:39,029] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:44:26,893] {scheduler_job.py:153} INFO - Started process (PID=7719) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:44:26,898] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:44:26,899] {logging_mixin.py:112} INFO - [2020-05-31 21:44:26,899] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:44:26,909] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:44:27,051] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:45:14,912] {scheduler_job.py:153} INFO - Started process (PID=7751) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:45:14,917] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:45:14,919] {logging_mixin.py:112} INFO - [2020-05-31 21:45:14,918] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:45:14,930] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:45:15,095] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:46:02,936] {scheduler_job.py:153} INFO - Started process (PID=7779) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:02,943] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:46:02,943] {logging_mixin.py:112} INFO - [2020-05-31 21:46:02,943] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:02,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:03,084] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:46:50,960] {scheduler_job.py:153} INFO - Started process (PID=7811) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:50,966] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:46:50,967] {logging_mixin.py:112} INFO - [2020-05-31 21:46:50,967] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:50,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:46:51,150] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:47:38,982] {scheduler_job.py:153} INFO - Started process (PID=7839) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:47:38,987] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:47:38,987] {logging_mixin.py:112} INFO - [2020-05-31 21:47:38,987] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:47:38,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:47:39,161] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:48:27,019] {scheduler_job.py:153} INFO - Started process (PID=7871) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:48:27,024] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:48:27,025] {logging_mixin.py:112} INFO - [2020-05-31 21:48:27,025] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:48:27,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:48:27,228] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:15,063] {scheduler_job.py:153} INFO - Started process (PID=7899) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:49:15,068] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:49:15,069] {logging_mixin.py:112} INFO - [2020-05-31 21:49:15,069] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:49:15,078] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:49:15,261] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:50:03,123] {scheduler_job.py:153} INFO - Started process (PID=7931) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:03,128] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:50:03,129] {logging_mixin.py:112} INFO - [2020-05-31 21:50:03,128] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:03,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:03,294] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:50:51,172] {scheduler_job.py:153} INFO - Started process (PID=7959) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:51,177] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:50:51,178] {logging_mixin.py:112} INFO - [2020-05-31 21:50:51,178] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:51,188] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:50:51,338] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:51:39,207] {scheduler_job.py:153} INFO - Started process (PID=7991) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:51:39,213] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:51:39,214] {logging_mixin.py:112} INFO - [2020-05-31 21:51:39,214] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:51:39,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:51:39,448] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:52:27,251] {scheduler_job.py:153} INFO - Started process (PID=8019) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:52:27,256] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:52:27,257] {logging_mixin.py:112} INFO - [2020-05-31 21:52:27,257] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:52:27,266] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:52:27,404] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:15,295] {scheduler_job.py:153} INFO - Started process (PID=8051) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:53:15,300] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:53:15,301] {logging_mixin.py:112} INFO - [2020-05-31 21:53:15,300] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:53:15,310] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:53:15,505] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:54:03,339] {scheduler_job.py:153} INFO - Started process (PID=8079) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:03,345] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:54:03,345] {logging_mixin.py:112} INFO - [2020-05-31 21:54:03,345] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:03,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:03,515] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:54:51,384] {scheduler_job.py:153} INFO - Started process (PID=8111) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:51,390] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:54:51,391] {logging_mixin.py:112} INFO - [2020-05-31 21:54:51,391] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:51,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:54:51,548] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:55:39,426] {scheduler_job.py:153} INFO - Started process (PID=8139) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:55:39,431] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:55:39,432] {logging_mixin.py:112} INFO - [2020-05-31 21:55:39,431] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:55:39,441] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:55:39,593] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:56:27,479] {scheduler_job.py:153} INFO - Started process (PID=8171) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:56:27,485] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:56:27,485] {logging_mixin.py:112} INFO - [2020-05-31 21:56:27,485] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:56:27,495] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:56:27,637] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:57:15,523] {scheduler_job.py:153} INFO - Started process (PID=8203) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:57:15,529] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:57:15,530] {logging_mixin.py:112} INFO - [2020-05-31 21:57:15,529] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:57:15,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:57:15,680] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:58:03,561] {scheduler_job.py:153} INFO - Started process (PID=8231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:03,567] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:58:03,567] {logging_mixin.py:112} INFO - [2020-05-31 21:58:03,567] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:03,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:03,780] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:58:51,608] {scheduler_job.py:153} INFO - Started process (PID=8263) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:51,613] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:58:51,614] {logging_mixin.py:112} INFO - [2020-05-31 21:58:51,614] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:51,625] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:58:51,802] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:59:39,651] {scheduler_job.py:153} INFO - Started process (PID=8291) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:59:39,656] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 21:59:39,657] {logging_mixin.py:112} INFO - [2020-05-31 21:59:39,657] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:59:39,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 21:59:39,847] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:00:27,693] {scheduler_job.py:153} INFO - Started process (PID=8323) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:00:27,698] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 22:00:27,698] {logging_mixin.py:112} INFO - [2020-05-31 22:00:27,698] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:00:27,708] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:00:27,846] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.154 seconds
[2020-05-31 22:01:15,773] {scheduler_job.py:153} INFO - Started process (PID=8351) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:01:15,778] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 22:01:15,779] {logging_mixin.py:112} INFO - [2020-05-31 22:01:15,779] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:01:15,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:01:15,924] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.152 seconds
[2020-05-31 22:02:03,796] {scheduler_job.py:153} INFO - Started process (PID=8383) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:03,802] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 22:02:03,802] {logging_mixin.py:112} INFO - [2020-05-31 22:02:03,802] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:03,811] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:04,102] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:02:51,842] {scheduler_job.py:153} INFO - Started process (PID=8411) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:51,848] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 22:02:51,848] {logging_mixin.py:112} INFO - [2020-05-31 22:02:51,848] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:51,857] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:02:52,024] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:33:43,063] {scheduler_job.py:153} INFO - Started process (PID=8463) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:33:43,069] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-05-31 22:33:43,069] {logging_mixin.py:112} INFO - [2020-05-31 22:33:43,069] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:33:43,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-05-31 22:33:43,559] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.496 seconds
[2020-06-01 14:32:50,647] {scheduler_job.py:153} INFO - Started process (PID=71) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:32:50,667] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:32:50,669] {logging_mixin.py:112} INFO - [2020-06-01 14:32:50,668] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:32:50,681] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:32:50,885] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.238 seconds
[2020-06-01 14:33:38,690] {scheduler_job.py:153} INFO - Started process (PID=103) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:33:38,696] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:33:38,697] {logging_mixin.py:112} INFO - [2020-06-01 14:33:38,697] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:33:38,711] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:33:39,938] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 1.248 seconds
[2020-06-01 14:34:26,800] {scheduler_job.py:153} INFO - Started process (PID=131) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:34:26,806] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:34:26,806] {logging_mixin.py:112} INFO - [2020-06-01 14:34:26,806] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:34:26,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:34:27,854] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 1.054 seconds
[2020-06-01 14:35:15,038] {scheduler_job.py:153} INFO - Started process (PID=163) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:35:15,159] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:35:15,160] {logging_mixin.py:112} INFO - [2020-06-01 14:35:15,159] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:35:15,272] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:35:15,972] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.934 seconds
[2020-06-01 14:36:03,932] {scheduler_job.py:153} INFO - Started process (PID=188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:03,943] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:36:03,944] {logging_mixin.py:112} INFO - [2020-06-01 14:36:03,943] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:04,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:04,627] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.696 seconds
[2020-06-01 14:36:53,195] {scheduler_job.py:153} INFO - Started process (PID=219) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:53,205] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:36:53,214] {logging_mixin.py:112} INFO - [2020-06-01 14:36:53,211] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:53,235] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:36:53,506] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.314 seconds
[2020-06-01 14:37:41,240] {scheduler_job.py:153} INFO - Started process (PID=247) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:37:41,246] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:37:41,247] {logging_mixin.py:112} INFO - [2020-06-01 14:37:41,247] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:37:41,258] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:37:41,388] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.148 seconds
[2020-06-01 14:38:29,348] {scheduler_job.py:153} INFO - Started process (PID=279) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:38:29,354] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:38:29,355] {logging_mixin.py:112} INFO - [2020-06-01 14:38:29,354] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:38:29,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:38:29,584] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.236 seconds
[2020-06-01 14:39:17,392] {scheduler_job.py:153} INFO - Started process (PID=307) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:39:17,398] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:39:17,399] {logging_mixin.py:112} INFO - [2020-06-01 14:39:17,399] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:39:17,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:39:17,717] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.325 seconds
[2020-06-01 14:40:06,681] {scheduler_job.py:153} INFO - Started process (PID=355) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:40:06,686] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 14:40:06,687] {logging_mixin.py:112} INFO - [2020-06-01 14:40:06,687] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:40:06,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 14:40:06,859] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.179 seconds
[2020-06-01 15:15:19,698] {scheduler_job.py:153} INFO - Started process (PID=1110) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:15:19,709] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:15:19,710] {logging_mixin.py:112} INFO - [2020-06-01 15:15:19,710] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:15:19,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:15:19,843] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.144 seconds
[2020-06-01 15:16:09,697] {scheduler_job.py:153} INFO - Started process (PID=1139) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:09,702] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:16:09,703] {logging_mixin.py:112} INFO - [2020-06-01 15:16:09,703] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:09,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:09,900] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.202 seconds
[2020-06-01 15:16:59,743] {scheduler_job.py:153} INFO - Started process (PID=1172) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:59,748] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:16:59,749] {logging_mixin.py:112} INFO - [2020-06-01 15:16:59,748] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:59,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:16:59,886] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.143 seconds
[2020-06-01 15:17:49,852] {scheduler_job.py:153} INFO - Started process (PID=1205) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:17:49,860] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:17:49,861] {logging_mixin.py:112} INFO - [2020-06-01 15:17:49,861] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:17:49,880] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:17:50,509] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:18:39,853] {scheduler_job.py:153} INFO - Started process (PID=1234) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:18:39,859] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:18:39,859] {logging_mixin.py:112} INFO - [2020-06-01 15:18:39,859] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:18:39,869] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:18:40,012] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.159 seconds
[2020-06-01 15:19:29,886] {scheduler_job.py:153} INFO - Started process (PID=1267) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:19:29,891] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:19:29,891] {logging_mixin.py:112} INFO - [2020-06-01 15:19:29,891] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:19:29,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:19:30,041] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.155 seconds
[2020-06-01 15:20:19,929] {scheduler_job.py:153} INFO - Started process (PID=1296) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:20:19,934] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:20:19,935] {logging_mixin.py:112} INFO - [2020-06-01 15:20:19,935] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:20:19,944] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:20:20,108] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:21:09,927] {scheduler_job.py:153} INFO - Started process (PID=1329) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:21:09,932] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:21:09,933] {logging_mixin.py:112} INFO - [2020-06-01 15:21:09,933] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:21:09,942] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:21:10,100] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.173 seconds
[2020-06-01 15:21:59,975] {scheduler_job.py:153} INFO - Started process (PID=1362) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:21:59,983] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:21:59,985] {logging_mixin.py:112} INFO - [2020-06-01 15:21:59,985] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:22:00,007] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:22:00,191] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.216 seconds
[2020-06-01 15:26:51,048] {scheduler_job.py:153} INFO - Started process (PID=1415) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:26:51,057] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 15:26:51,058] {logging_mixin.py:112} INFO - [2020-06-01 15:26:51,058] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:26:51,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 15:26:51,774] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.726 seconds
[2020-06-01 17:42:14,204] {scheduler_job.py:153} INFO - Started process (PID=79) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:42:14,228] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:42:14,228] {logging_mixin.py:112} INFO - [2020-06-01 17:42:14,228] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:42:14,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:42:14,428] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.224 seconds
[2020-06-01 17:43:04,270] {scheduler_job.py:153} INFO - Started process (PID=112) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:04,276] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:43:04,276] {logging_mixin.py:112} INFO - [2020-06-01 17:43:04,276] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:04,286] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:04,400] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.130 seconds
[2020-06-01 17:43:54,335] {scheduler_job.py:153} INFO - Started process (PID=141) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:54,340] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:43:54,341] {logging_mixin.py:112} INFO - [2020-06-01 17:43:54,341] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:54,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:43:54,539] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:44:44,376] {scheduler_job.py:153} INFO - Started process (PID=174) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:44:44,381] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:44:44,381] {logging_mixin.py:112} INFO - [2020-06-01 17:44:44,381] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:44:44,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:44:44,526] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.150 seconds
[2020-06-01 17:45:34,423] {scheduler_job.py:153} INFO - Started process (PID=203) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:45:34,428] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:45:34,429] {logging_mixin.py:112} INFO - [2020-06-01 17:45:34,429] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:45:34,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:45:34,581] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.158 seconds
[2020-06-01 17:46:24,444] {scheduler_job.py:153} INFO - Started process (PID=236) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:46:24,449] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:46:24,450] {logging_mixin.py:112} INFO - [2020-06-01 17:46:24,450] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:46:24,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:46:24,638] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:47:14,502] {scheduler_job.py:153} INFO - Started process (PID=269) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:47:14,508] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:47:14,509] {logging_mixin.py:112} INFO - [2020-06-01 17:47:14,509] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:47:14,520] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:47:14,693] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.191 seconds
[2020-06-01 17:48:04,539] {scheduler_job.py:153} INFO - Started process (PID=298) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:04,544] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:48:04,545] {logging_mixin.py:112} INFO - [2020-06-01 17:48:04,545] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:04,554] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:04,680] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.140 seconds
[2020-06-01 17:48:54,624] {scheduler_job.py:153} INFO - Started process (PID=331) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:54,634] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:48:54,636] {logging_mixin.py:112} INFO - [2020-06-01 17:48:54,636] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:54,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:48:54,979] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.355 seconds
[2020-06-01 17:49:44,666] {scheduler_job.py:153} INFO - Started process (PID=360) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:49:44,671] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:49:44,672] {logging_mixin.py:112} INFO - [2020-06-01 17:49:44,672] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:49:44,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:49:44,791] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.126 seconds
[2020-06-01 17:50:34,758] {scheduler_job.py:153} INFO - Started process (PID=393) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:50:34,764] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:50:34,764] {logging_mixin.py:112} INFO - [2020-06-01 17:50:34,764] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:50:34,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:50:34,948] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.190 seconds
[2020-06-01 17:51:24,861] {scheduler_job.py:153} INFO - Started process (PID=422) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:51:24,866] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:51:24,867] {logging_mixin.py:112} INFO - [2020-06-01 17:51:24,867] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:51:24,881] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:51:25,035] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:52:14,913] {scheduler_job.py:153} INFO - Started process (PID=455) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:52:14,918] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:52:14,919] {logging_mixin.py:112} INFO - [2020-06-01 17:52:14,918] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:52:14,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:52:15,047] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.135 seconds
[2020-06-01 17:53:04,997] {scheduler_job.py:153} INFO - Started process (PID=484) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:05,003] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:53:05,004] {logging_mixin.py:112} INFO - [2020-06-01 17:53:05,004] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:05,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:05,160] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.163 seconds
[2020-06-01 17:53:55,092] {scheduler_job.py:153} INFO - Started process (PID=517) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:55,097] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:53:55,098] {logging_mixin.py:112} INFO - [2020-06-01 17:53:55,098] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:55,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:53:55,224] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:54:45,193] {scheduler_job.py:153} INFO - Started process (PID=550) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:54:45,198] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:54:45,199] {logging_mixin.py:112} INFO - [2020-06-01 17:54:45,199] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:54:45,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:54:45,401] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.208 seconds
[2020-06-01 17:55:35,298] {scheduler_job.py:153} INFO - Started process (PID=579) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:55:35,303] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:55:35,304] {logging_mixin.py:112} INFO - [2020-06-01 17:55:35,303] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:55:35,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:55:35,466] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.168 seconds
[2020-06-01 17:56:25,391] {scheduler_job.py:153} INFO - Started process (PID=612) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:56:25,395] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:56:25,396] {logging_mixin.py:112} INFO - [2020-06-01 17:56:25,396] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:56:25,406] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:56:25,577] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:57:15,469] {scheduler_job.py:153} INFO - Started process (PID=641) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:57:15,474] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:57:15,475] {logging_mixin.py:112} INFO - [2020-06-01 17:57:15,475] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:57:15,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:57:15,602] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.133 seconds
[2020-06-01 17:58:05,542] {scheduler_job.py:153} INFO - Started process (PID=674) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:05,547] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:58:05,548] {logging_mixin.py:112} INFO - [2020-06-01 17:58:05,548] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:05,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:05,723] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.181 seconds
[2020-06-01 17:58:55,638] {scheduler_job.py:153} INFO - Started process (PID=703) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:55,643] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:58:55,644] {logging_mixin.py:112} INFO - [2020-06-01 17:58:55,644] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:55,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:58:55,811] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:59:45,731] {scheduler_job.py:153} INFO - Started process (PID=736) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:59:45,738] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 17:59:45,738] {logging_mixin.py:112} INFO - [2020-06-01 17:59:45,738] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:59:45,749] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 17:59:45,887] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.156 seconds
[2020-06-01 18:00:35,885] {scheduler_job.py:153} INFO - Started process (PID=769) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:00:35,890] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:00:35,891] {logging_mixin.py:112} INFO - [2020-06-01 18:00:35,891] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:00:35,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:00:36,066] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.181 seconds
[2020-06-01 18:01:26,011] {scheduler_job.py:153} INFO - Started process (PID=798) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:01:26,021] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:01:26,022] {logging_mixin.py:112} INFO - [2020-06-01 18:01:26,021] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:01:26,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:01:26,188] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:02:16,040] {scheduler_job.py:153} INFO - Started process (PID=831) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:02:16,047] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:02:16,048] {logging_mixin.py:112} INFO - [2020-06-01 18:02:16,047] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:02:16,059] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:02:16,263] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.223 seconds
[2020-06-01 18:03:06,049] {scheduler_job.py:153} INFO - Started process (PID=860) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:06,054] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:03:06,055] {logging_mixin.py:112} INFO - [2020-06-01 18:03:06,054] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:06,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:06,208] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.159 seconds
[2020-06-01 18:03:56,070] {scheduler_job.py:153} INFO - Started process (PID=893) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:56,075] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:03:56,076] {logging_mixin.py:112} INFO - [2020-06-01 18:03:56,075] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:56,085] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:03:56,241] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:04:46,114] {scheduler_job.py:153} INFO - Started process (PID=922) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:04:46,119] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:04:46,120] {logging_mixin.py:112} INFO - [2020-06-01 18:04:46,119] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:04:46,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:04:46,252] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.139 seconds
[2020-06-01 18:05:36,125] {scheduler_job.py:153} INFO - Started process (PID=955) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:05:36,131] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:05:36,132] {logging_mixin.py:112} INFO - [2020-06-01 18:05:36,132] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:05:36,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:05:36,273] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.148 seconds
[2020-06-01 18:07:03,033] {scheduler_job.py:153} INFO - Started process (PID=1006) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:07:03,039] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:07:03,040] {logging_mixin.py:112} INFO - [2020-06-01 18:07:03,039] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:07:03,050] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:07:03,173] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:08:32,445] {scheduler_job.py:153} INFO - Started process (PID=1078) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:08:32,452] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:08:32,453] {logging_mixin.py:112} INFO - [2020-06-01 18:08:32,453] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:08:32,464] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:08:32,605] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:09:22,885] {scheduler_job.py:153} INFO - Started process (PID=1111) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:09:22,916] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:09:22,917] {logging_mixin.py:112} INFO - [2020-06-01 18:09:22,916] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:09:22,944] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:09:23,132] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.247 seconds
[2020-06-01 18:10:12,878] {scheduler_job.py:153} INFO - Started process (PID=1140) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:10:12,886] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:10:12,887] {logging_mixin.py:112} INFO - [2020-06-01 18:10:12,886] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:10:12,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:10:13,104] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.225 seconds
[2020-06-01 18:11:02,937] {scheduler_job.py:153} INFO - Started process (PID=1173) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:02,943] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:11:02,943] {logging_mixin.py:112} INFO - [2020-06-01 18:11:02,943] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:02,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:03,083] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.147 seconds
[2020-06-01 18:11:52,924] {scheduler_job.py:153} INFO - Started process (PID=1202) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:52,930] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:11:52,930] {logging_mixin.py:112} INFO - [2020-06-01 18:11:52,930] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:52,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:11:53,083] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.159 seconds
[2020-06-01 18:12:42,985] {scheduler_job.py:153} INFO - Started process (PID=1235) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:12:42,990] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:12:42,991] {logging_mixin.py:112} INFO - [2020-06-01 18:12:42,991] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:12:43,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:12:43,128] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.143 seconds
[2020-06-01 18:13:32,975] {scheduler_job.py:153} INFO - Started process (PID=1264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:13:32,980] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:13:32,981] {logging_mixin.py:112} INFO - [2020-06-01 18:13:32,981] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:13:32,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:13:33,169] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:14:23,009] {scheduler_job.py:153} INFO - Started process (PID=1297) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:14:23,015] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:14:23,016] {logging_mixin.py:112} INFO - [2020-06-01 18:14:23,016] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:14:23,025] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:14:23,182] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.173 seconds
[2020-06-01 18:15:13,029] {scheduler_job.py:153} INFO - Started process (PID=1327) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:15:13,035] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:15:13,036] {logging_mixin.py:112} INFO - [2020-06-01 18:15:13,035] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:15:13,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:15:13,235] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.206 seconds
[2020-06-01 18:16:03,050] {scheduler_job.py:153} INFO - Started process (PID=1359) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:03,055] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:16:03,056] {logging_mixin.py:112} INFO - [2020-06-01 18:16:03,055] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:03,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:03,215] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.166 seconds
[2020-06-01 18:16:53,101] {scheduler_job.py:153} INFO - Started process (PID=1392) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:53,111] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:16:53,112] {logging_mixin.py:112} INFO - [2020-06-01 18:16:53,112] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:53,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:16:53,268] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.168 seconds
[2020-06-01 18:17:43,123] {scheduler_job.py:153} INFO - Started process (PID=1421) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:17:43,132] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:17:43,133] {logging_mixin.py:112} INFO - [2020-06-01 18:17:43,132] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:17:43,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:17:43,296] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.174 seconds
[2020-06-01 18:18:33,138] {scheduler_job.py:153} INFO - Started process (PID=1455) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:18:33,144] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:18:33,144] {logging_mixin.py:112} INFO - [2020-06-01 18:18:33,144] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:18:33,155] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:18:33,413] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:19:23,190] {scheduler_job.py:153} INFO - Started process (PID=1484) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:19:23,198] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:19:23,201] {logging_mixin.py:112} INFO - [2020-06-01 18:19:23,199] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:19:23,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:19:23,360] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.170 seconds
[2020-06-01 18:20:13,248] {scheduler_job.py:153} INFO - Started process (PID=1517) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:20:13,258] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:20:13,259] {logging_mixin.py:112} INFO - [2020-06-01 18:20:13,259] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:20:13,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:20:13,559] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.311 seconds
[2020-06-01 18:21:03,427] {scheduler_job.py:153} INFO - Started process (PID=1546) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:03,434] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:21:03,435] {logging_mixin.py:112} INFO - [2020-06-01 18:21:03,435] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:03,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:03,735] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:21:53,634] {scheduler_job.py:153} INFO - Started process (PID=1582) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:53,640] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:21:53,641] {logging_mixin.py:112} INFO - [2020-06-01 18:21:53,641] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:53,651] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:21:53,813] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.179 seconds
[2020-06-01 18:22:43,673] {scheduler_job.py:153} INFO - Started process (PID=1611) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:22:43,679] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:22:43,679] {logging_mixin.py:112} INFO - [2020-06-01 18:22:43,679] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:22:43,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:22:43,850] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.176 seconds
[2020-06-01 18:23:33,689] {scheduler_job.py:153} INFO - Started process (PID=1644) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:23:33,696] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:23:33,696] {logging_mixin.py:112} INFO - [2020-06-01 18:23:33,696] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:23:33,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:23:34,021] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:24:23,735] {scheduler_job.py:153} INFO - Started process (PID=1673) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:24:23,746] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:24:23,747] {logging_mixin.py:112} INFO - [2020-06-01 18:24:23,746] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:24:23,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:24:24,003] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.269 seconds
[2020-06-01 18:25:13,738] {scheduler_job.py:153} INFO - Started process (PID=1706) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:25:13,745] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:25:13,745] {logging_mixin.py:112} INFO - [2020-06-01 18:25:13,745] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:25:13,759] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:25:13,959] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.221 seconds
[2020-06-01 18:26:03,780] {scheduler_job.py:153} INFO - Started process (PID=1740) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:03,789] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:26:03,790] {logging_mixin.py:112} INFO - [2020-06-01 18:26:03,790] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:03,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:04,105] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:26:53,796] {scheduler_job.py:153} INFO - Started process (PID=1797) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:53,801] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:26:53,802] {logging_mixin.py:112} INFO - [2020-06-01 18:26:53,802] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:53,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:26:53,968] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.173 seconds
[2020-06-01 18:27:43,845] {scheduler_job.py:153} INFO - Started process (PID=1830) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:27:43,859] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:27:43,861] {logging_mixin.py:112} INFO - [2020-06-01 18:27:43,861] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:27:43,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:27:44,194] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.349 seconds
[2020-06-01 18:28:33,996] {scheduler_job.py:153} INFO - Started process (PID=1859) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:28:34,002] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:28:34,002] {logging_mixin.py:112} INFO - [2020-06-01 18:28:34,002] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:28:34,013] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:28:34,330] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:29:24,047] {scheduler_job.py:153} INFO - Started process (PID=1892) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:29:24,055] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:29:24,056] {logging_mixin.py:112} INFO - [2020-06-01 18:29:24,056] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:29:24,073] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:29:24,241] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.194 seconds
[2020-06-01 18:30:14,073] {scheduler_job.py:153} INFO - Started process (PID=1921) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:30:14,079] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:30:14,079] {logging_mixin.py:112} INFO - [2020-06-01 18:30:14,079] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:30:14,090] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:30:14,233] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.160 seconds
[2020-06-01 18:31:04,130] {scheduler_job.py:153} INFO - Started process (PID=1954) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:04,136] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:31:04,137] {logging_mixin.py:112} INFO - [2020-06-01 18:31:04,137] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:04,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:04,420] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:31:54,135] {scheduler_job.py:153} INFO - Started process (PID=1983) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:54,142] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:31:54,143] {logging_mixin.py:112} INFO - [2020-06-01 18:31:54,143] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:54,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:31:54,284] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.149 seconds
[2020-06-01 18:32:44,167] {scheduler_job.py:153} INFO - Started process (PID=2016) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:32:44,172] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:32:44,173] {logging_mixin.py:112} INFO - [2020-06-01 18:32:44,172] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:32:44,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:32:44,445] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.278 seconds
[2020-06-01 18:33:34,290] {scheduler_job.py:153} INFO - Started process (PID=2045) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:33:34,296] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:33:34,296] {logging_mixin.py:112} INFO - [2020-06-01 18:33:34,296] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:33:34,307] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:33:34,480] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:34:24,244] {scheduler_job.py:153} INFO - Started process (PID=2078) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:34:24,249] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:34:24,250] {logging_mixin.py:112} INFO - [2020-06-01 18:34:24,250] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:34:24,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:34:24,698] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.454 seconds
[2020-06-01 18:35:14,239] {scheduler_job.py:153} INFO - Started process (PID=2107) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:35:14,246] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:35:14,247] {logging_mixin.py:112} INFO - [2020-06-01 18:35:14,247] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:35:14,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:35:14,407] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.169 seconds
[2020-06-01 18:36:04,280] {scheduler_job.py:153} INFO - Started process (PID=2140) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:04,286] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:36:04,287] {logging_mixin.py:112} INFO - [2020-06-01 18:36:04,287] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:04,301] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:04,885] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:36:54,324] {scheduler_job.py:153} INFO - Started process (PID=2173) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:54,334] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:36:54,335] {logging_mixin.py:112} INFO - [2020-06-01 18:36:54,335] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:54,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:36:54,515] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.191 seconds
[2020-06-01 18:37:44,375] {scheduler_job.py:153} INFO - Started process (PID=2202) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:37:44,380] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:37:44,381] {logging_mixin.py:112} INFO - [2020-06-01 18:37:44,381] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:37:44,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:37:44,561] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.187 seconds
[2020-06-01 18:38:34,378] {scheduler_job.py:153} INFO - Started process (PID=2235) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:38:34,384] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:38:34,385] {logging_mixin.py:112} INFO - [2020-06-01 18:38:34,384] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:38:34,395] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:38:34,682] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:39:24,405] {scheduler_job.py:153} INFO - Started process (PID=2264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:39:24,411] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:39:24,412] {logging_mixin.py:112} INFO - [2020-06-01 18:39:24,412] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:39:24,423] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:39:24,641] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.235 seconds
[2020-06-01 18:40:14,434] {scheduler_job.py:153} INFO - Started process (PID=2297) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:40:14,440] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:40:14,441] {logging_mixin.py:112} INFO - [2020-06-01 18:40:14,441] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:40:14,452] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:40:14,927] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.493 seconds
[2020-06-01 18:41:04,461] {scheduler_job.py:153} INFO - Started process (PID=2326) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:04,466] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:41:04,467] {logging_mixin.py:112} INFO - [2020-06-01 18:41:04,467] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:04,477] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:04,649] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:41:54,493] {scheduler_job.py:153} INFO - Started process (PID=2359) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:54,498] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:41:54,499] {logging_mixin.py:112} INFO - [2020-06-01 18:41:54,499] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:54,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:41:55,059] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.567 seconds
[2020-06-01 18:42:44,534] {scheduler_job.py:153} INFO - Started process (PID=2388) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:42:44,541] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:42:44,541] {logging_mixin.py:112} INFO - [2020-06-01 18:42:44,541] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:42:44,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:42:44,823] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.289 seconds
[2020-06-01 18:43:34,815] {scheduler_job.py:153} INFO - Started process (PID=2421) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:43:34,820] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:43:34,821] {logging_mixin.py:112} INFO - [2020-06-01 18:43:34,821] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:43:34,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:43:35,612] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.797 seconds
[2020-06-01 18:44:24,679] {scheduler_job.py:153} INFO - Started process (PID=2450) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:44:24,685] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:44:24,685] {logging_mixin.py:112} INFO - [2020-06-01 18:44:24,685] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:44:24,696] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:44:25,030] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.351 seconds
[2020-06-01 18:45:14,734] {scheduler_job.py:153} INFO - Started process (PID=2483) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:45:14,740] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:45:14,740] {logging_mixin.py:112} INFO - [2020-06-01 18:45:14,740] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:45:14,754] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:45:15,008] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.274 seconds
[2020-06-01 18:46:05,049] {scheduler_job.py:153} INFO - Started process (PID=2512) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:05,054] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:46:05,055] {logging_mixin.py:112} INFO - [2020-06-01 18:46:05,055] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:05,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:05,514] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:46:55,079] {scheduler_job.py:153} INFO - Started process (PID=2545) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:55,084] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:46:55,085] {logging_mixin.py:112} INFO - [2020-06-01 18:46:55,085] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:55,096] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:46:55,367] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.289 seconds
[2020-06-01 18:47:45,115] {scheduler_job.py:153} INFO - Started process (PID=2578) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:47:45,124] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:47:45,125] {logging_mixin.py:112} INFO - [2020-06-01 18:47:45,125] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:47:45,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:47:45,393] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.278 seconds
[2020-06-01 18:48:44,874] {scheduler_job.py:153} INFO - Started process (PID=2607) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:48:44,882] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:48:44,882] {logging_mixin.py:112} INFO - [2020-06-01 18:48:44,882] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:48:44,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:48:45,079] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:49:34,895] {scheduler_job.py:153} INFO - Started process (PID=2640) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:49:34,900] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:49:34,901] {logging_mixin.py:112} INFO - [2020-06-01 18:49:34,901] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:49:34,911] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:49:35,179] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.284 seconds
[2020-06-01 18:50:24,924] {scheduler_job.py:153} INFO - Started process (PID=2669) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:50:24,930] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:50:24,930] {logging_mixin.py:112} INFO - [2020-06-01 18:50:24,930] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:50:24,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:50:25,225] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.302 seconds
[2020-06-01 18:51:14,954] {scheduler_job.py:153} INFO - Started process (PID=2702) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:51:14,959] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:51:14,960] {logging_mixin.py:112} INFO - [2020-06-01 18:51:14,960] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:51:14,970] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:51:15,456] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:52:11,219] {scheduler_job.py:153} INFO - Started process (PID=2735) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:52:11,224] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:52:11,225] {logging_mixin.py:112} INFO - [2020-06-01 18:52:11,225] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:52:11,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:52:11,809] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.591 seconds
[2020-06-01 18:53:01,586] {scheduler_job.py:153} INFO - Started process (PID=2764) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:01,593] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:53:01,595] {logging_mixin.py:112} INFO - [2020-06-01 18:53:01,593] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:01,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:01,934] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.348 seconds
[2020-06-01 18:53:51,887] {scheduler_job.py:153} INFO - Started process (PID=2797) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:51,894] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:53:51,895] {logging_mixin.py:112} INFO - [2020-06-01 18:53:51,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:51,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:53:52,765] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:54:41,915] {scheduler_job.py:153} INFO - Started process (PID=2826) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:54:41,920] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:54:41,921] {logging_mixin.py:112} INFO - [2020-06-01 18:54:41,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:54:41,931] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:54:42,198] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.283 seconds
[2020-06-01 18:55:31,954] {scheduler_job.py:153} INFO - Started process (PID=2859) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:55:31,960] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:55:31,961] {logging_mixin.py:112} INFO - [2020-06-01 18:55:31,961] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:55:31,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:55:32,573] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.619 seconds
[2020-06-01 18:56:23,020] {scheduler_job.py:153} INFO - Started process (PID=2888) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:56:23,026] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:56:23,027] {logging_mixin.py:112} INFO - [2020-06-01 18:56:23,027] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:56:23,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:56:23,254] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:57:22,970] {scheduler_job.py:153} INFO - Started process (PID=2921) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:57:22,975] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:57:22,976] {logging_mixin.py:112} INFO - [2020-06-01 18:57:22,976] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:57:22,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:57:23,356] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.386 seconds
[2020-06-01 18:58:13,007] {scheduler_job.py:153} INFO - Started process (PID=2954) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:58:13,012] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:58:13,013] {logging_mixin.py:112} INFO - [2020-06-01 18:58:13,013] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:58:13,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:58:13,241] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.234 seconds
[2020-06-01 18:59:03,059] {scheduler_job.py:153} INFO - Started process (PID=2983) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:03,066] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:59:03,066] {logging_mixin.py:112} INFO - [2020-06-01 18:59:03,066] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:03,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:03,342] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:59:53,054] {scheduler_job.py:153} INFO - Started process (PID=3012) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:53,060] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 18:59:53,060] {logging_mixin.py:112} INFO - [2020-06-01 18:59:53,060] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:53,070] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 18:59:53,275] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.222 seconds
[2020-06-01 19:00:43,087] {scheduler_job.py:153} INFO - Started process (PID=3045) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:00:43,093] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:00:43,094] {logging_mixin.py:112} INFO - [2020-06-01 19:00:43,094] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:00:43,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:00:43,254] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.167 seconds
[2020-06-01 19:01:33,117] {scheduler_job.py:153} INFO - Started process (PID=3074) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:01:33,123] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:01:33,123] {logging_mixin.py:112} INFO - [2020-06-01 19:01:33,123] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:01:33,133] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:01:33,341] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:02:23,145] {scheduler_job.py:153} INFO - Started process (PID=3107) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:02:23,151] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:02:23,152] {logging_mixin.py:112} INFO - [2020-06-01 19:02:23,151] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:02:23,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:02:23,297] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.152 seconds
[2020-06-01 19:03:13,285] {scheduler_job.py:153} INFO - Started process (PID=3140) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:03:13,290] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:03:13,291] {logging_mixin.py:112} INFO - [2020-06-01 19:03:13,291] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:03:13,301] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:03:13,441] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.156 seconds
[2020-06-01 19:04:03,200] {scheduler_job.py:153} INFO - Started process (PID=3169) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:03,206] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:04:03,206] {logging_mixin.py:112} INFO - [2020-06-01 19:04:03,206] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:03,217] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:03,385] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:04:53,227] {scheduler_job.py:153} INFO - Started process (PID=3202) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:53,234] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:04:53,234] {logging_mixin.py:112} INFO - [2020-06-01 19:04:53,234] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:53,243] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:04:53,391] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.164 seconds
[2020-06-01 19:05:43,260] {scheduler_job.py:153} INFO - Started process (PID=3231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:05:43,265] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:05:43,266] {logging_mixin.py:112} INFO - [2020-06-01 19:05:43,266] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:05:43,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:05:43,418] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.158 seconds
[2020-06-01 19:06:33,288] {scheduler_job.py:153} INFO - Started process (PID=3264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:06:33,293] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:06:33,294] {logging_mixin.py:112} INFO - [2020-06-01 19:06:33,294] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:06:33,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:06:33,483] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:07:23,314] {scheduler_job.py:153} INFO - Started process (PID=3293) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:07:23,320] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:07:23,320] {logging_mixin.py:112} INFO - [2020-06-01 19:07:23,320] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:07:23,330] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:07:23,539] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.225 seconds
[2020-06-01 19:08:13,486] {scheduler_job.py:153} INFO - Started process (PID=3326) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:08:13,492] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:08:13,493] {logging_mixin.py:112} INFO - [2020-06-01 19:08:13,493] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:08:13,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:08:13,938] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.452 seconds
[2020-06-01 19:51:25,130] {scheduler_job.py:153} INFO - Started process (PID=3371) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:51:25,138] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:51:25,140] {logging_mixin.py:112} INFO - [2020-06-01 19:51:25,139] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:51:25,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:51:26,454] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:52:17,358] {scheduler_job.py:153} INFO - Started process (PID=3396) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:52:17,366] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:52:17,367] {logging_mixin.py:112} INFO - [2020-06-01 19:52:17,367] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:52:17,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:52:17,835] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.477 seconds
[2020-06-01 19:53:07,385] {scheduler_job.py:153} INFO - Started process (PID=3421) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:07,391] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:53:07,392] {logging_mixin.py:112} INFO - [2020-06-01 19:53:07,391] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:07,401] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:07,553] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.168 seconds
[2020-06-01 19:53:57,431] {scheduler_job.py:153} INFO - Started process (PID=3446) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:57,437] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:53:57,437] {logging_mixin.py:112} INFO - [2020-06-01 19:53:57,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:57,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:53:57,654] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:54:47,476] {scheduler_job.py:153} INFO - Started process (PID=3471) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:54:47,492] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:54:47,493] {logging_mixin.py:112} INFO - [2020-06-01 19:54:47,492] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:54:47,507] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:54:47,690] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.216 seconds
[2020-06-01 19:55:37,470] {scheduler_job.py:153} INFO - Started process (PID=3496) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:55:37,476] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:55:37,477] {logging_mixin.py:112} INFO - [2020-06-01 19:55:37,476] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:55:37,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:55:37,663] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.193 seconds
[2020-06-01 19:56:27,519] {scheduler_job.py:153} INFO - Started process (PID=3522) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:56:27,525] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:56:27,525] {logging_mixin.py:112} INFO - [2020-06-01 19:56:27,525] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:56:27,536] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:56:27,741] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:57:17,576] {scheduler_job.py:153} INFO - Started process (PID=3547) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:57:17,588] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:57:17,589] {logging_mixin.py:112} INFO - [2020-06-01 19:57:17,588] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:57:17,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:57:17,799] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.223 seconds
[2020-06-01 19:58:07,642] {scheduler_job.py:153} INFO - Started process (PID=3572) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:07,649] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:58:07,650] {logging_mixin.py:112} INFO - [2020-06-01 19:58:07,650] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:07,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:07,964] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.322 seconds
[2020-06-01 19:58:57,634] {scheduler_job.py:153} INFO - Started process (PID=3597) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:57,641] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:58:57,643] {logging_mixin.py:112} INFO - [2020-06-01 19:58:57,643] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:57,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:58:58,085] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:59:47,647] {scheduler_job.py:153} INFO - Started process (PID=3622) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:59:47,653] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 19:59:47,654] {logging_mixin.py:112} INFO - [2020-06-01 19:59:47,654] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:59:47,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 19:59:47,808] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.161 seconds
[2020-06-01 20:00:37,680] {scheduler_job.py:153} INFO - Started process (PID=3647) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:00:37,685] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 20:00:37,686] {logging_mixin.py:112} INFO - [2020-06-01 20:00:37,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:00:37,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:00:37,883] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.204 seconds
[2020-06-01 20:01:27,748] {scheduler_job.py:153} INFO - Started process (PID=3674) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:01:27,754] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-01 20:01:27,755] {logging_mixin.py:112} INFO - [2020-06-01 20:01:27,754] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:01:27,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-01 20:01:27,926] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:15:38,223] {scheduler_job.py:153} INFO - Started process (PID=237) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:15:38,234] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:15:38,235] {logging_mixin.py:112} INFO - [2020-06-02 15:15:38,235] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:15:38,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:15:38,525] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.302 seconds
[2020-06-02 15:16:52,908] {scheduler_job.py:153} INFO - Started process (PID=277) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:16:52,913] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:16:52,914] {logging_mixin.py:112} INFO - [2020-06-02 15:16:52,914] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:16:52,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:16:53,157] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.249 seconds
[2020-06-02 15:17:42,873] {scheduler_job.py:153} INFO - Started process (PID=303) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:17:42,878] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:17:42,879] {logging_mixin.py:112} INFO - [2020-06-02 15:17:42,879] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:17:43,020] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:17:43,145] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.272 seconds
[2020-06-02 15:18:32,903] {scheduler_job.py:153} INFO - Started process (PID=330) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:18:32,908] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:18:32,908] {logging_mixin.py:112} INFO - [2020-06-02 15:18:32,908] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:18:33,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:18:33,167] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.264 seconds
[2020-06-02 15:19:22,922] {scheduler_job.py:153} INFO - Started process (PID=383) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:19:22,927] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:19:22,928] {logging_mixin.py:112} INFO - [2020-06-02 15:19:22,928] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:19:23,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:19:23,177] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.255 seconds
[2020-06-02 15:20:12,963] {scheduler_job.py:153} INFO - Started process (PID=420) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:20:12,970] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:20:12,971] {logging_mixin.py:112} INFO - [2020-06-02 15:20:12,971] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:20:13,193] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:20:13,323] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.361 seconds
[2020-06-02 15:21:02,970] {scheduler_job.py:153} INFO - Started process (PID=446) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:21:02,975] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:21:02,976] {logging_mixin.py:112} INFO - [2020-06-02 15:21:02,976] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:21:02,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:21:03,088] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.119 seconds
[2020-06-02 15:22:17,503] {scheduler_job.py:153} INFO - Started process (PID=486) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:22:17,508] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:22:17,509] {logging_mixin.py:112} INFO - [2020-06-02 15:22:17,508] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:22:17,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:22:17,669] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:23:07,532] {scheduler_job.py:153} INFO - Started process (PID=512) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:07,539] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:23:07,539] {logging_mixin.py:112} INFO - [2020-06-02 15:23:07,539] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:07,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:08,756] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 1.223 seconds
[2020-06-02 15:23:57,555] {scheduler_job.py:153} INFO - Started process (PID=539) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:57,561] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:23:57,561] {logging_mixin.py:112} INFO - [2020-06-02 15:23:57,561] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:57,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:23:57,689] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.134 seconds
[2020-06-02 15:24:47,602] {scheduler_job.py:153} INFO - Started process (PID=566) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:24:47,608] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:24:47,608] {logging_mixin.py:112} INFO - [2020-06-02 15:24:47,608] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:24:47,618] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:24:47,912] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:25:48,202] {scheduler_job.py:153} INFO - Started process (PID=604) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:25:48,207] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:25:48,208] {logging_mixin.py:112} INFO - [2020-06-02 15:25:48,208] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:25:48,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:25:48,542] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.340 seconds
[2020-06-02 15:26:50,461] {scheduler_job.py:153} INFO - Started process (PID=635) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:26:50,465] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:26:50,466] {logging_mixin.py:112} INFO - [2020-06-02 15:26:50,466] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:26:50,475] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:26:50,730] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.269 seconds
[2020-06-02 15:27:40,485] {scheduler_job.py:153} INFO - Started process (PID=660) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:27:40,490] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:27:40,490] {logging_mixin.py:112} INFO - [2020-06-02 15:27:40,490] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:27:40,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:27:40,787] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.303 seconds
[2020-06-02 15:28:30,505] {scheduler_job.py:153} INFO - Started process (PID=685) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:28:30,510] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:28:30,510] {logging_mixin.py:112} INFO - [2020-06-02 15:28:30,510] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:28:30,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:28:30,772] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.267 seconds
[2020-06-02 15:29:20,526] {scheduler_job.py:153} INFO - Started process (PID=710) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:29:20,531] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:29:20,531] {logging_mixin.py:112} INFO - [2020-06-02 15:29:20,531] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:29:20,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:29:20,761] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.235 seconds
[2020-06-02 15:30:10,569] {scheduler_job.py:153} INFO - Started process (PID=735) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:30:10,574] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:30:10,574] {logging_mixin.py:112} INFO - [2020-06-02 15:30:10,574] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:30:10,719] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:30:10,837] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.269 seconds
[2020-06-02 15:31:00,595] {scheduler_job.py:153} INFO - Started process (PID=760) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:31:00,600] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:31:00,600] {logging_mixin.py:112} INFO - [2020-06-02 15:31:00,600] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:31:00,610] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:31:00,739] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.144 seconds
[2020-06-02 15:32:02,303] {scheduler_job.py:153} INFO - Started process (PID=791) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:02,308] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:32:02,309] {logging_mixin.py:112} INFO - [2020-06-02 15:32:02,309] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:02,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:02,487] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:32:52,328] {scheduler_job.py:153} INFO - Started process (PID=816) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:52,333] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:32:52,334] {logging_mixin.py:112} INFO - [2020-06-02 15:32:52,334] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:52,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:32:52,462] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.134 seconds
[2020-06-02 15:33:42,348] {scheduler_job.py:153} INFO - Started process (PID=841) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:33:42,353] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:33:42,354] {logging_mixin.py:112} INFO - [2020-06-02 15:33:42,354] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:33:42,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:33:42,465] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.117 seconds
[2020-06-02 15:34:32,372] {scheduler_job.py:153} INFO - Started process (PID=866) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:34:32,377] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:34:32,377] {logging_mixin.py:112} INFO - [2020-06-02 15:34:32,377] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:34:32,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:34:32,541] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:35:22,409] {scheduler_job.py:153} INFO - Started process (PID=908) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:35:22,414] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:35:22,415] {logging_mixin.py:112} INFO - [2020-06-02 15:35:22,415] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:35:22,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:35:22,521] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.112 seconds
[2020-06-02 15:36:12,420] {scheduler_job.py:153} INFO - Started process (PID=936) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:36:12,427] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:36:12,428] {logging_mixin.py:112} INFO - [2020-06-02 15:36:12,428] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:36:12,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:36:12,562] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.143 seconds
[2020-06-02 15:37:02,440] {scheduler_job.py:153} INFO - Started process (PID=961) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:02,446] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:37:02,446] {logging_mixin.py:112} INFO - [2020-06-02 15:37:02,446] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:02,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:02,595] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:37:52,468] {scheduler_job.py:153} INFO - Started process (PID=986) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:52,474] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:37:52,474] {logging_mixin.py:112} INFO - [2020-06-02 15:37:52,474] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:52,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:37:52,596] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.127 seconds
[2020-06-02 15:38:42,488] {scheduler_job.py:153} INFO - Started process (PID=1022) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:38:42,495] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:38:42,496] {logging_mixin.py:112} INFO - [2020-06-02 15:38:42,495] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:38:42,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:38:42,635] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.147 seconds
[2020-06-02 15:39:32,524] {scheduler_job.py:153} INFO - Started process (PID=1047) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:39:32,529] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:39:32,529] {logging_mixin.py:112} INFO - [2020-06-02 15:39:32,529] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:39:32,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:39:32,760] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:40:22,538] {scheduler_job.py:153} INFO - Started process (PID=1072) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:40:22,544] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:40:22,544] {logging_mixin.py:112} INFO - [2020-06-02 15:40:22,544] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:40:22,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:40:22,706] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.168 seconds
[2020-06-02 15:41:12,565] {scheduler_job.py:153} INFO - Started process (PID=1097) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:41:12,570] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:41:12,571] {logging_mixin.py:112} INFO - [2020-06-02 15:41:12,571] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:41:12,582] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:41:12,718] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.153 seconds
[2020-06-02 15:42:46,339] {scheduler_job.py:153} INFO - Started process (PID=1158) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:42:46,344] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:42:46,345] {logging_mixin.py:112} INFO - [2020-06-02 15:42:46,345] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:42:46,354] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:42:46,614] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.275 seconds
[2020-06-02 15:43:36,365] {scheduler_job.py:153} INFO - Started process (PID=1184) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:43:36,371] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:43:36,372] {logging_mixin.py:112} INFO - [2020-06-02 15:43:36,372] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:43:36,383] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:43:36,671] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.306 seconds
[2020-06-02 15:44:26,389] {scheduler_job.py:153} INFO - Started process (PID=1209) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:44:26,395] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:44:26,396] {logging_mixin.py:112} INFO - [2020-06-02 15:44:26,396] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:44:26,544] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:44:26,665] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.277 seconds
[2020-06-02 15:45:28,181] {scheduler_job.py:153} INFO - Started process (PID=1240) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:45:28,187] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:45:28,187] {logging_mixin.py:112} INFO - [2020-06-02 15:45:28,187] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:45:28,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:45:28,454] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.273 seconds
[2020-06-02 15:46:35,568] {scheduler_job.py:153} INFO - Started process (PID=1271) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:46:35,574] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:46:35,574] {logging_mixin.py:112} INFO - [2020-06-02 15:46:35,574] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:46:35,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:46:35,842] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.274 seconds
[2020-06-02 15:47:37,387] {scheduler_job.py:153} INFO - Started process (PID=1302) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:47:37,393] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:47:37,393] {logging_mixin.py:112} INFO - [2020-06-02 15:47:37,393] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:47:37,403] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:47:37,589] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:48:27,413] {scheduler_job.py:153} INFO - Started process (PID=1327) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:48:27,419] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:48:27,419] {logging_mixin.py:112} INFO - [2020-06-02 15:48:27,419] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:48:27,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:48:27,602] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.189 seconds
[2020-06-02 15:49:17,437] {scheduler_job.py:153} INFO - Started process (PID=1352) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:49:17,443] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:49:17,444] {logging_mixin.py:112} INFO - [2020-06-02 15:49:17,443] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:49:17,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:49:17,589] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.152 seconds
[2020-06-02 15:50:07,462] {scheduler_job.py:153} INFO - Started process (PID=1377) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:07,468] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:50:07,468] {logging_mixin.py:112} INFO - [2020-06-02 15:50:07,468] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:07,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:07,788] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:50:57,536] {scheduler_job.py:153} INFO - Started process (PID=1402) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:57,542] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:50:57,542] {logging_mixin.py:112} INFO - [2020-06-02 15:50:57,542] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:57,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:50:57,666] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.130 seconds
[2020-06-02 15:51:47,535] {scheduler_job.py:153} INFO - Started process (PID=1427) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:51:47,541] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:51:47,542] {logging_mixin.py:112} INFO - [2020-06-02 15:51:47,542] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:51:47,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:51:47,667] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.132 seconds
[2020-06-02 15:52:37,555] {scheduler_job.py:153} INFO - Started process (PID=1452) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:52:37,561] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:52:37,561] {logging_mixin.py:112} INFO - [2020-06-02 15:52:37,561] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:52:37,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:52:37,754] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:53:27,581] {scheduler_job.py:153} INFO - Started process (PID=1477) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:53:27,586] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:53:27,586] {logging_mixin.py:112} INFO - [2020-06-02 15:53:27,586] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:53:27,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:53:27,733] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.152 seconds
[2020-06-02 15:54:17,604] {scheduler_job.py:153} INFO - Started process (PID=1502) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:54:17,609] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:54:17,610] {logging_mixin.py:112} INFO - [2020-06-02 15:54:17,610] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:54:17,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:54:17,732] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.128 seconds
[2020-06-02 15:55:07,629] {scheduler_job.py:153} INFO - Started process (PID=1527) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:07,634] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:55:07,635] {logging_mixin.py:112} INFO - [2020-06-02 15:55:07,635] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:07,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:07,831] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:55:57,680] {scheduler_job.py:153} INFO - Started process (PID=1552) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:57,687] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:55:57,688] {logging_mixin.py:112} INFO - [2020-06-02 15:55:57,688] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:57,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:55:57,853] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.173 seconds
[2020-06-02 15:56:47,677] {scheduler_job.py:153} INFO - Started process (PID=1577) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:56:47,684] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:56:47,685] {logging_mixin.py:112} INFO - [2020-06-02 15:56:47,685] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:56:47,693] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:56:47,875] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.198 seconds
[2020-06-02 15:57:37,701] {scheduler_job.py:153} INFO - Started process (PID=1602) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:57:37,706] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:57:37,707] {logging_mixin.py:112} INFO - [2020-06-02 15:57:37,707] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:57:37,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:57:37,872] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:58:27,723] {scheduler_job.py:153} INFO - Started process (PID=1627) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:58:27,728] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:58:27,729] {logging_mixin.py:112} INFO - [2020-06-02 15:58:27,729] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:58:27,739] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:58:27,897] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.175 seconds
[2020-06-02 15:59:17,746] {scheduler_job.py:153} INFO - Started process (PID=1652) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:59:17,751] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 15:59:17,752] {logging_mixin.py:112} INFO - [2020-06-02 15:59:17,752] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:59:17,761] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 15:59:17,919] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.173 seconds
[2020-06-02 16:00:07,884] {scheduler_job.py:153} INFO - Started process (PID=1677) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:07,889] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:00:07,890] {logging_mixin.py:112} INFO - [2020-06-02 16:00:07,889] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:07,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:08,082] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:00:57,897] {scheduler_job.py:153} INFO - Started process (PID=1702) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:57,903] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:00:57,903] {logging_mixin.py:112} INFO - [2020-06-02 16:00:57,903] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:57,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:00:58,085] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.188 seconds
[2020-06-02 16:01:47,920] {scheduler_job.py:153} INFO - Started process (PID=1727) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:01:47,927] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:01:47,927] {logging_mixin.py:112} INFO - [2020-06-02 16:01:47,927] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:01:47,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:01:48,084] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.164 seconds
[2020-06-02 16:02:37,950] {scheduler_job.py:153} INFO - Started process (PID=1752) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:02:37,955] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:02:37,955] {logging_mixin.py:112} INFO - [2020-06-02 16:02:37,955] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:02:37,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:02:38,317] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:03:27,969] {scheduler_job.py:153} INFO - Started process (PID=1777) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:03:27,975] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:03:27,975] {logging_mixin.py:112} INFO - [2020-06-02 16:03:27,975] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:03:27,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:03:28,150] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.181 seconds
[2020-06-02 16:04:17,990] {scheduler_job.py:153} INFO - Started process (PID=1802) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:04:17,995] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:04:17,996] {logging_mixin.py:112} INFO - [2020-06-02 16:04:17,995] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:04:18,005] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:04:18,127] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.138 seconds
[2020-06-02 16:05:08,026] {scheduler_job.py:153} INFO - Started process (PID=1827) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:08,031] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:05:08,031] {logging_mixin.py:112} INFO - [2020-06-02 16:05:08,031] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:08,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:08,238] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:05:58,041] {scheduler_job.py:153} INFO - Started process (PID=1852) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:58,047] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:05:58,047] {logging_mixin.py:112} INFO - [2020-06-02 16:05:58,047] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:58,057] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:05:58,207] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.166 seconds
[2020-06-02 16:06:48,067] {scheduler_job.py:153} INFO - Started process (PID=1877) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:06:48,072] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:06:48,073] {logging_mixin.py:112} INFO - [2020-06-02 16:06:48,073] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:06:48,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:06:48,237] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.171 seconds
[2020-06-02 16:07:38,092] {scheduler_job.py:153} INFO - Started process (PID=1902) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:07:38,099] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:07:38,099] {logging_mixin.py:112} INFO - [2020-06-02 16:07:38,099] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:07:38,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:07:38,258] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:08:28,120] {scheduler_job.py:153} INFO - Started process (PID=1927) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:08:28,125] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:08:28,126] {logging_mixin.py:112} INFO - [2020-06-02 16:08:28,126] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:08:28,135] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:08:28,259] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.140 seconds
[2020-06-02 16:09:18,142] {scheduler_job.py:153} INFO - Started process (PID=1952) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:09:18,147] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:09:18,148] {logging_mixin.py:112} INFO - [2020-06-02 16:09:18,148] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:09:18,157] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:09:18,281] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.139 seconds
[2020-06-02 16:10:08,187] {scheduler_job.py:153} INFO - Started process (PID=1977) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:08,192] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:10:08,193] {logging_mixin.py:112} INFO - [2020-06-02 16:10:08,193] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:08,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:08,414] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:10:58,223] {scheduler_job.py:153} INFO - Started process (PID=2002) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:58,231] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:10:58,232] {logging_mixin.py:112} INFO - [2020-06-02 16:10:58,232] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:58,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:10:58,395] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.172 seconds
[2020-06-02 16:11:48,262] {scheduler_job.py:153} INFO - Started process (PID=2027) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:11:48,268] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:11:48,269] {logging_mixin.py:112} INFO - [2020-06-02 16:11:48,269] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:11:48,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:11:48,436] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.174 seconds
[2020-06-02 16:12:38,294] {scheduler_job.py:153} INFO - Started process (PID=2052) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:12:38,299] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:12:38,300] {logging_mixin.py:112} INFO - [2020-06-02 16:12:38,300] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:12:38,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:12:38,465] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:13:28,349] {scheduler_job.py:153} INFO - Started process (PID=2077) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:13:28,356] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:13:28,357] {logging_mixin.py:112} INFO - [2020-06-02 16:13:28,357] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:13:28,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:13:28,479] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.130 seconds
[2020-06-02 16:14:18,349] {scheduler_job.py:153} INFO - Started process (PID=2102) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:14:18,355] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:14:18,356] {logging_mixin.py:112} INFO - [2020-06-02 16:14:18,355] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:14:18,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:14:18,513] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.164 seconds
[2020-06-02 16:15:08,380] {scheduler_job.py:153} INFO - Started process (PID=2127) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:08,386] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:15:08,387] {logging_mixin.py:112} INFO - [2020-06-02 16:15:08,386] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:08,396] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:08,566] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:15:58,410] {scheduler_job.py:153} INFO - Started process (PID=2152) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:58,416] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:15:58,416] {logging_mixin.py:112} INFO - [2020-06-02 16:15:58,416] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:58,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:15:58,612] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.202 seconds
[2020-06-02 16:16:48,436] {scheduler_job.py:153} INFO - Started process (PID=2177) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:16:48,442] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:16:48,442] {logging_mixin.py:112} INFO - [2020-06-02 16:16:48,442] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:16:48,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:16:48,570] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.134 seconds
[2020-06-02 16:17:38,465] {scheduler_job.py:153} INFO - Started process (PID=2202) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:17:38,471] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:17:38,471] {logging_mixin.py:112} INFO - [2020-06-02 16:17:38,471] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:17:38,482] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:17:38,643] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:18:28,516] {scheduler_job.py:153} INFO - Started process (PID=2227) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:18:28,522] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:18:28,523] {logging_mixin.py:112} INFO - [2020-06-02 16:18:28,523] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:18:28,532] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:18:28,666] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.150 seconds
[2020-06-02 16:19:18,520] {scheduler_job.py:153} INFO - Started process (PID=2252) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:19:18,527] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:19:18,527] {logging_mixin.py:112} INFO - [2020-06-02 16:19:18,527] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:19:18,537] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:19:18,665] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.146 seconds
[2020-06-02 16:20:08,550] {scheduler_job.py:153} INFO - Started process (PID=2277) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:08,556] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:20:08,556] {logging_mixin.py:112} INFO - [2020-06-02 16:20:08,556] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:08,566] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:08,753] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:20:58,581] {scheduler_job.py:153} INFO - Started process (PID=2302) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:58,586] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:20:58,587] {logging_mixin.py:112} INFO - [2020-06-02 16:20:58,587] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:58,597] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:20:58,776] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.196 seconds
[2020-06-02 16:21:48,607] {scheduler_job.py:153} INFO - Started process (PID=2327) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:21:48,613] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:21:48,614] {logging_mixin.py:112} INFO - [2020-06-02 16:21:48,614] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:21:48,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:21:48,743] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.136 seconds
[2020-06-02 16:22:38,635] {scheduler_job.py:153} INFO - Started process (PID=2352) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:22:38,640] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:22:38,641] {logging_mixin.py:112} INFO - [2020-06-02 16:22:38,641] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:22:38,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:22:38,818] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:23:28,688] {scheduler_job.py:153} INFO - Started process (PID=2377) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:23:28,693] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:23:28,694] {logging_mixin.py:112} INFO - [2020-06-02 16:23:28,694] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:23:28,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:23:28,819] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.131 seconds
[2020-06-02 16:24:18,691] {scheduler_job.py:153} INFO - Started process (PID=2402) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:24:18,698] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:24:18,698] {logging_mixin.py:112} INFO - [2020-06-02 16:24:18,698] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:24:18,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:24:18,819] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.128 seconds
[2020-06-02 16:25:08,716] {scheduler_job.py:153} INFO - Started process (PID=2427) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:08,721] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:25:08,722] {logging_mixin.py:112} INFO - [2020-06-02 16:25:08,722] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:08,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:08,906] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:25:58,746] {scheduler_job.py:153} INFO - Started process (PID=2452) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:58,751] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:25:58,752] {logging_mixin.py:112} INFO - [2020-06-02 16:25:58,752] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:58,761] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:25:58,885] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.140 seconds
[2020-06-02 16:26:48,774] {scheduler_job.py:153} INFO - Started process (PID=2477) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:26:48,780] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:26:48,780] {logging_mixin.py:112} INFO - [2020-06-02 16:26:48,780] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:26:48,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:26:48,931] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.157 seconds
[2020-06-02 16:27:38,801] {scheduler_job.py:153} INFO - Started process (PID=2502) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:27:38,807] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:27:38,807] {logging_mixin.py:112} INFO - [2020-06-02 16:27:38,807] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:27:38,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:27:38,973] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.172 seconds
[2020-06-02 16:28:28,871] {scheduler_job.py:153} INFO - Started process (PID=2527) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:28:28,876] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:28:28,877] {logging_mixin.py:112} INFO - [2020-06-02 16:28:28,877] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:28:28,887] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:28:29,006] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.135 seconds
[2020-06-02 16:29:18,858] {scheduler_job.py:153} INFO - Started process (PID=2552) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:29:18,863] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:29:18,864] {logging_mixin.py:112} INFO - [2020-06-02 16:29:18,864] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:29:18,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:29:18,997] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.140 seconds
[2020-06-02 16:30:08,887] {scheduler_job.py:153} INFO - Started process (PID=2577) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:08,894] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:30:08,895] {logging_mixin.py:112} INFO - [2020-06-02 16:30:08,895] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:08,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:09,050] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.163 seconds
[2020-06-02 16:30:58,913] {scheduler_job.py:153} INFO - Started process (PID=2602) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:58,919] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:30:58,919] {logging_mixin.py:112} INFO - [2020-06-02 16:30:58,919] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:58,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:30:59,053] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.140 seconds
[2020-06-02 16:31:48,942] {scheduler_job.py:153} INFO - Started process (PID=2627) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:31:48,947] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:31:48,948] {logging_mixin.py:112} INFO - [2020-06-02 16:31:48,948] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:31:48,958] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:31:49,084] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.142 seconds
[2020-06-02 16:32:38,969] {scheduler_job.py:153} INFO - Started process (PID=2652) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:32:38,975] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:32:38,976] {logging_mixin.py:112} INFO - [2020-06-02 16:32:38,976] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:32:38,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:32:39,162] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.193 seconds
[2020-06-02 16:33:29,038] {scheduler_job.py:153} INFO - Started process (PID=2677) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:33:29,043] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:33:29,044] {logging_mixin.py:112} INFO - [2020-06-02 16:33:29,044] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:33:29,054] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:33:29,249] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.211 seconds
[2020-06-02 16:34:19,029] {scheduler_job.py:153} INFO - Started process (PID=2702) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:34:19,034] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:34:19,035] {logging_mixin.py:112} INFO - [2020-06-02 16:34:19,035] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:34:19,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:34:19,173] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.144 seconds
[2020-06-02 16:35:09,057] {scheduler_job.py:153} INFO - Started process (PID=2727) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:09,063] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:35:09,064] {logging_mixin.py:112} INFO - [2020-06-02 16:35:09,064] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:09,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:09,248] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:35:59,091] {scheduler_job.py:153} INFO - Started process (PID=2752) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:59,098] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:35:59,099] {logging_mixin.py:112} INFO - [2020-06-02 16:35:59,099] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:59,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:35:59,248] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.157 seconds
[2020-06-02 16:36:49,119] {scheduler_job.py:153} INFO - Started process (PID=2777) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:36:49,124] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:36:49,125] {logging_mixin.py:112} INFO - [2020-06-02 16:36:49,125] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:36:49,134] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:36:49,270] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.151 seconds
[2020-06-02 16:37:39,151] {scheduler_job.py:153} INFO - Started process (PID=2802) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:37:39,157] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:37:39,157] {logging_mixin.py:112} INFO - [2020-06-02 16:37:39,157] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:37:39,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:37:39,335] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:38:29,216] {scheduler_job.py:153} INFO - Started process (PID=2827) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:38:29,222] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:38:29,222] {logging_mixin.py:112} INFO - [2020-06-02 16:38:29,222] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:38:29,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:38:29,358] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.142 seconds
[2020-06-02 16:39:19,200] {scheduler_job.py:153} INFO - Started process (PID=2852) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:39:19,206] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:39:19,207] {logging_mixin.py:112} INFO - [2020-06-02 16:39:19,207] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:39:19,218] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:39:19,369] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.169 seconds
[2020-06-02 16:40:09,228] {scheduler_job.py:153} INFO - Started process (PID=2877) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:09,234] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:40:09,234] {logging_mixin.py:112} INFO - [2020-06-02 16:40:09,234] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:09,245] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:09,434] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:40:59,256] {scheduler_job.py:153} INFO - Started process (PID=2902) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:59,263] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:40:59,263] {logging_mixin.py:112} INFO - [2020-06-02 16:40:59,263] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:59,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:40:59,425] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.169 seconds
[2020-06-02 16:41:49,297] {scheduler_job.py:153} INFO - Started process (PID=2927) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:41:49,304] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:41:49,305] {logging_mixin.py:112} INFO - [2020-06-02 16:41:49,305] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:41:49,314] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:41:49,492] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.195 seconds
[2020-06-02 16:45:13,842] {scheduler_job.py:153} INFO - Started process (PID=2956) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:45:13,849] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-02 16:45:13,850] {logging_mixin.py:112} INFO - [2020-06-02 16:45:13,850] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:45:13,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-02 16:45:14,053] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.211 seconds
[2020-06-03 14:51:20,151] {scheduler_job.py:153} INFO - Started process (PID=142) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:51:20,196] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:51:20,197] {logging_mixin.py:112} INFO - [2020-06-03 14:51:20,197] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:51:20,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:51:20,710] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.559 seconds
[2020-06-03 14:52:10,257] {scheduler_job.py:153} INFO - Started process (PID=169) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:52:10,265] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:52:10,265] {logging_mixin.py:112} INFO - [2020-06-03 14:52:10,265] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:52:10,276] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:52:10,546] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.289 seconds
[2020-06-03 14:53:00,368] {scheduler_job.py:153} INFO - Started process (PID=196) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:53:00,379] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:53:00,380] {logging_mixin.py:112} INFO - [2020-06-03 14:53:00,380] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:53:00,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:53:00,719] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.351 seconds
[2020-06-03 14:54:00,856] {scheduler_job.py:153} INFO - Started process (PID=231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:54:00,861] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:54:00,862] {logging_mixin.py:112} INFO - [2020-06-03 14:54:00,861] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:54:00,871] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:54:01,114] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.258 seconds
[2020-06-03 14:55:15,578] {scheduler_job.py:153} INFO - Started process (PID=271) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:55:15,583] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:55:15,584] {logging_mixin.py:112} INFO - [2020-06-03 14:55:15,584] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:55:15,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:55:15,825] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.247 seconds
[2020-06-03 14:56:40,163] {scheduler_job.py:153} INFO - Started process (PID=311) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:56:40,168] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:56:40,169] {logging_mixin.py:112} INFO - [2020-06-03 14:56:40,169] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:56:40,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:56:40,462] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.299 seconds
[2020-06-03 14:58:00,492] {scheduler_job.py:153} INFO - Started process (PID=350) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:00,513] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:58:00,514] {logging_mixin.py:112} INFO - [2020-06-03 14:58:00,513] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:00,681] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:00,993] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.501 seconds
[2020-06-03 14:58:50,802] {scheduler_job.py:153} INFO - Started process (PID=376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:50,808] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:58:50,808] {logging_mixin.py:112} INFO - [2020-06-03 14:58:50,808] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:50,819] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:58:50,983] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.182 seconds
[2020-06-03 14:59:41,005] {scheduler_job.py:153} INFO - Started process (PID=403) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:59:41,046] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 14:59:41,047] {logging_mixin.py:112} INFO - [2020-06-03 14:59:41,047] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:59:41,057] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 14:59:41,345] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.340 seconds
[2020-06-03 15:00:32,907] {scheduler_job.py:153} INFO - Started process (PID=429) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:00:32,915] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:00:32,917] {logging_mixin.py:112} INFO - [2020-06-03 15:00:32,916] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:00:32,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:00:33,428] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.521 seconds
[2020-06-03 15:01:22,989] {scheduler_job.py:153} INFO - Started process (PID=456) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:01:22,995] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:01:22,996] {logging_mixin.py:112} INFO - [2020-06-03 15:01:22,995] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:01:23,007] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:01:23,364] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.375 seconds
[2020-06-03 15:02:14,194] {scheduler_job.py:153} INFO - Started process (PID=482) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:02:14,202] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:02:14,203] {logging_mixin.py:112} INFO - [2020-06-03 15:02:14,203] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:02:14,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:02:14,803] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:03:04,414] {scheduler_job.py:153} INFO - Started process (PID=508) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:04,430] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:03:04,431] {logging_mixin.py:112} INFO - [2020-06-03 15:03:04,431] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:04,462] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:04,967] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.553 seconds
[2020-06-03 15:03:55,035] {scheduler_job.py:153} INFO - Started process (PID=535) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:55,041] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:03:55,042] {logging_mixin.py:112} INFO - [2020-06-03 15:03:55,042] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:55,053] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:03:55,251] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.216 seconds
[2020-06-03 15:04:45,043] {scheduler_job.py:153} INFO - Started process (PID=561) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:04:45,055] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:04:45,056] {logging_mixin.py:112} INFO - [2020-06-03 15:04:45,055] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:04:45,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:04:45,240] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.197 seconds
[2020-06-03 15:05:35,133] {scheduler_job.py:153} INFO - Started process (PID=588) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:05:35,140] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:05:35,140] {logging_mixin.py:112} INFO - [2020-06-03 15:05:35,140] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:05:35,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:05:35,282] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.149 seconds
[2020-06-03 15:06:25,251] {scheduler_job.py:153} INFO - Started process (PID=615) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:06:25,256] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:06:25,257] {logging_mixin.py:112} INFO - [2020-06-03 15:06:25,257] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:06:25,266] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:06:25,394] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.143 seconds
[2020-06-03 15:07:15,381] {scheduler_job.py:153} INFO - Started process (PID=641) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:07:15,386] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:07:15,387] {logging_mixin.py:112} INFO - [2020-06-03 15:07:15,387] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:07:15,399] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:07:15,658] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:08:05,441] {scheduler_job.py:153} INFO - Started process (PID=668) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:05,446] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:08:05,447] {logging_mixin.py:112} INFO - [2020-06-03 15:08:05,446] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:05,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:05,571] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.130 seconds
[2020-06-03 15:08:55,538] {scheduler_job.py:153} INFO - Started process (PID=694) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:55,544] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:08:55,545] {logging_mixin.py:112} INFO - [2020-06-03 15:08:55,544] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:55,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:08:55,669] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.132 seconds
[2020-06-03 15:10:15,843] {scheduler_job.py:153} INFO - Started process (PID=728) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:10:15,854] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:10:15,855] {logging_mixin.py:112} INFO - [2020-06-03 15:10:15,855] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:10:15,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:10:16,190] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.347 seconds
[2020-06-03 15:11:05,893] {scheduler_job.py:153} INFO - Started process (PID=754) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:05,900] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:11:05,900] {logging_mixin.py:112} INFO - [2020-06-03 15:11:05,900] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:05,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:06,154] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.261 seconds
[2020-06-03 15:11:55,994] {scheduler_job.py:153} INFO - Started process (PID=781) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:56,004] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:11:56,005] {logging_mixin.py:112} INFO - [2020-06-03 15:11:56,005] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:56,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:11:56,337] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.344 seconds
[2020-06-03 15:12:46,021] {scheduler_job.py:153} INFO - Started process (PID=808) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:12:46,027] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:12:46,028] {logging_mixin.py:112} INFO - [2020-06-03 15:12:46,028] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:12:46,201] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:12:46,378] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.358 seconds
[2020-06-03 15:14:01,690] {scheduler_job.py:153} INFO - Started process (PID=847) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:14:01,697] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:14:01,698] {logging_mixin.py:112} INFO - [2020-06-03 15:14:01,698] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:14:01,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:14:02,011] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:15:26,577] {scheduler_job.py:153} INFO - Started process (PID=887) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:15:26,582] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:15:26,583] {logging_mixin.py:112} INFO - [2020-06-03 15:15:26,583] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:15:26,593] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:15:26,743] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.166 seconds
[2020-06-03 15:16:16,607] {scheduler_job.py:153} INFO - Started process (PID=913) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:16:16,615] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:16:16,616] {logging_mixin.py:112} INFO - [2020-06-03 15:16:16,616] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:16:16,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:16:16,857] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:17:40,139] {scheduler_job.py:153} INFO - Started process (PID=953) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:17:40,145] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:17:40,146] {logging_mixin.py:112} INFO - [2020-06-03 15:17:40,146] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:17:40,155] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:17:40,341] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.202 seconds
[2020-06-03 15:18:30,165] {scheduler_job.py:153} INFO - Started process (PID=980) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:18:30,170] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:18:30,171] {logging_mixin.py:112} INFO - [2020-06-03 15:18:30,171] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:18:30,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:18:30,377] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.212 seconds
[2020-06-03 15:19:20,191] {scheduler_job.py:153} INFO - Started process (PID=1006) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:19:20,196] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:19:20,197] {logging_mixin.py:112} INFO - [2020-06-03 15:19:20,197] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:19:20,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:19:20,548] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:20:10,216] {scheduler_job.py:153} INFO - Started process (PID=1033) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:20:10,221] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:20:10,222] {logging_mixin.py:112} INFO - [2020-06-03 15:20:10,222] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:20:10,232] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:20:10,386] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.170 seconds
[2020-06-03 15:21:00,274] {scheduler_job.py:153} INFO - Started process (PID=1059) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:00,283] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:21:00,284] {logging_mixin.py:112} INFO - [2020-06-03 15:21:00,284] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:00,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:00,432] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.158 seconds
[2020-06-03 15:21:42,444] {scheduler_job.py:153} INFO - Started process (PID=1086) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:42,450] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:21:42,451] {logging_mixin.py:112} INFO - [2020-06-03 15:21:42,450] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:42,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:21:42,779] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.335 seconds
[2020-06-03 15:22:32,545] {scheduler_job.py:153} INFO - Started process (PID=1112) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:22:32,552] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:22:32,553] {logging_mixin.py:112} INFO - [2020-06-03 15:22:32,553] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:22:32,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:22:32,851] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.306 seconds
[2020-06-03 15:23:34,505] {scheduler_job.py:153} INFO - Started process (PID=1145) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:23:34,510] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:23:34,510] {logging_mixin.py:112} INFO - [2020-06-03 15:23:34,510] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:23:34,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:23:34,764] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.259 seconds
[2020-06-03 15:24:41,925] {scheduler_job.py:153} INFO - Started process (PID=1178) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:24:41,930] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:24:41,930] {logging_mixin.py:112} INFO - [2020-06-03 15:24:41,930] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:24:42,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:24:42,217] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.293 seconds
[2020-06-03 15:25:44,099] {scheduler_job.py:153} INFO - Started process (PID=1211) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:25:44,104] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:25:44,105] {logging_mixin.py:112} INFO - [2020-06-03 15:25:44,105] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:25:44,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:25:44,383] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.284 seconds
[2020-06-03 15:26:34,178] {scheduler_job.py:153} INFO - Started process (PID=1238) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:26:34,184] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:26:34,184] {logging_mixin.py:112} INFO - [2020-06-03 15:26:34,184] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:26:34,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:26:34,365] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.187 seconds
[2020-06-03 15:27:24,255] {scheduler_job.py:153} INFO - Started process (PID=1264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:27:24,261] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:27:24,272] {logging_mixin.py:112} INFO - [2020-06-03 15:27:24,272] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:27:24,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:27:24,428] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:28:14,295] {scheduler_job.py:153} INFO - Started process (PID=1291) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:28:14,301] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:28:14,301] {logging_mixin.py:112} INFO - [2020-06-03 15:28:14,301] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:28:14,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:28:14,517] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.223 seconds
[2020-06-03 15:29:04,336] {scheduler_job.py:153} INFO - Started process (PID=1318) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:04,343] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:29:04,344] {logging_mixin.py:112} INFO - [2020-06-03 15:29:04,344] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:04,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:04,562] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py took 0.226 seconds
[2020-06-03 15:29:54,357] {scheduler_job.py:153} INFO - Started process (PID=1344) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:54,365] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py for tasks to queue
[2020-06-03 15:29:54,366] {logging_mixin.py:112} INFO - [2020-06-03 15:29:54,366] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:54,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_python_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_python_operator.py
[2020-06-03 15:29:54,604] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
