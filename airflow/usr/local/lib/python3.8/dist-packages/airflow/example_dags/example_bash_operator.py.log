[2020-05-31 21:01:31,540] {scheduler_job.py:153} INFO - Started process (PID=6104) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:01:31,545] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:01:31,546] {logging_mixin.py:112} INFO - [2020-05-31 21:01:31,546] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:01:31,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:01:31,758] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:02:19,583] {scheduler_job.py:153} INFO - Started process (PID=6136) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:02:19,588] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:02:19,589] {logging_mixin.py:112} INFO - [2020-05-31 21:02:19,589] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:02:19,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:02:19,726] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.143 seconds
[2020-05-31 21:03:07,585] {scheduler_job.py:153} INFO - Started process (PID=6164) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:07,590] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:03:07,591] {logging_mixin.py:112} INFO - [2020-05-31 21:03:07,591] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:07,602] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:07,761] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:03:55,613] {scheduler_job.py:153} INFO - Started process (PID=6196) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:55,618] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:03:55,619] {logging_mixin.py:112} INFO - [2020-05-31 21:03:55,619] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:55,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:03:55,835] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:04:43,633] {scheduler_job.py:153} INFO - Started process (PID=6224) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:04:43,638] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:04:43,639] {logging_mixin.py:112} INFO - [2020-05-31 21:04:43,638] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:04:43,650] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:04:43,800] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:05:31,656] {scheduler_job.py:153} INFO - Started process (PID=6256) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:05:31,661] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:05:31,662] {logging_mixin.py:112} INFO - [2020-05-31 21:05:31,662] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:05:31,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:05:31,845] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:06:19,681] {scheduler_job.py:153} INFO - Started process (PID=6284) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:06:19,686] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:06:19,687] {logging_mixin.py:112} INFO - [2020-05-31 21:06:19,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:06:19,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:06:19,856] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:07:07,706] {scheduler_job.py:153} INFO - Started process (PID=6316) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:07,711] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:07:07,712] {logging_mixin.py:112} INFO - [2020-05-31 21:07:07,711] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:07,723] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:07,844] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:07:55,730] {scheduler_job.py:153} INFO - Started process (PID=6344) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:55,735] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:07:55,736] {logging_mixin.py:112} INFO - [2020-05-31 21:07:55,736] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:55,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:07:55,889] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:08:43,753] {scheduler_job.py:153} INFO - Started process (PID=6376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:08:43,759] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:08:43,759] {logging_mixin.py:112} INFO - [2020-05-31 21:08:43,759] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:08:43,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:08:43,944] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:31,779] {scheduler_job.py:153} INFO - Started process (PID=6404) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:09:31,785] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:09:31,786] {logging_mixin.py:112} INFO - [2020-05-31 21:09:31,786] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:09:31,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:09:31,943] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:10:19,802] {scheduler_job.py:153} INFO - Started process (PID=6436) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:10:19,807] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:10:19,807] {logging_mixin.py:112} INFO - [2020-05-31 21:10:19,807] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:10:19,823] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:10:19,988] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:11:07,826] {scheduler_job.py:153} INFO - Started process (PID=6464) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:07,831] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:11:07,831] {logging_mixin.py:112} INFO - [2020-05-31 21:11:07,831] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:07,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:08,021] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:11:55,850] {scheduler_job.py:153} INFO - Started process (PID=6496) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:55,856] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:11:55,856] {logging_mixin.py:112} INFO - [2020-05-31 21:11:55,856] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:55,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:11:56,010] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:12:43,876] {scheduler_job.py:153} INFO - Started process (PID=6524) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:12:43,881] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:12:43,881] {logging_mixin.py:112} INFO - [2020-05-31 21:12:43,881] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:12:43,892] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:12:44,075] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:13:31,900] {scheduler_job.py:153} INFO - Started process (PID=6556) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:13:31,906] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:13:31,906] {logging_mixin.py:112} INFO - [2020-05-31 21:13:31,906] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:13:31,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:13:32,053] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:14:19,922] {scheduler_job.py:153} INFO - Started process (PID=6588) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:14:19,927] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:14:19,927] {logging_mixin.py:112} INFO - [2020-05-31 21:14:19,927] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:14:19,939] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:14:20,097] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:15:07,969] {scheduler_job.py:153} INFO - Started process (PID=6616) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:07,974] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:15:07,975] {logging_mixin.py:112} INFO - [2020-05-31 21:15:07,975] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:07,987] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:08,164] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:15:55,999] {scheduler_job.py:153} INFO - Started process (PID=6648) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:56,005] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:15:56,005] {logging_mixin.py:112} INFO - [2020-05-31 21:15:56,005] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:56,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:15:56,141] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:16:44,024] {scheduler_job.py:153} INFO - Started process (PID=6676) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:16:44,031] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:16:44,032] {logging_mixin.py:112} INFO - [2020-05-31 21:16:44,032] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:16:44,043] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:16:44,152] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:17:32,051] {scheduler_job.py:153} INFO - Started process (PID=6708) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:17:32,057] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:17:32,057] {logging_mixin.py:112} INFO - [2020-05-31 21:17:32,057] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:17:32,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:17:32,229] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:18:20,078] {scheduler_job.py:153} INFO - Started process (PID=6736) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:18:20,083] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:18:20,084] {logging_mixin.py:112} INFO - [2020-05-31 21:18:20,084] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:18:20,095] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:18:20,240] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:19:08,103] {scheduler_job.py:153} INFO - Started process (PID=6768) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:08,109] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:19:08,110] {logging_mixin.py:112} INFO - [2020-05-31 21:19:08,109] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:08,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:08,297] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:19:56,152] {scheduler_job.py:153} INFO - Started process (PID=6796) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:56,158] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:19:56,159] {logging_mixin.py:112} INFO - [2020-05-31 21:19:56,159] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:56,174] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:19:56,464] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:20:44,172] {scheduler_job.py:153} INFO - Started process (PID=6828) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:20:44,177] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:20:44,178] {logging_mixin.py:112} INFO - [2020-05-31 21:20:44,178] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:20:44,190] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:20:44,384] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:21:32,202] {scheduler_job.py:153} INFO - Started process (PID=6856) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:21:32,207] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:21:32,208] {logging_mixin.py:112} INFO - [2020-05-31 21:21:32,208] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:21:32,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:21:32,361] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:22:20,226] {scheduler_job.py:153} INFO - Started process (PID=6888) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:22:20,232] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:22:20,233] {logging_mixin.py:112} INFO - [2020-05-31 21:22:20,232] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:22:20,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:22:20,393] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:23:08,252] {scheduler_job.py:153} INFO - Started process (PID=6916) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:08,259] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:23:08,259] {logging_mixin.py:112} INFO - [2020-05-31 21:23:08,259] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:08,271] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:08,427] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:23:56,277] {scheduler_job.py:153} INFO - Started process (PID=6948) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:56,283] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:23:56,284] {logging_mixin.py:112} INFO - [2020-05-31 21:23:56,284] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:56,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:23:56,404] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:24:44,305] {scheduler_job.py:153} INFO - Started process (PID=6976) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:24:44,311] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:24:44,311] {logging_mixin.py:112} INFO - [2020-05-31 21:24:44,311] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:24:44,321] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:24:44,459] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:32,331] {scheduler_job.py:153} INFO - Started process (PID=7008) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:25:32,337] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:25:32,337] {logging_mixin.py:112} INFO - [2020-05-31 21:25:32,337] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:25:32,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:25:32,503] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:26:20,356] {scheduler_job.py:153} INFO - Started process (PID=7036) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:26:20,362] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:26:20,362] {logging_mixin.py:112} INFO - [2020-05-31 21:26:20,362] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:26:20,374] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:26:20,514] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:27:08,383] {scheduler_job.py:153} INFO - Started process (PID=7068) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:08,388] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:27:08,389] {logging_mixin.py:112} INFO - [2020-05-31 21:27:08,388] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:08,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:08,548] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:27:56,406] {scheduler_job.py:153} INFO - Started process (PID=7100) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:56,412] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:27:56,413] {logging_mixin.py:112} INFO - [2020-05-31 21:27:56,413] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:56,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:27:56,558] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:28:44,430] {scheduler_job.py:153} INFO - Started process (PID=7128) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:28:44,437] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:28:44,438] {logging_mixin.py:112} INFO - [2020-05-31 21:28:44,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:28:44,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:28:44,678] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:32,459] {scheduler_job.py:153} INFO - Started process (PID=7160) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:29:32,464] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:29:32,465] {logging_mixin.py:112} INFO - [2020-05-31 21:29:32,465] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:29:32,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:29:32,613] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:30:20,481] {scheduler_job.py:153} INFO - Started process (PID=7188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:30:20,486] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:30:20,487] {logging_mixin.py:112} INFO - [2020-05-31 21:30:20,487] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:30:20,497] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:30:20,668] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:31:08,508] {scheduler_job.py:153} INFO - Started process (PID=7220) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:08,513] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:31:08,514] {logging_mixin.py:112} INFO - [2020-05-31 21:31:08,514] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:08,525] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:08,679] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:31:56,536] {scheduler_job.py:153} INFO - Started process (PID=7248) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:56,541] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:31:56,542] {logging_mixin.py:112} INFO - [2020-05-31 21:31:56,542] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:56,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:31:56,712] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:32:44,561] {scheduler_job.py:153} INFO - Started process (PID=7280) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:32:44,567] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:32:44,567] {logging_mixin.py:112} INFO - [2020-05-31 21:32:44,567] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:32:44,579] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:32:44,688] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.126 seconds
[2020-05-31 21:33:32,584] {scheduler_job.py:153} INFO - Started process (PID=7308) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:33:32,589] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:33:32,590] {logging_mixin.py:112} INFO - [2020-05-31 21:33:32,590] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:33:32,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:33:32,777] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:34:20,607] {scheduler_job.py:153} INFO - Started process (PID=7340) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:34:20,613] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:34:20,614] {logging_mixin.py:112} INFO - [2020-05-31 21:34:20,614] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:34:20,624] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:34:20,742] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.136 seconds
[2020-05-31 21:35:08,630] {scheduler_job.py:153} INFO - Started process (PID=7368) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:08,635] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:35:08,636] {logging_mixin.py:112} INFO - [2020-05-31 21:35:08,636] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:08,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:08,810] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:35:56,653] {scheduler_job.py:153} INFO - Started process (PID=7400) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:56,659] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:35:56,659] {logging_mixin.py:112} INFO - [2020-05-31 21:35:56,659] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:56,670] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:35:56,786] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.133 seconds
[2020-05-31 21:36:44,672] {scheduler_job.py:153} INFO - Started process (PID=7428) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:36:44,677] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:36:44,678] {logging_mixin.py:112} INFO - [2020-05-31 21:36:44,678] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:36:44,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:36:44,898] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:37:32,695] {scheduler_job.py:153} INFO - Started process (PID=7460) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:37:32,700] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:37:32,701] {logging_mixin.py:112} INFO - [2020-05-31 21:37:32,701] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:37:32,712] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:37:33,090] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:38:20,716] {scheduler_job.py:153} INFO - Started process (PID=7488) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:38:20,722] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:38:20,722] {logging_mixin.py:112} INFO - [2020-05-31 21:38:20,722] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:38:20,734] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:38:20,909] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:39:08,740] {scheduler_job.py:153} INFO - Started process (PID=7520) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:08,745] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:39:08,746] {logging_mixin.py:112} INFO - [2020-05-31 21:39:08,746] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:08,757] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:08,898] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:39:56,766] {scheduler_job.py:153} INFO - Started process (PID=7548) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:56,772] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:39:56,772] {logging_mixin.py:112} INFO - [2020-05-31 21:39:56,772] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:56,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:39:56,907] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.142 seconds
[2020-05-31 21:40:44,786] {scheduler_job.py:153} INFO - Started process (PID=7580) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:40:44,791] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:40:44,792] {logging_mixin.py:112} INFO - [2020-05-31 21:40:44,792] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:40:44,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:40:44,986] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:32,815] {scheduler_job.py:153} INFO - Started process (PID=7612) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:41:32,823] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:41:32,824] {logging_mixin.py:112} INFO - [2020-05-31 21:41:32,824] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:41:32,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:41:32,954] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.138 seconds
[2020-05-31 21:42:20,829] {scheduler_job.py:153} INFO - Started process (PID=7640) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:42:20,835] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:42:20,835] {logging_mixin.py:112} INFO - [2020-05-31 21:42:20,835] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:42:20,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:42:20,974] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:43:08,851] {scheduler_job.py:153} INFO - Started process (PID=7672) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:08,856] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:43:08,856] {logging_mixin.py:112} INFO - [2020-05-31 21:43:08,856] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:08,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:08,985] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:43:56,877] {scheduler_job.py:153} INFO - Started process (PID=7700) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:56,882] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:43:56,883] {logging_mixin.py:112} INFO - [2020-05-31 21:43:56,883] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:56,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:43:57,007] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:44:44,899] {scheduler_job.py:153} INFO - Started process (PID=7732) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:44:44,904] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:44:44,905] {logging_mixin.py:112} INFO - [2020-05-31 21:44:44,905] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:44:44,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:44:45,062] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:45:32,922] {scheduler_job.py:153} INFO - Started process (PID=7760) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:45:32,928] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:45:32,929] {logging_mixin.py:112} INFO - [2020-05-31 21:45:32,929] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:45:32,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:45:33,073] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:46:20,947] {scheduler_job.py:153} INFO - Started process (PID=7792) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:46:20,952] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:46:20,952] {logging_mixin.py:112} INFO - [2020-05-31 21:46:20,952] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:46:20,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:46:21,117] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:47:08,969] {scheduler_job.py:153} INFO - Started process (PID=7820) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:08,974] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:47:08,975] {logging_mixin.py:112} INFO - [2020-05-31 21:47:08,975] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:08,985] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:09,162] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:47:56,992] {scheduler_job.py:153} INFO - Started process (PID=7852) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:56,997] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:47:56,998] {logging_mixin.py:112} INFO - [2020-05-31 21:47:56,998] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:57,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:47:57,138] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:48:45,034] {scheduler_job.py:153} INFO - Started process (PID=7880) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:48:45,039] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:48:45,040] {logging_mixin.py:112} INFO - [2020-05-31 21:48:45,039] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:48:45,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:48:45,205] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:33,095] {scheduler_job.py:153} INFO - Started process (PID=7912) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:49:33,100] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:49:33,100] {logging_mixin.py:112} INFO - [2020-05-31 21:49:33,100] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:49:33,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:49:33,305] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:50:21,139] {scheduler_job.py:153} INFO - Started process (PID=7940) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:50:21,144] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:50:21,145] {logging_mixin.py:112} INFO - [2020-05-31 21:50:21,145] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:50:21,156] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:50:21,327] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:51:09,178] {scheduler_job.py:153} INFO - Started process (PID=7972) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:09,183] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:51:09,184] {logging_mixin.py:112} INFO - [2020-05-31 21:51:09,184] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:09,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:09,372] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:51:57,224] {scheduler_job.py:153} INFO - Started process (PID=8000) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:57,229] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:51:57,230] {logging_mixin.py:112} INFO - [2020-05-31 21:51:57,230] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:57,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:51:57,383] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:52:45,267] {scheduler_job.py:153} INFO - Started process (PID=8032) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:52:45,272] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:52:45,282] {logging_mixin.py:112} INFO - [2020-05-31 21:52:45,282] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:52:45,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:52:45,449] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:33,311] {scheduler_job.py:153} INFO - Started process (PID=8060) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:53:33,317] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:53:33,317] {logging_mixin.py:112} INFO - [2020-05-31 21:53:33,317] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:53:33,328] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:53:33,470] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.159 seconds
[2020-05-31 21:54:21,356] {scheduler_job.py:153} INFO - Started process (PID=8092) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:54:21,362] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:54:21,363] {logging_mixin.py:112} INFO - [2020-05-31 21:54:21,362] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:54:21,374] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:54:21,537] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:55:09,405] {scheduler_job.py:153} INFO - Started process (PID=8124) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:09,413] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:55:09,413] {logging_mixin.py:112} INFO - [2020-05-31 21:55:09,413] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:09,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:09,971] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:55:57,452] {scheduler_job.py:153} INFO - Started process (PID=8152) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:57,456] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:55:57,457] {logging_mixin.py:112} INFO - [2020-05-31 21:55:57,457] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:57,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:55:57,625] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:56:45,487] {scheduler_job.py:153} INFO - Started process (PID=8184) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:56:45,494] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:56:45,494] {logging_mixin.py:112} INFO - [2020-05-31 21:56:45,494] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:56:45,505] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:56:45,670] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:57:33,534] {scheduler_job.py:153} INFO - Started process (PID=8212) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:57:33,540] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:57:33,540] {logging_mixin.py:112} INFO - [2020-05-31 21:57:33,540] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:57:33,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:57:33,747] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:58:21,579] {scheduler_job.py:153} INFO - Started process (PID=8244) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:58:21,585] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:58:21,585] {logging_mixin.py:112} INFO - [2020-05-31 21:58:21,585] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:58:21,597] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:58:21,780] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:59:09,622] {scheduler_job.py:153} INFO - Started process (PID=8272) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:09,627] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:59:09,628] {logging_mixin.py:112} INFO - [2020-05-31 21:59:09,628] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:09,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:09,814] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:59:57,666] {scheduler_job.py:153} INFO - Started process (PID=8304) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:57,671] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 21:59:57,672] {logging_mixin.py:112} INFO - [2020-05-31 21:59:57,672] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:57,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 21:59:57,836] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:00:45,710] {scheduler_job.py:153} INFO - Started process (PID=8332) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:00:45,716] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 22:00:45,716] {logging_mixin.py:112} INFO - [2020-05-31 22:00:45,716] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:00:45,728] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:00:45,869] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:01:33,754] {scheduler_job.py:153} INFO - Started process (PID=8364) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:01:33,759] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 22:01:33,760] {logging_mixin.py:112} INFO - [2020-05-31 22:01:33,760] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:01:33,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:01:33,969] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:02:21,816] {scheduler_job.py:153} INFO - Started process (PID=8392) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:02:21,822] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 22:02:21,823] {logging_mixin.py:112} INFO - [2020-05-31 22:02:21,823] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:02:21,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:02:21,991] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:03:09,869] {scheduler_job.py:153} INFO - Started process (PID=8424) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:03:09,874] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-05-31 22:03:09,875] {logging_mixin.py:112} INFO - [2020-05-31 22:03:09,875] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:03:09,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-05-31 22:03:10,023] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.153 seconds
[2020-06-01 14:32:56,637] {scheduler_job.py:153} INFO - Started process (PID=78) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:32:56,677] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:32:56,678] {logging_mixin.py:112} INFO - [2020-06-01 14:32:56,678] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:32:56,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:32:56,837] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.201 seconds
[2020-06-01 14:33:44,691] {scheduler_job.py:153} INFO - Started process (PID=106) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:33:44,698] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:33:44,698] {logging_mixin.py:112} INFO - [2020-06-01 14:33:44,698] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:33:44,710] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:33:44,973] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.281 seconds
[2020-06-01 14:34:32,813] {scheduler_job.py:153} INFO - Started process (PID=135) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:34:32,819] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:34:32,820] {logging_mixin.py:112} INFO - [2020-06-01 14:34:32,820] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:34:32,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:34:33,243] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.430 seconds
[2020-06-01 14:35:21,000] {scheduler_job.py:153} INFO - Started process (PID=166) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:35:21,055] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:35:21,056] {logging_mixin.py:112} INFO - [2020-06-01 14:35:21,056] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:35:21,303] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:35:21,751] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.752 seconds
[2020-06-01 14:36:10,464] {scheduler_job.py:153} INFO - Started process (PID=194) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:10,472] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:36:10,473] {logging_mixin.py:112} INFO - [2020-06-01 14:36:10,473] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:10,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:11,136] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.672 seconds
[2020-06-01 14:36:59,211] {scheduler_job.py:153} INFO - Started process (PID=222) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:59,217] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:36:59,218] {logging_mixin.py:112} INFO - [2020-06-01 14:36:59,218] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:59,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:36:59,495] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.284 seconds
[2020-06-01 14:37:47,240] {scheduler_job.py:153} INFO - Started process (PID=250) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:37:47,247] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:37:47,248] {logging_mixin.py:112} INFO - [2020-06-01 14:37:47,248] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:37:47,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:37:47,481] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.241 seconds
[2020-06-01 14:38:35,343] {scheduler_job.py:153} INFO - Started process (PID=282) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:38:35,349] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:38:35,350] {logging_mixin.py:112} INFO - [2020-06-01 14:38:35,350] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:38:35,363] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:38:35,569] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.226 seconds
[2020-06-01 14:39:23,432] {scheduler_job.py:153} INFO - Started process (PID=310) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:39:23,438] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:39:23,438] {logging_mixin.py:112} INFO - [2020-06-01 14:39:23,438] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:39:23,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:39:23,606] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.174 seconds
[2020-06-01 14:40:12,687] {scheduler_job.py:153} INFO - Started process (PID=358) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:40:12,692] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 14:40:12,693] {logging_mixin.py:112} INFO - [2020-06-01 14:40:12,693] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:40:12,709] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 14:40:12,835] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.148 seconds
[2020-06-01 15:15:33,673] {scheduler_job.py:153} INFO - Started process (PID=1117) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:15:33,717] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:15:33,718] {logging_mixin.py:112} INFO - [2020-06-01 15:15:33,718] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:15:33,729] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:15:33,920] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:16:23,705] {scheduler_job.py:153} INFO - Started process (PID=1150) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:16:23,710] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:16:23,710] {logging_mixin.py:112} INFO - [2020-06-01 15:16:23,710] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:16:23,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:16:23,845] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.140 seconds
[2020-06-01 15:17:13,750] {scheduler_job.py:153} INFO - Started process (PID=1179) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:17:13,755] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:17:13,755] {logging_mixin.py:112} INFO - [2020-06-01 15:17:13,755] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:17:13,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:17:13,924] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:18:03,819] {scheduler_job.py:153} INFO - Started process (PID=1212) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:03,824] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:18:03,824] {logging_mixin.py:112} INFO - [2020-06-01 15:18:03,824] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:03,836] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:04,012] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.194 seconds
[2020-06-01 15:18:53,871] {scheduler_job.py:153} INFO - Started process (PID=1245) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:53,875] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:18:53,876] {logging_mixin.py:112} INFO - [2020-06-01 15:18:53,876] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:53,887] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:18:54,008] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.137 seconds
[2020-06-01 15:19:43,885] {scheduler_job.py:153} INFO - Started process (PID=1274) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:19:43,890] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:19:43,890] {logging_mixin.py:112} INFO - [2020-06-01 15:19:43,890] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:19:43,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:19:44,053] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:20:33,909] {scheduler_job.py:153} INFO - Started process (PID=1307) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:20:33,914] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:20:33,915] {logging_mixin.py:112} INFO - [2020-06-01 15:20:33,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:20:33,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:20:34,069] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.160 seconds
[2020-06-01 15:21:23,960] {scheduler_job.py:153} INFO - Started process (PID=1336) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:21:23,995] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:21:23,996] {logging_mixin.py:112} INFO - [2020-06-01 15:21:23,995] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:21:24,013] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:21:24,166] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.206 seconds
[2020-06-01 15:22:13,982] {scheduler_job.py:153} INFO - Started process (PID=1369) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:22:13,987] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:22:13,988] {logging_mixin.py:112} INFO - [2020-06-01 15:22:13,988] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:22:13,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:22:14,196] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:26:55,536] {scheduler_job.py:153} INFO - Started process (PID=1422) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:26:55,541] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 15:26:55,542] {logging_mixin.py:112} INFO - [2020-06-01 15:26:55,542] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:26:55,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 15:26:56,595] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 1.059 seconds
[2020-06-01 17:42:44,251] {scheduler_job.py:153} INFO - Started process (PID=98) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:42:44,267] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:42:44,268] {logging_mixin.py:112} INFO - [2020-06-01 17:42:44,268] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:42:44,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:42:44,551] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.300 seconds
[2020-06-01 17:43:34,305] {scheduler_job.py:153} INFO - Started process (PID=131) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:43:34,310] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:43:34,310] {logging_mixin.py:112} INFO - [2020-06-01 17:43:34,310] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:43:34,322] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:43:34,453] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.148 seconds
[2020-06-01 17:44:24,378] {scheduler_job.py:153} INFO - Started process (PID=160) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:44:24,384] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:44:24,385] {logging_mixin.py:112} INFO - [2020-06-01 17:44:24,384] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:44:24,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:44:24,517] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.139 seconds
[2020-06-01 17:45:14,403] {scheduler_job.py:153} INFO - Started process (PID=193) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:45:14,408] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:45:14,409] {logging_mixin.py:112} INFO - [2020-06-01 17:45:14,409] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:45:14,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:45:14,548] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.145 seconds
[2020-06-01 17:46:04,438] {scheduler_job.py:153} INFO - Started process (PID=222) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:04,443] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:46:04,444] {logging_mixin.py:112} INFO - [2020-06-01 17:46:04,444] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:04,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:04,582] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.145 seconds
[2020-06-01 17:46:54,462] {scheduler_job.py:153} INFO - Started process (PID=255) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:54,468] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:46:54,468] {logging_mixin.py:112} INFO - [2020-06-01 17:46:54,468] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:54,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:46:54,616] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:47:44,516] {scheduler_job.py:153} INFO - Started process (PID=284) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:47:44,521] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:47:44,522] {logging_mixin.py:112} INFO - [2020-06-01 17:47:44,522] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:47:44,534] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:47:44,670] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.154 seconds
[2020-06-01 17:48:34,588] {scheduler_job.py:153} INFO - Started process (PID=317) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:48:34,593] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:48:34,594] {logging_mixin.py:112} INFO - [2020-06-01 17:48:34,594] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:48:34,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:48:34,839] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.252 seconds
[2020-06-01 17:49:24,638] {scheduler_job.py:153} INFO - Started process (PID=350) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:49:24,644] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:49:24,644] {logging_mixin.py:112} INFO - [2020-06-01 17:49:24,644] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:49:24,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:49:24,810] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.172 seconds
[2020-06-01 17:50:14,734] {scheduler_job.py:153} INFO - Started process (PID=379) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:50:14,739] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:50:14,740] {logging_mixin.py:112} INFO - [2020-06-01 17:50:14,740] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:50:14,762] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:50:14,901] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.168 seconds
[2020-06-01 17:51:04,853] {scheduler_job.py:153} INFO - Started process (PID=412) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:04,858] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:51:04,858] {logging_mixin.py:112} INFO - [2020-06-01 17:51:04,858] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:04,873] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:05,067] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.214 seconds
[2020-06-01 17:51:54,878] {scheduler_job.py:153} INFO - Started process (PID=441) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:54,883] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:51:54,884] {logging_mixin.py:112} INFO - [2020-06-01 17:51:54,884] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:54,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:51:55,058] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:52:44,978] {scheduler_job.py:153} INFO - Started process (PID=474) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:52:44,983] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:52:44,984] {logging_mixin.py:112} INFO - [2020-06-01 17:52:44,984] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:52:44,994] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:52:45,125] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.147 seconds
[2020-06-01 17:53:35,074] {scheduler_job.py:153} INFO - Started process (PID=503) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:53:35,082] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:53:35,083] {logging_mixin.py:112} INFO - [2020-06-01 17:53:35,082] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:53:35,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:53:35,236] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-01 17:54:25,160] {scheduler_job.py:153} INFO - Started process (PID=536) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:54:25,165] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:54:25,166] {logging_mixin.py:112} INFO - [2020-06-01 17:54:25,166] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:54:25,178] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:54:25,313] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.153 seconds
[2020-06-01 17:55:15,265] {scheduler_job.py:153} INFO - Started process (PID=569) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:55:15,270] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:55:15,271] {logging_mixin.py:112} INFO - [2020-06-01 17:55:15,271] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:55:15,286] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:55:15,428] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.163 seconds
[2020-06-01 17:56:05,348] {scheduler_job.py:153} INFO - Started process (PID=598) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:05,355] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:56:05,355] {logging_mixin.py:112} INFO - [2020-06-01 17:56:05,355] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:05,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:05,522] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.174 seconds
[2020-06-01 17:56:55,433] {scheduler_job.py:153} INFO - Started process (PID=631) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:55,438] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:56:55,439] {logging_mixin.py:112} INFO - [2020-06-01 17:56:55,439] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:55,452] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:56:55,611] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:57:45,533] {scheduler_job.py:153} INFO - Started process (PID=660) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:57:45,538] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:57:45,538] {logging_mixin.py:112} INFO - [2020-06-01 17:57:45,538] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:57:45,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:57:45,720] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.188 seconds
[2020-06-01 17:58:35,611] {scheduler_job.py:153} INFO - Started process (PID=693) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:58:35,617] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:58:35,617] {logging_mixin.py:112} INFO - [2020-06-01 17:58:35,617] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:58:35,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:58:35,810] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.199 seconds
[2020-06-01 17:59:25,711] {scheduler_job.py:153} INFO - Started process (PID=722) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:59:25,719] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 17:59:25,720] {logging_mixin.py:112} INFO - [2020-06-01 17:59:25,720] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:59:25,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 17:59:25,890] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:00:15,872] {scheduler_job.py:153} INFO - Started process (PID=755) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:00:15,877] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:00:15,877] {logging_mixin.py:112} INFO - [2020-06-01 18:00:15,877] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:00:15,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:00:16,332] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.461 seconds
[2020-06-01 18:01:05,954] {scheduler_job.py:153} INFO - Started process (PID=784) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:05,962] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:01:05,963] {logging_mixin.py:112} INFO - [2020-06-01 18:01:05,963] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:05,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:06,206] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.252 seconds
[2020-06-01 18:01:56,014] {scheduler_job.py:153} INFO - Started process (PID=817) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:56,020] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:01:56,020] {logging_mixin.py:112} INFO - [2020-06-01 18:01:56,020] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:56,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:01:56,270] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.256 seconds
[2020-06-01 18:02:46,052] {scheduler_job.py:153} INFO - Started process (PID=850) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:02:46,057] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:02:46,057] {logging_mixin.py:112} INFO - [2020-06-01 18:02:46,057] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:02:46,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:02:46,228] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.176 seconds
[2020-06-01 18:03:36,063] {scheduler_job.py:153} INFO - Started process (PID=879) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:03:36,068] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:03:36,069] {logging_mixin.py:112} INFO - [2020-06-01 18:03:36,068] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:03:36,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:03:36,218] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.155 seconds
[2020-06-01 18:04:26,093] {scheduler_job.py:153} INFO - Started process (PID=912) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:04:26,099] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:04:26,099] {logging_mixin.py:112} INFO - [2020-06-01 18:04:26,099] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:04:26,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:04:26,286] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:05:16,118] {scheduler_job.py:153} INFO - Started process (PID=941) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:05:16,124] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:05:16,124] {logging_mixin.py:112} INFO - [2020-06-01 18:05:16,124] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:05:16,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:05:16,283] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.165 seconds
[2020-06-01 18:06:43,023] {scheduler_job.py:153} INFO - Started process (PID=996) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:06:43,029] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:06:43,030] {logging_mixin.py:112} INFO - [2020-06-01 18:06:43,030] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:06:43,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:06:43,164] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.141 seconds
[2020-06-01 18:08:12,434] {scheduler_job.py:153} INFO - Started process (PID=1064) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:08:12,441] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:08:12,441] {logging_mixin.py:112} INFO - [2020-06-01 18:08:12,441] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:08:12,452] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:08:12,598] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.165 seconds
[2020-06-01 18:09:02,485] {scheduler_job.py:153} INFO - Started process (PID=1097) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:02,491] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:09:02,492] {logging_mixin.py:112} INFO - [2020-06-01 18:09:02,492] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:02,505] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:02,640] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:09:52,869] {scheduler_job.py:153} INFO - Started process (PID=1126) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:52,875] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:09:52,875] {logging_mixin.py:112} INFO - [2020-06-01 18:09:52,875] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:52,886] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:09:53,051] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.182 seconds
[2020-06-01 18:10:42,891] {scheduler_job.py:153} INFO - Started process (PID=1159) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:10:42,897] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:10:42,897] {logging_mixin.py:112} INFO - [2020-06-01 18:10:42,897] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:10:42,908] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:10:43,097] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.206 seconds
[2020-06-01 18:11:32,914] {scheduler_job.py:153} INFO - Started process (PID=1192) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:11:32,920] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:11:32,921] {logging_mixin.py:112} INFO - [2020-06-01 18:11:32,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:11:32,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:11:33,116] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:12:22,998] {scheduler_job.py:153} INFO - Started process (PID=1221) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:12:23,003] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:12:23,003] {logging_mixin.py:112} INFO - [2020-06-01 18:12:23,003] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:12:23,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:12:23,128] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.130 seconds
[2020-06-01 18:13:12,965] {scheduler_job.py:153} INFO - Started process (PID=1254) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:13:12,970] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:13:12,971] {logging_mixin.py:112} INFO - [2020-06-01 18:13:12,971] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:13:12,982] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:13:13,173] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.208 seconds
[2020-06-01 18:14:02,989] {scheduler_job.py:153} INFO - Started process (PID=1283) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:02,995] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:14:02,996] {logging_mixin.py:112} INFO - [2020-06-01 18:14:02,996] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:03,007] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:03,138] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:14:53,017] {scheduler_job.py:153} INFO - Started process (PID=1316) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:53,024] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:14:53,025] {logging_mixin.py:112} INFO - [2020-06-01 18:14:53,025] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:53,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:14:53,271] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.254 seconds
[2020-06-01 18:15:43,042] {scheduler_job.py:153} INFO - Started process (PID=1345) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:15:43,047] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:15:43,048] {logging_mixin.py:112} INFO - [2020-06-01 18:15:43,048] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:15:43,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:15:43,256] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.214 seconds
[2020-06-01 18:16:33,075] {scheduler_job.py:153} INFO - Started process (PID=1378) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:16:33,086] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:16:33,086] {logging_mixin.py:112} INFO - [2020-06-01 18:16:33,086] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:16:33,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:16:33,292] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:17:23,151] {scheduler_job.py:153} INFO - Started process (PID=1411) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:17:23,158] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:17:23,159] {logging_mixin.py:112} INFO - [2020-06-01 18:17:23,159] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:17:23,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:17:23,436] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.286 seconds
[2020-06-01 18:18:13,128] {scheduler_job.py:153} INFO - Started process (PID=1440) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:18:13,134] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:18:13,134] {logging_mixin.py:112} INFO - [2020-06-01 18:18:13,134] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:18:13,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:18:13,361] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.233 seconds
[2020-06-01 18:19:03,182] {scheduler_job.py:153} INFO - Started process (PID=1474) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:03,189] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:19:03,190] {logging_mixin.py:112} INFO - [2020-06-01 18:19:03,190] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:03,205] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:03,536] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:19:53,291] {scheduler_job.py:153} INFO - Started process (PID=1503) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:53,301] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:19:53,304] {logging_mixin.py:112} INFO - [2020-06-01 18:19:53,303] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:53,318] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:19:53,626] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.335 seconds
[2020-06-01 18:20:43,381] {scheduler_job.py:153} INFO - Started process (PID=1536) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:20:43,387] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:20:43,388] {logging_mixin.py:112} INFO - [2020-06-01 18:20:43,388] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:20:43,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:20:43,573] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.192 seconds
[2020-06-01 18:21:33,624] {scheduler_job.py:153} INFO - Started process (PID=1567) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:21:33,632] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:21:33,634] {logging_mixin.py:112} INFO - [2020-06-01 18:21:33,634] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:21:33,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:21:33,936] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:22:23,666] {scheduler_job.py:153} INFO - Started process (PID=1601) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:22:23,672] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:22:23,673] {logging_mixin.py:112} INFO - [2020-06-01 18:22:23,673] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:22:23,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:22:23,914] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.248 seconds
[2020-06-01 18:23:13,680] {scheduler_job.py:153} INFO - Started process (PID=1630) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:23:13,685] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:23:13,686] {logging_mixin.py:112} INFO - [2020-06-01 18:23:13,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:23:13,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:23:13,855] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.175 seconds
[2020-06-01 18:24:03,704] {scheduler_job.py:153} INFO - Started process (PID=1663) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:03,709] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:24:03,710] {logging_mixin.py:112} INFO - [2020-06-01 18:24:03,710] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:03,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:04,077] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:24:53,729] {scheduler_job.py:153} INFO - Started process (PID=1692) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:53,737] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:24:53,738] {logging_mixin.py:112} INFO - [2020-06-01 18:24:53,738] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:53,754] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:24:53,938] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.209 seconds
[2020-06-01 18:25:43,765] {scheduler_job.py:153} INFO - Started process (PID=1729) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:25:43,772] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:25:43,772] {logging_mixin.py:112} INFO - [2020-06-01 18:25:43,772] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:25:43,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:25:44,118] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.353 seconds
[2020-06-01 18:26:33,784] {scheduler_job.py:153} INFO - Started process (PID=1774) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:26:33,790] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:26:33,790] {logging_mixin.py:112} INFO - [2020-06-01 18:26:33,790] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:26:33,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:26:34,253] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:27:23,837] {scheduler_job.py:153} INFO - Started process (PID=1816) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:27:23,843] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:27:23,844] {logging_mixin.py:112} INFO - [2020-06-01 18:27:23,844] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:27:23,855] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:27:23,999] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-01 18:28:14,000] {scheduler_job.py:153} INFO - Started process (PID=1846) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:28:14,009] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:28:14,010] {logging_mixin.py:112} INFO - [2020-06-01 18:28:14,010] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:28:14,030] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:28:14,162] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.163 seconds
[2020-06-01 18:29:04,011] {scheduler_job.py:153} INFO - Started process (PID=1878) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:04,019] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:29:04,020] {logging_mixin.py:112} INFO - [2020-06-01 18:29:04,020] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:04,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:04,263] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:29:54,043] {scheduler_job.py:153} INFO - Started process (PID=1911) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:54,050] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:29:54,050] {logging_mixin.py:112} INFO - [2020-06-01 18:29:54,050] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:54,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:29:54,257] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.214 seconds
[2020-06-01 18:30:44,088] {scheduler_job.py:153} INFO - Started process (PID=1940) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:30:44,094] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:30:44,095] {logging_mixin.py:112} INFO - [2020-06-01 18:30:44,095] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:30:44,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:30:44,406] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.319 seconds
[2020-06-01 18:31:34,124] {scheduler_job.py:153} INFO - Started process (PID=1973) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:31:34,131] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:31:34,131] {logging_mixin.py:112} INFO - [2020-06-01 18:31:34,131] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:31:34,142] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:31:34,452] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:32:24,147] {scheduler_job.py:153} INFO - Started process (PID=2002) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:32:24,153] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:32:24,154] {logging_mixin.py:112} INFO - [2020-06-01 18:32:24,154] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:32:24,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:32:24,288] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.141 seconds
[2020-06-01 18:33:14,171] {scheduler_job.py:153} INFO - Started process (PID=2035) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:33:14,178] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:33:14,178] {logging_mixin.py:112} INFO - [2020-06-01 18:33:14,178] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:33:14,192] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:33:14,301] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.129 seconds
[2020-06-01 18:34:04,212] {scheduler_job.py:153} INFO - Started process (PID=2064) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:04,221] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:34:04,222] {logging_mixin.py:112} INFO - [2020-06-01 18:34:04,222] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:04,242] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:04,530] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:34:54,232] {scheduler_job.py:153} INFO - Started process (PID=2097) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:54,238] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:34:54,239] {logging_mixin.py:112} INFO - [2020-06-01 18:34:54,239] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:54,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:34:54,451] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.219 seconds
[2020-06-01 18:35:44,280] {scheduler_job.py:153} INFO - Started process (PID=2126) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:35:44,286] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:35:44,286] {logging_mixin.py:112} INFO - [2020-06-01 18:35:44,286] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:35:44,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:35:44,461] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.181 seconds
[2020-06-01 18:36:34,301] {scheduler_job.py:153} INFO - Started process (PID=2159) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:36:34,307] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:36:34,309] {logging_mixin.py:112} INFO - [2020-06-01 18:36:34,308] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:36:34,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:36:34,572] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:37:24,331] {scheduler_job.py:153} INFO - Started process (PID=2188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:37:24,337] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:37:24,338] {logging_mixin.py:112} INFO - [2020-06-01 18:37:24,338] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:37:24,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:37:24,462] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.131 seconds
[2020-06-01 18:38:14,361] {scheduler_job.py:153} INFO - Started process (PID=2221) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:38:14,367] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:38:14,368] {logging_mixin.py:112} INFO - [2020-06-01 18:38:14,367] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:38:14,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:38:14,534] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.173 seconds
[2020-06-01 18:39:04,391] {scheduler_job.py:153} INFO - Started process (PID=2254) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:04,398] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:39:04,399] {logging_mixin.py:112} INFO - [2020-06-01 18:39:04,398] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:04,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:04,783] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:39:54,423] {scheduler_job.py:153} INFO - Started process (PID=2283) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:54,430] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:39:54,430] {logging_mixin.py:112} INFO - [2020-06-01 18:39:54,430] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:54,443] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:39:54,585] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-01 18:40:44,471] {scheduler_job.py:153} INFO - Started process (PID=2316) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:40:44,478] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:40:44,479] {logging_mixin.py:112} INFO - [2020-06-01 18:40:44,478] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:40:44,493] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:40:44,806] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.335 seconds
[2020-06-01 18:41:34,482] {scheduler_job.py:153} INFO - Started process (PID=2345) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:41:34,487] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:41:34,488] {logging_mixin.py:112} INFO - [2020-06-01 18:41:34,488] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:41:34,500] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:41:34,816] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:42:24,510] {scheduler_job.py:153} INFO - Started process (PID=2378) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:42:24,517] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:42:24,517] {logging_mixin.py:112} INFO - [2020-06-01 18:42:24,517] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:42:24,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:42:24,864] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.354 seconds
[2020-06-01 18:43:14,541] {scheduler_job.py:153} INFO - Started process (PID=2407) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:43:14,549] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:43:14,549] {logging_mixin.py:112} INFO - [2020-06-01 18:43:14,549] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:43:14,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:43:15,037] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.495 seconds
[2020-06-01 18:44:04,664] {scheduler_job.py:153} INFO - Started process (PID=2440) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:04,670] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:44:04,671] {logging_mixin.py:112} INFO - [2020-06-01 18:44:04,670] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:04,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:04,979] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:44:54,719] {scheduler_job.py:153} INFO - Started process (PID=2469) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:54,724] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:44:54,725] {logging_mixin.py:112} INFO - [2020-06-01 18:44:54,725] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:54,737] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:44:55,057] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.338 seconds
[2020-06-01 18:45:45,038] {scheduler_job.py:153} INFO - Started process (PID=2502) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:45:45,044] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:45:45,045] {logging_mixin.py:112} INFO - [2020-06-01 18:45:45,045] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:45:45,057] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:45:45,384] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.346 seconds
[2020-06-01 18:46:35,083] {scheduler_job.py:153} INFO - Started process (PID=2531) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:46:35,089] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:46:35,089] {logging_mixin.py:112} INFO - [2020-06-01 18:46:35,089] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:46:35,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:46:35,423] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:47:25,106] {scheduler_job.py:153} INFO - Started process (PID=2564) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:47:25,112] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:47:25,113] {logging_mixin.py:112} INFO - [2020-06-01 18:47:25,112] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:47:25,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:47:25,415] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.309 seconds
[2020-06-01 18:48:15,125] {scheduler_job.py:153} INFO - Started process (PID=2593) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:48:15,132] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:48:15,133] {logging_mixin.py:112} INFO - [2020-06-01 18:48:15,133] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:48:15,144] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:48:15,393] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.268 seconds
[2020-06-01 18:49:15,037] {scheduler_job.py:153} INFO - Started process (PID=2626) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:49:15,044] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:49:15,045] {logging_mixin.py:112} INFO - [2020-06-01 18:49:15,045] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:49:15,059] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:49:15,534] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:50:05,017] {scheduler_job.py:153} INFO - Started process (PID=2659) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:05,022] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:50:05,023] {logging_mixin.py:112} INFO - [2020-06-01 18:50:05,023] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:05,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:05,433] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.416 seconds
[2020-06-01 18:50:54,943] {scheduler_job.py:153} INFO - Started process (PID=2688) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:54,949] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:50:54,950] {logging_mixin.py:112} INFO - [2020-06-01 18:50:54,950] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:54,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:50:55,511] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.568 seconds
[2020-06-01 18:51:50,812] {scheduler_job.py:153} INFO - Started process (PID=2721) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:51:50,818] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:51:50,818] {logging_mixin.py:112} INFO - [2020-06-01 18:51:50,818] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:51:50,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:51:51,667] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:52:41,709] {scheduler_job.py:153} INFO - Started process (PID=2754) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:52:41,715] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:52:41,716] {logging_mixin.py:112} INFO - [2020-06-01 18:52:41,716] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:52:41,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:52:42,574] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.865 seconds
[2020-06-01 18:53:31,889] {scheduler_job.py:153} INFO - Started process (PID=2783) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:53:31,895] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:53:31,896] {logging_mixin.py:112} INFO - [2020-06-01 18:53:31,896] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:53:31,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:53:32,191] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.302 seconds
[2020-06-01 18:54:21,903] {scheduler_job.py:153} INFO - Started process (PID=2816) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:54:21,908] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:54:21,909] {logging_mixin.py:112} INFO - [2020-06-01 18:54:21,909] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:54:21,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:54:22,341] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:55:11,935] {scheduler_job.py:153} INFO - Started process (PID=2845) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:55:11,941] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:55:11,942] {logging_mixin.py:112} INFO - [2020-06-01 18:55:11,942] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:55:11,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:55:12,231] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.296 seconds
[2020-06-01 18:56:03,008] {scheduler_job.py:153} INFO - Started process (PID=2878) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:56:03,014] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:56:03,015] {logging_mixin.py:112} INFO - [2020-06-01 18:56:03,015] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:56:03,028] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:56:03,310] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.302 seconds
[2020-06-01 18:57:02,910] {scheduler_job.py:153} INFO - Started process (PID=2907) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:02,918] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:57:02,919] {logging_mixin.py:112} INFO - [2020-06-01 18:57:02,919] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:02,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:03,519] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:57:52,985] {scheduler_job.py:153} INFO - Started process (PID=2940) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:52,990] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:57:52,991] {logging_mixin.py:112} INFO - [2020-06-01 18:57:52,991] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:53,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:57:53,576] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.591 seconds
[2020-06-01 18:58:43,015] {scheduler_job.py:153} INFO - Started process (PID=2973) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:58:43,021] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:58:43,023] {logging_mixin.py:112} INFO - [2020-06-01 18:58:43,022] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:58:43,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:58:43,357] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.342 seconds
[2020-06-01 18:59:33,118] {scheduler_job.py:153} INFO - Started process (PID=3002) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:59:33,126] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 18:59:33,126] {logging_mixin.py:112} INFO - [2020-06-01 18:59:33,126] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:59:33,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 18:59:33,520] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:00:23,074] {scheduler_job.py:153} INFO - Started process (PID=3031) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:00:23,080] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:00:23,081] {logging_mixin.py:112} INFO - [2020-06-01 19:00:23,080] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:00:23,091] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:00:23,342] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.268 seconds
[2020-06-01 19:01:13,117] {scheduler_job.py:153} INFO - Started process (PID=3064) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:01:13,123] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:01:13,123] {logging_mixin.py:112} INFO - [2020-06-01 19:01:13,123] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:01:13,134] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:01:13,282] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.165 seconds
[2020-06-01 19:02:03,135] {scheduler_job.py:153} INFO - Started process (PID=3093) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:03,140] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:02:03,141] {logging_mixin.py:112} INFO - [2020-06-01 19:02:03,141] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:03,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:03,441] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:02:53,161] {scheduler_job.py:153} INFO - Started process (PID=3126) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:53,166] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:02:53,167] {logging_mixin.py:112} INFO - [2020-06-01 19:02:53,167] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:53,179] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:02:53,320] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.160 seconds
[2020-06-01 19:03:43,190] {scheduler_job.py:153} INFO - Started process (PID=3155) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:03:43,196] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:03:43,197] {logging_mixin.py:112} INFO - [2020-06-01 19:03:43,196] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:03:43,208] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:03:43,329] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.138 seconds
[2020-06-01 19:04:33,218] {scheduler_job.py:153} INFO - Started process (PID=3188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:04:33,224] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:04:33,225] {logging_mixin.py:112} INFO - [2020-06-01 19:04:33,225] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:04:33,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:04:33,416] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.198 seconds
[2020-06-01 19:05:23,247] {scheduler_job.py:153} INFO - Started process (PID=3221) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:05:23,253] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:05:23,254] {logging_mixin.py:112} INFO - [2020-06-01 19:05:23,254] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:05:23,265] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:05:23,441] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.194 seconds
[2020-06-01 19:06:13,290] {scheduler_job.py:153} INFO - Started process (PID=3250) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:06:13,295] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:06:13,296] {logging_mixin.py:112} INFO - [2020-06-01 19:06:13,296] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:06:13,307] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:06:13,530] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.241 seconds
[2020-06-01 19:07:03,310] {scheduler_job.py:153} INFO - Started process (PID=3283) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:03,315] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:07:03,316] {logging_mixin.py:112} INFO - [2020-06-01 19:07:03,316] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:03,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:03,473] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:07:53,333] {scheduler_job.py:153} INFO - Started process (PID=3312) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:53,339] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:07:53,340] {logging_mixin.py:112} INFO - [2020-06-01 19:07:53,339] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:53,351] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:07:53,573] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.240 seconds
[2020-06-01 19:51:06,728] {scheduler_job.py:153} INFO - Started process (PID=3361) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:06,734] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:51:06,735] {logging_mixin.py:112} INFO - [2020-06-01 19:51:06,734] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:06,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:07,472] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.744 seconds
[2020-06-01 19:51:57,361] {scheduler_job.py:153} INFO - Started process (PID=3386) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:57,371] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:51:57,372] {logging_mixin.py:112} INFO - [2020-06-01 19:51:57,372] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:57,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:51:57,865] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:52:47,380] {scheduler_job.py:153} INFO - Started process (PID=3411) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:52:47,386] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:52:47,387] {logging_mixin.py:112} INFO - [2020-06-01 19:52:47,386] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:52:47,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:52:47,687] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.308 seconds
[2020-06-01 19:53:37,424] {scheduler_job.py:153} INFO - Started process (PID=3436) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:53:37,429] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:53:37,430] {logging_mixin.py:112} INFO - [2020-06-01 19:53:37,430] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:53:37,441] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:53:37,575] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.152 seconds
[2020-06-01 19:54:27,446] {scheduler_job.py:153} INFO - Started process (PID=3461) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:54:27,451] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:54:27,452] {logging_mixin.py:112} INFO - [2020-06-01 19:54:27,452] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:54:27,464] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:54:27,586] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:55:17,462] {scheduler_job.py:153} INFO - Started process (PID=3486) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:55:17,467] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:55:17,468] {logging_mixin.py:112} INFO - [2020-06-01 19:55:17,468] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:55:17,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:55:17,719] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.258 seconds
[2020-06-01 19:56:07,508] {scheduler_job.py:153} INFO - Started process (PID=3512) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:07,513] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:56:07,514] {logging_mixin.py:112} INFO - [2020-06-01 19:56:07,514] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:07,527] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:07,664] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.157 seconds
[2020-06-01 19:56:57,545] {scheduler_job.py:153} INFO - Started process (PID=3537) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:57,555] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:56:57,556] {logging_mixin.py:112} INFO - [2020-06-01 19:56:57,556] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:57,573] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:56:57,986] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:57:47,579] {scheduler_job.py:153} INFO - Started process (PID=3562) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:57:47,586] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:57:47,587] {logging_mixin.py:112} INFO - [2020-06-01 19:57:47,587] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:57:47,599] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:57:47,759] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.180 seconds
[2020-06-01 19:58:37,623] {scheduler_job.py:153} INFO - Started process (PID=3587) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:58:37,630] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:58:37,631] {logging_mixin.py:112} INFO - [2020-06-01 19:58:37,630] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:58:37,643] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:58:37,798] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.175 seconds
[2020-06-01 19:59:27,640] {scheduler_job.py:153} INFO - Started process (PID=3612) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:59:27,646] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 19:59:27,647] {logging_mixin.py:112} INFO - [2020-06-01 19:59:27,647] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:59:27,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 19:59:27,973] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 20:00:17,680] {scheduler_job.py:153} INFO - Started process (PID=3637) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:00:17,686] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 20:00:17,687] {logging_mixin.py:112} INFO - [2020-06-01 20:00:17,687] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:00:17,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:00:17,890] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.210 seconds
[2020-06-01 20:01:07,714] {scheduler_job.py:153} INFO - Started process (PID=3663) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:01:07,719] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-01 20:01:07,720] {logging_mixin.py:112} INFO - [2020-06-01 20:01:07,719] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:01:07,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-01 20:01:07,944] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.231 seconds
[2020-06-02 15:16:12,248] {scheduler_job.py:153} INFO - Started process (PID=255) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:16:12,286] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:16:12,286] {logging_mixin.py:112} INFO - [2020-06-02 15:16:12,286] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:16:12,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:16:12,582] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.334 seconds
[2020-06-02 15:17:26,929] {scheduler_job.py:153} INFO - Started process (PID=295) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:17:26,935] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:17:26,936] {logging_mixin.py:112} INFO - [2020-06-02 15:17:26,936] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:17:26,948] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:17:27,190] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.261 seconds
[2020-06-02 15:18:16,888] {scheduler_job.py:153} INFO - Started process (PID=321) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:18:16,893] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:18:16,893] {logging_mixin.py:112} INFO - [2020-06-02 15:18:16,893] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:18:17,039] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:18:17,145] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.258 seconds
[2020-06-02 15:19:06,915] {scheduler_job.py:153} INFO - Started process (PID=370) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:06,921] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:19:06,921] {logging_mixin.py:112} INFO - [2020-06-02 15:19:06,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:07,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:07,176] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.261 seconds
[2020-06-02 15:19:56,945] {scheduler_job.py:153} INFO - Started process (PID=411) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:56,950] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:19:56,951] {logging_mixin.py:112} INFO - [2020-06-02 15:19:56,951] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:57,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:19:57,211] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.266 seconds
[2020-06-02 15:20:46,960] {scheduler_job.py:153} INFO - Started process (PID=438) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:20:46,966] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:20:46,966] {logging_mixin.py:112} INFO - [2020-06-02 15:20:46,966] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:20:46,977] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:20:47,148] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:21:37,013] {scheduler_job.py:153} INFO - Started process (PID=465) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:21:37,020] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:21:37,021] {logging_mixin.py:112} INFO - [2020-06-02 15:21:37,021] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:21:37,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:21:37,207] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.194 seconds
[2020-06-02 15:22:51,525] {scheduler_job.py:153} INFO - Started process (PID=504) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:22:51,532] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:22:51,533] {logging_mixin.py:112} INFO - [2020-06-02 15:22:51,533] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:22:51,544] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:22:51,667] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.143 seconds
[2020-06-02 15:23:41,550] {scheduler_job.py:153} INFO - Started process (PID=530) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:23:41,556] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:23:41,557] {logging_mixin.py:112} INFO - [2020-06-02 15:23:41,557] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:23:41,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:23:41,711] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-02 15:24:31,585] {scheduler_job.py:153} INFO - Started process (PID=557) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:24:31,591] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:24:31,591] {logging_mixin.py:112} INFO - [2020-06-02 15:24:31,591] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:24:31,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:24:31,712] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.127 seconds
[2020-06-02 15:25:30,256] {scheduler_job.py:153} INFO - Started process (PID=595) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:25:30,262] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:25:30,263] {logging_mixin.py:112} INFO - [2020-06-02 15:25:30,263] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:25:30,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:25:30,544] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.288 seconds
[2020-06-02 15:26:20,233] {scheduler_job.py:153} INFO - Started process (PID=620) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:26:20,239] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:26:20,240] {logging_mixin.py:112} INFO - [2020-06-02 15:26:20,239] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:26:20,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:26:20,622] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.390 seconds
[2020-06-02 15:27:22,488] {scheduler_job.py:153} INFO - Started process (PID=651) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:27:22,494] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:27:22,495] {logging_mixin.py:112} INFO - [2020-06-02 15:27:22,495] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:27:22,651] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:27:22,763] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.276 seconds
[2020-06-02 15:28:12,496] {scheduler_job.py:153} INFO - Started process (PID=676) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:28:12,501] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:28:12,502] {logging_mixin.py:112} INFO - [2020-06-02 15:28:12,502] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:28:12,645] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:28:12,753] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.257 seconds
[2020-06-02 15:29:02,521] {scheduler_job.py:153} INFO - Started process (PID=701) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:02,526] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:29:02,527] {logging_mixin.py:112} INFO - [2020-06-02 15:29:02,527] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:02,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:02,805] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.284 seconds
[2020-06-02 15:29:52,545] {scheduler_job.py:153} INFO - Started process (PID=726) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:52,550] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:29:52,551] {logging_mixin.py:112} INFO - [2020-06-02 15:29:52,551] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:52,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:29:52,804] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.259 seconds
[2020-06-02 15:30:42,594] {scheduler_job.py:153} INFO - Started process (PID=751) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:30:42,599] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:30:42,599] {logging_mixin.py:112} INFO - [2020-06-02 15:30:42,599] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:30:42,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:30:42,738] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.144 seconds
[2020-06-02 15:31:32,616] {scheduler_job.py:153} INFO - Started process (PID=776) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:31:32,621] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:31:32,622] {logging_mixin.py:112} INFO - [2020-06-02 15:31:32,622] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:31:32,635] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:31:32,787] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:32:34,337] {scheduler_job.py:153} INFO - Started process (PID=807) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:32:34,343] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:32:34,344] {logging_mixin.py:112} INFO - [2020-06-02 15:32:34,343] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:32:34,354] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:32:34,485] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.148 seconds
[2020-06-02 15:33:24,342] {scheduler_job.py:153} INFO - Started process (PID=832) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:33:24,349] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:33:24,350] {logging_mixin.py:112} INFO - [2020-06-02 15:33:24,350] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:33:24,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:33:24,508] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.166 seconds
[2020-06-02 15:34:14,366] {scheduler_job.py:153} INFO - Started process (PID=857) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:34:14,371] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:34:14,372] {logging_mixin.py:112} INFO - [2020-06-02 15:34:14,371] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:34:14,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:34:14,530] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:35:04,391] {scheduler_job.py:153} INFO - Started process (PID=882) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:04,396] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:35:04,397] {logging_mixin.py:112} INFO - [2020-06-02 15:35:04,397] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:04,408] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:04,653] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.263 seconds
[2020-06-02 15:35:54,413] {scheduler_job.py:153} INFO - Started process (PID=926) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:54,419] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:35:54,419] {logging_mixin.py:112} INFO - [2020-06-02 15:35:54,419] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:54,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:35:54,597] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.184 seconds
[2020-06-02 15:36:44,442] {scheduler_job.py:153} INFO - Started process (PID=952) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:36:44,447] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:36:44,448] {logging_mixin.py:112} INFO - [2020-06-02 15:36:44,448] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:36:44,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:36:44,618] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:37:34,458] {scheduler_job.py:153} INFO - Started process (PID=977) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:37:34,463] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:37:34,464] {logging_mixin.py:112} INFO - [2020-06-02 15:37:34,464] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:37:34,476] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:37:34,607] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.149 seconds
[2020-06-02 15:38:24,486] {scheduler_job.py:153} INFO - Started process (PID=1012) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:38:24,493] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:38:24,494] {logging_mixin.py:112} INFO - [2020-06-02 15:38:24,494] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:38:24,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:38:24,617] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.131 seconds
[2020-06-02 15:39:14,511] {scheduler_job.py:153} INFO - Started process (PID=1038) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:39:14,517] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:39:14,517] {logging_mixin.py:112} INFO - [2020-06-02 15:39:14,517] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:39:14,532] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:39:14,690] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.180 seconds
[2020-06-02 15:40:04,529] {scheduler_job.py:153} INFO - Started process (PID=1063) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:04,535] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:40:04,535] {logging_mixin.py:112} INFO - [2020-06-02 15:40:04,535] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:04,546] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:04,727] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.198 seconds
[2020-06-02 15:40:54,557] {scheduler_job.py:153} INFO - Started process (PID=1088) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:54,562] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:40:54,563] {logging_mixin.py:112} INFO - [2020-06-02 15:40:54,563] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:54,575] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:40:54,696] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.139 seconds
[2020-06-02 15:42:54,345] {scheduler_job.py:153} INFO - Started process (PID=1163) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:42:54,353] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:42:54,354] {logging_mixin.py:112} INFO - [2020-06-02 15:42:54,354] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:42:54,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:42:54,724] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.379 seconds
[2020-06-02 15:43:44,389] {scheduler_job.py:153} INFO - Started process (PID=1188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:43:44,395] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:43:44,395] {logging_mixin.py:112} INFO - [2020-06-02 15:43:44,395] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:43:44,407] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:43:44,654] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.265 seconds
[2020-06-02 15:44:34,396] {scheduler_job.py:153} INFO - Started process (PID=1213) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:44:34,402] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:44:34,403] {logging_mixin.py:112} INFO - [2020-06-02 15:44:34,403] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:44:34,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:44:34,689] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.294 seconds
[2020-06-02 15:45:36,206] {scheduler_job.py:153} INFO - Started process (PID=1244) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:45:36,211] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:45:36,212] {logging_mixin.py:112} INFO - [2020-06-02 15:45:36,212] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:45:36,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:45:36,493] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.288 seconds
[2020-06-02 15:46:43,542] {scheduler_job.py:153} INFO - Started process (PID=1275) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:46:43,548] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:46:43,549] {logging_mixin.py:112} INFO - [2020-06-02 15:46:43,548] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:46:43,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:46:43,844] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.302 seconds
[2020-06-02 15:47:45,419] {scheduler_job.py:153} INFO - Started process (PID=1306) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:47:45,424] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:47:45,424] {logging_mixin.py:112} INFO - [2020-06-02 15:47:45,424] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:47:45,437] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:47:45,579] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.160 seconds
[2020-06-02 15:48:35,419] {scheduler_job.py:153} INFO - Started process (PID=1331) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:48:35,424] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:48:35,425] {logging_mixin.py:112} INFO - [2020-06-02 15:48:35,425] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:48:35,436] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:48:35,567] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.149 seconds
[2020-06-02 15:49:25,444] {scheduler_job.py:153} INFO - Started process (PID=1356) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:49:25,449] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:49:25,450] {logging_mixin.py:112} INFO - [2020-06-02 15:49:25,450] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:49:25,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:49:25,656] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:50:15,468] {scheduler_job.py:153} INFO - Started process (PID=1381) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:50:15,473] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:50:15,474] {logging_mixin.py:112} INFO - [2020-06-02 15:50:15,474] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:50:15,485] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:50:15,611] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.143 seconds
[2020-06-02 15:51:05,515] {scheduler_job.py:153} INFO - Started process (PID=1406) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:05,521] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:51:05,522] {logging_mixin.py:112} INFO - [2020-06-02 15:51:05,522] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:05,532] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:05,667] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.152 seconds
[2020-06-02 15:51:55,539] {scheduler_job.py:153} INFO - Started process (PID=1431) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:55,545] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:51:55,545] {logging_mixin.py:112} INFO - [2020-06-02 15:51:55,545] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:55,556] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:51:55,721] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:52:45,586] {scheduler_job.py:153} INFO - Started process (PID=1456) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:52:45,592] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:52:45,592] {logging_mixin.py:112} INFO - [2020-06-02 15:52:45,592] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:52:45,603] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:52:45,712] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.125 seconds
[2020-06-02 15:53:35,589] {scheduler_job.py:153} INFO - Started process (PID=1481) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:53:35,595] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:53:35,595] {logging_mixin.py:112} INFO - [2020-06-02 15:53:35,595] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:53:35,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:53:35,732] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.143 seconds
[2020-06-02 15:54:25,609] {scheduler_job.py:153} INFO - Started process (PID=1506) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:54:25,615] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:54:25,615] {logging_mixin.py:112} INFO - [2020-06-02 15:54:25,615] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:54:25,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:54:25,977] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:55:15,633] {scheduler_job.py:153} INFO - Started process (PID=1531) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:55:15,639] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:55:15,639] {logging_mixin.py:112} INFO - [2020-06-02 15:55:15,639] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:55:15,651] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:55:15,809] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.176 seconds
[2020-06-02 15:56:05,657] {scheduler_job.py:153} INFO - Started process (PID=1556) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:05,662] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:56:05,662] {logging_mixin.py:112} INFO - [2020-06-02 15:56:05,662] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:05,674] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:05,823] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.167 seconds
[2020-06-02 15:56:55,681] {scheduler_job.py:153} INFO - Started process (PID=1581) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:55,688] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:56:55,689] {logging_mixin.py:112} INFO - [2020-06-02 15:56:55,689] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:55,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:56:56,078] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:57:45,730] {scheduler_job.py:153} INFO - Started process (PID=1606) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:57:45,735] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:57:45,736] {logging_mixin.py:112} INFO - [2020-06-02 15:57:45,735] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:57:45,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:57:45,886] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.157 seconds
[2020-06-02 15:58:35,726] {scheduler_job.py:153} INFO - Started process (PID=1631) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:58:35,732] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:58:35,733] {logging_mixin.py:112} INFO - [2020-06-02 15:58:35,732] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:58:35,744] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:58:35,903] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.177 seconds
[2020-06-02 15:59:25,754] {scheduler_job.py:153} INFO - Started process (PID=1656) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:59:25,761] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 15:59:25,761] {logging_mixin.py:112} INFO - [2020-06-02 15:59:25,761] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:59:25,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 15:59:25,962] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:00:15,876] {scheduler_job.py:153} INFO - Started process (PID=1681) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:00:15,881] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:00:15,882] {logging_mixin.py:112} INFO - [2020-06-02 16:00:15,882] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:00:15,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:00:16,084] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.208 seconds
[2020-06-02 16:01:05,900] {scheduler_job.py:153} INFO - Started process (PID=1706) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:05,906] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:01:05,906] {logging_mixin.py:112} INFO - [2020-06-02 16:01:05,906] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:05,918] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:06,083] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.183 seconds
[2020-06-02 16:01:55,935] {scheduler_job.py:153} INFO - Started process (PID=1731) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:55,941] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:01:55,941] {logging_mixin.py:112} INFO - [2020-06-02 16:01:55,941] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:55,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:01:56,150] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:02:45,949] {scheduler_job.py:153} INFO - Started process (PID=1756) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:02:45,955] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:02:45,955] {logging_mixin.py:112} INFO - [2020-06-02 16:02:45,955] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:02:45,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:02:46,128] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.179 seconds
[2020-06-02 16:03:35,973] {scheduler_job.py:153} INFO - Started process (PID=1781) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:03:35,978] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:03:35,979] {logging_mixin.py:112} INFO - [2020-06-02 16:03:35,979] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:03:35,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:03:36,106] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.133 seconds
[2020-06-02 16:04:26,001] {scheduler_job.py:153} INFO - Started process (PID=1806) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:04:26,006] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:04:26,007] {logging_mixin.py:112} INFO - [2020-06-02 16:04:26,007] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:04:26,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:04:26,171] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:05:16,018] {scheduler_job.py:153} INFO - Started process (PID=1831) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:05:16,023] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:05:16,024] {logging_mixin.py:112} INFO - [2020-06-02 16:05:16,024] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:05:16,035] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:05:16,161] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.144 seconds
[2020-06-02 16:06:06,047] {scheduler_job.py:153} INFO - Started process (PID=1856) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:06,052] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:06:06,053] {logging_mixin.py:112} INFO - [2020-06-02 16:06:06,053] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:06,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:06,260] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.213 seconds
[2020-06-02 16:06:56,083] {scheduler_job.py:153} INFO - Started process (PID=1881) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:56,088] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:06:56,089] {logging_mixin.py:112} INFO - [2020-06-02 16:06:56,089] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:56,100] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:06:56,292] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:07:46,096] {scheduler_job.py:153} INFO - Started process (PID=1906) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:07:46,103] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:07:46,103] {logging_mixin.py:112} INFO - [2020-06-02 16:07:46,103] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:07:46,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:07:46,248] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.152 seconds
[2020-06-02 16:08:36,122] {scheduler_job.py:153} INFO - Started process (PID=1931) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:08:36,127] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:08:36,128] {logging_mixin.py:112} INFO - [2020-06-02 16:08:36,128] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:08:36,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:08:36,271] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.149 seconds
[2020-06-02 16:09:26,147] {scheduler_job.py:153} INFO - Started process (PID=1956) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:09:26,152] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:09:26,153] {logging_mixin.py:112} INFO - [2020-06-02 16:09:26,152] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:09:26,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:09:26,356] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:10:16,181] {scheduler_job.py:153} INFO - Started process (PID=1981) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:10:16,187] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:10:16,188] {logging_mixin.py:112} INFO - [2020-06-02 16:10:16,187] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:10:16,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:10:16,338] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.157 seconds
[2020-06-02 16:11:06,250] {scheduler_job.py:153} INFO - Started process (PID=2006) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:06,259] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:11:06,260] {logging_mixin.py:112} INFO - [2020-06-02 16:11:06,260] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:06,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:06,415] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.165 seconds
[2020-06-02 16:11:56,272] {scheduler_job.py:153} INFO - Started process (PID=2031) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:56,277] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:11:56,278] {logging_mixin.py:112} INFO - [2020-06-02 16:11:56,278] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:56,290] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:11:56,545] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:12:46,311] {scheduler_job.py:153} INFO - Started process (PID=2056) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:12:46,319] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:12:46,320] {logging_mixin.py:112} INFO - [2020-06-02 16:12:46,319] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:12:46,336] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:12:46,518] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.207 seconds
[2020-06-02 16:13:36,329] {scheduler_job.py:153} INFO - Started process (PID=2081) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:13:36,336] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:13:36,337] {logging_mixin.py:112} INFO - [2020-06-02 16:13:36,337] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:13:36,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:13:36,504] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.175 seconds
[2020-06-02 16:14:26,355] {scheduler_job.py:153} INFO - Started process (PID=2106) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:14:26,361] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:14:26,362] {logging_mixin.py:112} INFO - [2020-06-02 16:14:26,362] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:14:26,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:14:26,545] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:15:16,411] {scheduler_job.py:153} INFO - Started process (PID=2131) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:15:16,417] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:15:16,417] {logging_mixin.py:112} INFO - [2020-06-02 16:15:16,417] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:15:16,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:15:16,590] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.179 seconds
[2020-06-02 16:16:06,417] {scheduler_job.py:153} INFO - Started process (PID=2156) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:06,422] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:16:06,423] {logging_mixin.py:112} INFO - [2020-06-02 16:16:06,423] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:06,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:06,568] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.151 seconds
[2020-06-02 16:16:56,442] {scheduler_job.py:153} INFO - Started process (PID=2181) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:56,448] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:16:56,448] {logging_mixin.py:112} INFO - [2020-06-02 16:16:56,448] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:56,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:16:56,599] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:17:46,468] {scheduler_job.py:153} INFO - Started process (PID=2206) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:17:46,474] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:17:46,475] {logging_mixin.py:112} INFO - [2020-06-02 16:17:46,474] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:17:46,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:17:46,633] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.165 seconds
[2020-06-02 16:18:36,496] {scheduler_job.py:153} INFO - Started process (PID=2231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:18:36,503] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:18:36,504] {logging_mixin.py:112} INFO - [2020-06-02 16:18:36,504] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:18:36,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:18:36,655] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.159 seconds
[2020-06-02 16:19:26,526] {scheduler_job.py:153} INFO - Started process (PID=2256) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:19:26,533] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:19:26,563] {logging_mixin.py:112} INFO - [2020-06-02 16:19:26,563] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:19:26,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:19:26,731] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:20:16,566] {scheduler_job.py:153} INFO - Started process (PID=2281) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:20:16,572] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:20:16,572] {logging_mixin.py:112} INFO - [2020-06-02 16:20:16,572] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:20:16,583] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:20:16,721] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.154 seconds
[2020-06-02 16:21:06,585] {scheduler_job.py:153} INFO - Started process (PID=2306) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:06,591] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:21:06,591] {logging_mixin.py:112} INFO - [2020-06-02 16:21:06,591] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:06,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:06,720] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.135 seconds
[2020-06-02 16:21:56,613] {scheduler_job.py:153} INFO - Started process (PID=2331) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:56,619] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:21:56,619] {logging_mixin.py:112} INFO - [2020-06-02 16:21:56,619] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:56,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:21:56,829] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:22:46,640] {scheduler_job.py:153} INFO - Started process (PID=2356) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:22:46,645] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:22:46,646] {logging_mixin.py:112} INFO - [2020-06-02 16:22:46,646] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:22:46,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:22:46,797] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.158 seconds
[2020-06-02 16:23:36,667] {scheduler_job.py:153} INFO - Started process (PID=2381) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:23:36,672] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:23:36,673] {logging_mixin.py:112} INFO - [2020-06-02 16:23:36,673] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:23:36,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:23:36,786] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.120 seconds
[2020-06-02 16:24:26,697] {scheduler_job.py:153} INFO - Started process (PID=2406) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:24:26,703] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:24:26,704] {logging_mixin.py:112} INFO - [2020-06-02 16:24:26,704] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:24:26,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:24:26,851] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:25:16,749] {scheduler_job.py:153} INFO - Started process (PID=2431) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:25:16,754] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:25:16,755] {logging_mixin.py:112} INFO - [2020-06-02 16:25:16,755] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:25:16,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:25:16,885] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.136 seconds
[2020-06-02 16:26:06,749] {scheduler_job.py:153} INFO - Started process (PID=2456) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:06,755] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:26:06,756] {logging_mixin.py:112} INFO - [2020-06-02 16:26:06,755] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:06,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:06,863] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.114 seconds
[2020-06-02 16:26:56,780] {scheduler_job.py:153} INFO - Started process (PID=2481) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:56,786] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:26:56,786] {logging_mixin.py:112} INFO - [2020-06-02 16:26:56,786] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:56,800] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:26:56,979] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.199 seconds
[2020-06-02 16:27:46,806] {scheduler_job.py:153} INFO - Started process (PID=2506) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:27:46,812] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:27:46,812] {logging_mixin.py:112} INFO - [2020-06-02 16:27:46,812] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:27:46,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:27:46,961] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.155 seconds
[2020-06-02 16:28:36,835] {scheduler_job.py:153} INFO - Started process (PID=2531) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:28:36,841] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:28:36,841] {logging_mixin.py:112} INFO - [2020-06-02 16:28:36,841] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:28:36,854] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:28:36,974] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.139 seconds
[2020-06-02 16:29:26,861] {scheduler_job.py:153} INFO - Started process (PID=2556) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:29:26,867] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:29:26,868] {logging_mixin.py:112} INFO - [2020-06-02 16:29:26,868] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:29:26,880] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:29:27,049] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:30:16,933] {scheduler_job.py:153} INFO - Started process (PID=2581) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:30:16,939] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:30:16,940] {logging_mixin.py:112} INFO - [2020-06-02 16:30:16,940] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:30:16,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:30:17,094] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.161 seconds
[2020-06-02 16:31:06,919] {scheduler_job.py:153} INFO - Started process (PID=2606) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:06,924] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:31:06,925] {logging_mixin.py:112} INFO - [2020-06-02 16:31:06,925] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:06,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:07,097] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.178 seconds
[2020-06-02 16:31:56,946] {scheduler_job.py:153} INFO - Started process (PID=2631) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:56,952] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:31:56,952] {logging_mixin.py:112} INFO - [2020-06-02 16:31:56,952] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:56,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:31:57,136] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:32:46,973] {scheduler_job.py:153} INFO - Started process (PID=2656) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:32:46,979] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:32:46,980] {logging_mixin.py:112} INFO - [2020-06-02 16:32:46,979] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:32:46,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:32:47,154] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.180 seconds
[2020-06-02 16:33:37,003] {scheduler_job.py:153} INFO - Started process (PID=2681) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:33:37,009] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:33:37,010] {logging_mixin.py:112} INFO - [2020-06-02 16:33:37,009] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:33:37,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:33:37,152] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.149 seconds
[2020-06-02 16:34:27,034] {scheduler_job.py:153} INFO - Started process (PID=2706) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:34:27,040] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:34:27,040] {logging_mixin.py:112} INFO - [2020-06-02 16:34:27,040] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:34:27,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:34:27,204] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.170 seconds
[2020-06-02 16:35:17,104] {scheduler_job.py:153} INFO - Started process (PID=2731) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:35:17,110] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:35:17,111] {logging_mixin.py:112} INFO - [2020-06-02 16:35:17,111] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:35:17,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:35:17,247] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.144 seconds
[2020-06-02 16:36:07,096] {scheduler_job.py:153} INFO - Started process (PID=2756) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:07,103] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:36:07,104] {logging_mixin.py:112} INFO - [2020-06-02 16:36:07,104] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:07,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:07,238] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.142 seconds
[2020-06-02 16:36:57,126] {scheduler_job.py:153} INFO - Started process (PID=2781) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:57,131] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:36:57,132] {logging_mixin.py:112} INFO - [2020-06-02 16:36:57,132] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:57,143] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:36:57,335] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:37:47,156] {scheduler_job.py:153} INFO - Started process (PID=2806) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:37:47,162] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:37:47,162] {logging_mixin.py:112} INFO - [2020-06-02 16:37:47,162] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:37:47,174] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:37:47,317] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.161 seconds
[2020-06-02 16:38:37,181] {scheduler_job.py:153} INFO - Started process (PID=2831) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:38:37,187] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:38:37,188] {logging_mixin.py:112} INFO - [2020-06-02 16:38:37,187] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:38:37,200] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:38:37,339] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.157 seconds
[2020-06-02 16:39:27,210] {scheduler_job.py:153} INFO - Started process (PID=2856) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:39:27,216] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:39:27,216] {logging_mixin.py:112} INFO - [2020-06-02 16:39:27,216] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:39:27,228] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:39:27,390] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:40:17,243] {scheduler_job.py:153} INFO - Started process (PID=2881) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:40:17,248] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:40:17,248] {logging_mixin.py:112} INFO - [2020-06-02 16:40:17,248] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:40:17,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:40:17,404] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-02 16:41:07,261] {scheduler_job.py:153} INFO - Started process (PID=2906) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:41:07,268] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:41:07,268] {logging_mixin.py:112} INFO - [2020-06-02 16:41:07,268] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:41:07,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:41:07,438] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.177 seconds
[2020-06-02 16:44:31,070] {scheduler_job.py:153} INFO - Started process (PID=2935) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:44:31,077] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:44:31,078] {logging_mixin.py:112} INFO - [2020-06-02 16:44:31,078] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:44:31,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:44:32,144] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 1.074 seconds
[2020-06-02 16:45:21,850] {scheduler_job.py:153} INFO - Started process (PID=2960) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:45:21,857] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-02 16:45:21,858] {logging_mixin.py:112} INFO - [2020-06-02 16:45:21,858] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:45:21,871] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-02 16:45:22,117] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.266 seconds
[2020-06-03 14:51:10,156] {scheduler_job.py:153} INFO - Started process (PID=137) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:51:10,184] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:51:10,184] {logging_mixin.py:112} INFO - [2020-06-03 14:51:10,184] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:51:10,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:51:10,454] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.298 seconds
[2020-06-03 14:52:00,257] {scheduler_job.py:153} INFO - Started process (PID=164) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:00,266] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:52:00,267] {logging_mixin.py:112} INFO - [2020-06-03 14:52:00,267] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:00,286] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:00,647] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.390 seconds
[2020-06-03 14:52:50,348] {scheduler_job.py:153} INFO - Started process (PID=190) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:50,362] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:52:50,364] {logging_mixin.py:112} INFO - [2020-06-03 14:52:50,363] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:50,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:52:50,910] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.562 seconds
[2020-06-03 14:53:36,812] {scheduler_job.py:153} INFO - Started process (PID=219) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:53:36,817] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:53:36,818] {logging_mixin.py:112} INFO - [2020-06-03 14:53:36,818] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:53:36,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:53:37,132] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.320 seconds
[2020-06-03 14:54:51,535] {scheduler_job.py:153} INFO - Started process (PID=258) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:54:51,540] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:54:51,540] {logging_mixin.py:112} INFO - [2020-06-03 14:54:51,540] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:54:51,551] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:54:51,803] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.269 seconds
[2020-06-03 14:56:16,145] {scheduler_job.py:153} INFO - Started process (PID=298) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:56:16,150] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:56:16,151] {logging_mixin.py:112} INFO - [2020-06-03 14:56:16,150] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:56:16,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:56:16,446] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.301 seconds
[2020-06-03 14:57:35,978] {scheduler_job.py:153} INFO - Started process (PID=337) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:57:35,988] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:57:35,990] {logging_mixin.py:112} INFO - [2020-06-03 14:57:35,989] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:57:36,351] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:57:36,645] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.668 seconds
[2020-06-03 14:58:26,746] {scheduler_job.py:153} INFO - Started process (PID=364) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:58:26,776] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:58:26,777] {logging_mixin.py:112} INFO - [2020-06-03 14:58:26,777] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:58:26,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:58:26,985] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.240 seconds
[2020-06-03 14:59:17,055] {scheduler_job.py:153} INFO - Started process (PID=390) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:59:17,061] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 14:59:17,061] {logging_mixin.py:112} INFO - [2020-06-03 14:59:17,061] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:59:17,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 14:59:17,677] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.622 seconds
[2020-06-03 15:00:08,893] {scheduler_job.py:153} INFO - Started process (PID=417) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:08,902] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:00:08,903] {logging_mixin.py:112} INFO - [2020-06-03 15:00:08,903] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:08,917] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:09,346] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.453 seconds
[2020-06-03 15:00:58,960] {scheduler_job.py:153} INFO - Started process (PID=443) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:58,969] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:00:58,970] {logging_mixin.py:112} INFO - [2020-06-03 15:00:58,970] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:59,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:00:59,640] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.680 seconds
[2020-06-03 15:01:49,099] {scheduler_job.py:153} INFO - Started process (PID=470) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:01:49,104] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:01:49,105] {logging_mixin.py:112} INFO - [2020-06-03 15:01:49,105] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:01:49,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:01:51,460] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:02:40,208] {scheduler_job.py:153} INFO - Started process (PID=496) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:02:40,214] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:02:40,214] {logging_mixin.py:112} INFO - [2020-06-03 15:02:40,214] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:02:40,227] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:02:40,519] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.311 seconds
[2020-06-03 15:03:30,943] {scheduler_job.py:153} INFO - Started process (PID=522) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:03:30,949] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:03:30,949] {logging_mixin.py:112} INFO - [2020-06-03 15:03:30,949] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:03:30,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:03:31,175] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.233 seconds
[2020-06-03 15:04:20,987] {scheduler_job.py:153} INFO - Started process (PID=549) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:04:20,993] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:04:20,994] {logging_mixin.py:112} INFO - [2020-06-03 15:04:20,994] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:04:21,006] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:04:21,226] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:05:11,212] {scheduler_job.py:153} INFO - Started process (PID=575) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:05:11,220] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:05:11,220] {logging_mixin.py:112} INFO - [2020-06-03 15:05:11,220] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:05:11,236] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:05:11,387] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.175 seconds
[2020-06-03 15:06:01,197] {scheduler_job.py:153} INFO - Started process (PID=602) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:01,203] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:06:01,203] {logging_mixin.py:112} INFO - [2020-06-03 15:06:01,203] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:01,215] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:01,339] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.142 seconds
[2020-06-03 15:06:51,488] {scheduler_job.py:153} INFO - Started process (PID=628) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:51,494] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:06:51,494] {logging_mixin.py:112} INFO - [2020-06-03 15:06:51,494] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:51,506] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:06:51,702] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:07:41,426] {scheduler_job.py:153} INFO - Started process (PID=655) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:07:41,436] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:07:41,437] {logging_mixin.py:112} INFO - [2020-06-03 15:07:41,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:07:41,464] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:07:41,606] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.180 seconds
[2020-06-03 15:08:31,487] {scheduler_job.py:153} INFO - Started process (PID=682) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:08:31,493] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:08:31,494] {logging_mixin.py:112} INFO - [2020-06-03 15:08:31,493] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:08:31,520] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:08:31,650] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.162 seconds
[2020-06-03 15:09:21,570] {scheduler_job.py:153} INFO - Started process (PID=708) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:09:21,575] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:09:21,576] {logging_mixin.py:112} INFO - [2020-06-03 15:09:21,576] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:09:21,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:09:21,746] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:10:26,062] {scheduler_job.py:153} INFO - Started process (PID=733) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:10:26,069] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:10:26,069] {logging_mixin.py:112} INFO - [2020-06-03 15:10:26,069] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:10:26,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:10:26,436] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.373 seconds
[2020-06-03 15:11:15,917] {scheduler_job.py:153} INFO - Started process (PID=760) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:11:15,922] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:11:15,922] {logging_mixin.py:112} INFO - [2020-06-03 15:11:15,922] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:11:15,933] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:11:16,177] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.260 seconds
[2020-06-03 15:12:05,996] {scheduler_job.py:153} INFO - Started process (PID=786) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:12:06,007] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:12:06,008] {logging_mixin.py:112} INFO - [2020-06-03 15:12:06,008] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:12:06,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:12:06,279] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.283 seconds
[2020-06-03 15:13:21,650] {scheduler_job.py:153} INFO - Started process (PID=826) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:13:21,656] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:13:21,657] {logging_mixin.py:112} INFO - [2020-06-03 15:13:21,656] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:13:21,800] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:13:21,912] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.262 seconds
[2020-06-03 15:14:46,493] {scheduler_job.py:153} INFO - Started process (PID=865) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:14:46,499] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:14:46,499] {logging_mixin.py:112} INFO - [2020-06-03 15:14:46,499] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:14:46,650] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:14:46,850] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.357 seconds
[2020-06-03 15:15:36,558] {scheduler_job.py:153} INFO - Started process (PID=892) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:15:36,564] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:15:36,564] {logging_mixin.py:112} INFO - [2020-06-03 15:15:36,564] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:15:36,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:15:36,755] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:17:00,127] {scheduler_job.py:153} INFO - Started process (PID=932) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:00,133] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:17:00,137] {logging_mixin.py:112} INFO - [2020-06-03 15:17:00,137] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:00,157] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:00,336] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.209 seconds
[2020-06-03 15:17:50,155] {scheduler_job.py:153} INFO - Started process (PID=958) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:50,161] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:17:50,162] {logging_mixin.py:112} INFO - [2020-06-03 15:17:50,162] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:50,173] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:17:50,332] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:18:40,170] {scheduler_job.py:153} INFO - Started process (PID=985) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:18:40,175] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:18:40,176] {logging_mixin.py:112} INFO - [2020-06-03 15:18:40,176] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:18:40,186] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:18:40,387] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.217 seconds
[2020-06-03 15:19:30,193] {scheduler_job.py:153} INFO - Started process (PID=1011) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:19:30,199] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:19:30,199] {logging_mixin.py:112} INFO - [2020-06-03 15:19:30,199] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:19:30,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:19:30,353] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.160 seconds
[2020-06-03 15:20:20,216] {scheduler_job.py:153} INFO - Started process (PID=1038) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:20:20,221] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:20:20,222] {logging_mixin.py:112} INFO - [2020-06-03 15:20:20,222] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:20:20,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:20:20,407] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:22:00,526] {scheduler_job.py:153} INFO - Started process (PID=1095) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:00,545] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:22:00,546] {logging_mixin.py:112} INFO - [2020-06-03 15:22:00,546] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:00,568] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:00,929] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.403 seconds
[2020-06-03 15:22:50,560] {scheduler_job.py:153} INFO - Started process (PID=1122) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:50,566] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:22:50,567] {logging_mixin.py:112} INFO - [2020-06-03 15:22:50,567] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:50,580] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:22:50,841] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.281 seconds
[2020-06-03 15:23:52,534] {scheduler_job.py:153} INFO - Started process (PID=1155) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:23:52,539] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:23:52,540] {logging_mixin.py:112} INFO - [2020-06-03 15:23:52,540] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:23:52,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:23:52,830] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.296 seconds
[2020-06-03 15:24:59,950] {scheduler_job.py:153} INFO - Started process (PID=1188) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:24:59,956] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:24:59,956] {logging_mixin.py:112} INFO - [2020-06-03 15:24:59,956] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:25:00,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:25:00,251] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.301 seconds
[2020-06-03 15:26:02,121] {scheduler_job.py:153} INFO - Started process (PID=1221) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:02,126] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:26:02,127] {logging_mixin.py:112} INFO - [2020-06-03 15:26:02,127] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:02,277] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:02,405] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.284 seconds
[2020-06-03 15:26:52,228] {scheduler_job.py:153} INFO - Started process (PID=1247) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:52,233] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:26:52,234] {logging_mixin.py:112} INFO - [2020-06-03 15:26:52,234] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:52,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:26:52,450] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.222 seconds
[2020-06-03 15:27:42,263] {scheduler_job.py:153} INFO - Started process (PID=1274) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:27:42,269] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:27:42,269] {logging_mixin.py:112} INFO - [2020-06-03 15:27:42,269] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:27:42,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:27:42,622] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:28:32,367] {scheduler_job.py:153} INFO - Started process (PID=1301) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:28:32,377] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:28:32,378] {logging_mixin.py:112} INFO - [2020-06-03 15:28:32,378] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:28:32,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:28:32,597] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.230 seconds
[2020-06-03 15:29:22,336] {scheduler_job.py:153} INFO - Started process (PID=1327) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:29:22,341] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:29:22,342] {logging_mixin.py:112} INFO - [2020-06-03 15:29:22,342] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:29:22,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:29:22,528] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py took 0.193 seconds
[2020-06-03 15:30:12,431] {scheduler_job.py:153} INFO - Started process (PID=1354) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:30:12,437] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2020-06-03 15:30:12,437] {logging_mixin.py:112} INFO - [2020-06-03 15:30:12,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:30:12,451] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/example_bash_operator.py
[2020-06-03 15:30:12,628] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1516, in sync_to_db
    orm_dag.tags = self.get_dagtags(session=session)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 70, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1555, in get_dagtags
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
