[2020-05-31 21:01:49,593] {scheduler_job.py:153} INFO - Started process (PID=6117) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:01:49,598] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:01:49,598] {logging_mixin.py:112} INFO - [2020-05-31 21:01:49,598] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:01:49,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:01:49,741] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.149 seconds
[2020-05-31 21:02:37,638] {scheduler_job.py:153} INFO - Started process (PID=6145) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:02:37,642] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:02:37,643] {logging_mixin.py:112} INFO - [2020-05-31 21:02:37,643] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:02:37,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:02:37,780] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.143 seconds
[2020-05-31 21:03:25,607] {scheduler_job.py:153} INFO - Started process (PID=6177) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:03:25,612] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:03:25,613] {logging_mixin.py:112} INFO - [2020-05-31 21:03:25,613] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:03:25,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:03:25,791] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:04:13,628] {scheduler_job.py:153} INFO - Started process (PID=6205) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:04:13,633] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:04:13,634] {logging_mixin.py:112} INFO - [2020-05-31 21:04:13,634] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:04:13,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:04:13,774] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.146 seconds
[2020-05-31 21:05:01,652] {scheduler_job.py:153} INFO - Started process (PID=6237) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:01,657] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:05:01,657] {logging_mixin.py:112} INFO - [2020-05-31 21:05:01,657] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:01,666] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:01,868] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:05:49,676] {scheduler_job.py:153} INFO - Started process (PID=6265) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:49,681] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:05:49,681] {logging_mixin.py:112} INFO - [2020-05-31 21:05:49,681] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:49,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:05:49,856] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:06:37,702] {scheduler_job.py:153} INFO - Started process (PID=6297) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:06:37,707] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:06:37,708] {logging_mixin.py:112} INFO - [2020-05-31 21:06:37,708] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:06:37,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:06:37,889] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:07:25,725] {scheduler_job.py:153} INFO - Started process (PID=6325) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:07:25,730] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:07:25,730] {logging_mixin.py:112} INFO - [2020-05-31 21:07:25,730] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:07:25,738] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:07:25,850] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.126 seconds
[2020-05-31 21:08:13,750] {scheduler_job.py:153} INFO - Started process (PID=6357) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:08:13,755] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:08:13,756] {logging_mixin.py:112} INFO - [2020-05-31 21:08:13,756] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:08:13,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:08:13,900] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:01,774] {scheduler_job.py:153} INFO - Started process (PID=6385) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:01,779] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:09:01,780] {logging_mixin.py:112} INFO - [2020-05-31 21:09:01,779] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:01,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:01,955] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:09:49,798] {scheduler_job.py:153} INFO - Started process (PID=6417) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:49,803] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:09:49,803] {logging_mixin.py:112} INFO - [2020-05-31 21:09:49,803] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:49,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:09:49,966] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:10:37,822] {scheduler_job.py:153} INFO - Started process (PID=6445) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:10:37,827] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:10:37,828] {logging_mixin.py:112} INFO - [2020-05-31 21:10:37,828] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:10:37,840] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:10:37,987] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:11:25,846] {scheduler_job.py:153} INFO - Started process (PID=6477) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:11:25,856] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:11:25,857] {logging_mixin.py:112} INFO - [2020-05-31 21:11:25,856] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:11:25,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:11:25,998] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:12:13,883] {scheduler_job.py:153} INFO - Started process (PID=6509) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:12:13,890] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:12:13,890] {logging_mixin.py:112} INFO - [2020-05-31 21:12:13,890] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:12:13,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:12:14,213] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:13:01,894] {scheduler_job.py:153} INFO - Started process (PID=6537) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:01,900] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:13:01,900] {logging_mixin.py:112} INFO - [2020-05-31 21:13:01,900] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:01,909] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:02,078] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:13:49,918] {scheduler_job.py:153} INFO - Started process (PID=6569) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:49,923] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:13:49,924] {logging_mixin.py:112} INFO - [2020-05-31 21:13:49,924] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:49,933] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:13:50,064] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:14:37,940] {scheduler_job.py:153} INFO - Started process (PID=6597) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:14:37,945] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:14:37,946] {logging_mixin.py:112} INFO - [2020-05-31 21:14:37,946] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:14:37,955] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:14:38,108] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:15:25,994] {scheduler_job.py:153} INFO - Started process (PID=6629) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:15:26,000] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:15:26,000] {logging_mixin.py:112} INFO - [2020-05-31 21:15:26,000] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:15:26,010] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:15:26,163] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:16:14,041] {scheduler_job.py:153} INFO - Started process (PID=6657) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:16:14,046] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:16:14,048] {logging_mixin.py:112} INFO - [2020-05-31 21:16:14,047] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:16:14,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:16:14,332] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:17:02,048] {scheduler_job.py:153} INFO - Started process (PID=6689) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:02,054] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:17:02,055] {logging_mixin.py:112} INFO - [2020-05-31 21:17:02,054] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:02,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:02,207] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:17:50,071] {scheduler_job.py:153} INFO - Started process (PID=6717) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:50,076] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:17:50,077] {logging_mixin.py:112} INFO - [2020-05-31 21:17:50,076] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:50,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:17:50,240] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:18:38,098] {scheduler_job.py:153} INFO - Started process (PID=6749) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:18:38,103] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:18:38,103] {logging_mixin.py:112} INFO - [2020-05-31 21:18:38,103] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:18:38,111] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:18:38,273] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:19:26,134] {scheduler_job.py:153} INFO - Started process (PID=6777) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:19:26,140] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:19:26,140] {logging_mixin.py:112} INFO - [2020-05-31 21:19:26,140] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:19:26,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:19:26,356] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.223 seconds
[2020-05-31 21:20:14,159] {scheduler_job.py:153} INFO - Started process (PID=6809) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:20:14,164] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:20:14,165] {logging_mixin.py:112} INFO - [2020-05-31 21:20:14,165] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:20:14,174] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:20:14,405] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:21:02,183] {scheduler_job.py:153} INFO - Started process (PID=6837) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:02,188] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:21:02,188] {logging_mixin.py:112} INFO - [2020-05-31 21:21:02,188] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:02,197] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:02,393] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:21:50,212] {scheduler_job.py:153} INFO - Started process (PID=6869) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:50,217] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:21:50,217] {logging_mixin.py:112} INFO - [2020-05-31 21:21:50,217] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:50,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:21:50,349] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:22:38,234] {scheduler_job.py:153} INFO - Started process (PID=6897) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:22:38,241] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:22:38,242] {logging_mixin.py:112} INFO - [2020-05-31 21:22:38,241] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:22:38,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:22:38,427] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:23:26,261] {scheduler_job.py:153} INFO - Started process (PID=6929) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:23:26,267] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:23:26,268] {logging_mixin.py:112} INFO - [2020-05-31 21:23:26,267] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:23:26,276] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:23:26,404] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:24:14,285] {scheduler_job.py:153} INFO - Started process (PID=6957) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:24:14,290] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:24:14,291] {logging_mixin.py:112} INFO - [2020-05-31 21:24:14,291] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:24:14,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:24:14,460] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:02,314] {scheduler_job.py:153} INFO - Started process (PID=6989) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:02,319] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:25:02,320] {logging_mixin.py:112} INFO - [2020-05-31 21:25:02,320] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:02,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:02,482] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:25:50,347] {scheduler_job.py:153} INFO - Started process (PID=7018) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:50,353] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:25:50,354] {logging_mixin.py:112} INFO - [2020-05-31 21:25:50,353] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:50,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:25:50,492] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:26:38,364] {scheduler_job.py:153} INFO - Started process (PID=7049) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:26:38,369] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:26:38,370] {logging_mixin.py:112} INFO - [2020-05-31 21:26:38,370] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:26:38,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:26:38,670] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:27:26,391] {scheduler_job.py:153} INFO - Started process (PID=7081) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:27:26,396] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:27:26,397] {logging_mixin.py:112} INFO - [2020-05-31 21:27:26,397] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:27:26,406] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:27:26,536] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:28:14,417] {scheduler_job.py:153} INFO - Started process (PID=7109) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:28:14,424] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:28:14,425] {logging_mixin.py:112} INFO - [2020-05-31 21:28:14,425] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:28:14,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:28:14,580] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:02,442] {scheduler_job.py:153} INFO - Started process (PID=7141) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:02,447] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:29:02,448] {logging_mixin.py:112} INFO - [2020-05-31 21:29:02,448] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:02,457] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:02,591] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:29:50,464] {scheduler_job.py:153} INFO - Started process (PID=7169) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:50,469] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:29:50,470] {logging_mixin.py:112} INFO - [2020-05-31 21:29:50,470] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:50,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:29:50,646] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:30:38,490] {scheduler_job.py:153} INFO - Started process (PID=7201) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:30:38,495] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:30:38,496] {logging_mixin.py:112} INFO - [2020-05-31 21:30:38,495] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:30:38,504] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:30:38,646] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:31:26,519] {scheduler_job.py:153} INFO - Started process (PID=7229) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:31:26,524] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:31:26,525] {logging_mixin.py:112} INFO - [2020-05-31 21:31:26,525] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:31:26,534] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:31:26,689] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:32:14,544] {scheduler_job.py:153} INFO - Started process (PID=7261) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:32:14,550] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:32:14,550] {logging_mixin.py:112} INFO - [2020-05-31 21:32:14,550] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:32:14,560] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:32:14,701] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:33:02,572] {scheduler_job.py:153} INFO - Started process (PID=7289) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:02,577] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:33:02,577] {logging_mixin.py:112} INFO - [2020-05-31 21:33:02,577] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:02,586] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:02,755] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:33:50,592] {scheduler_job.py:153} INFO - Started process (PID=7321) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:50,599] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:33:50,600] {logging_mixin.py:112} INFO - [2020-05-31 21:33:50,599] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:50,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:33:50,706] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.114 seconds
[2020-05-31 21:34:38,615] {scheduler_job.py:153} INFO - Started process (PID=7349) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:34:38,622] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:34:38,622] {logging_mixin.py:112} INFO - [2020-05-31 21:34:38,622] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:34:38,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:34:38,799] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:35:26,637] {scheduler_job.py:153} INFO - Started process (PID=7381) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:35:26,642] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:35:26,643] {logging_mixin.py:112} INFO - [2020-05-31 21:35:26,643] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:35:26,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:35:26,777] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:36:14,691] {scheduler_job.py:153} INFO - Started process (PID=7409) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:36:14,697] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:36:14,697] {logging_mixin.py:112} INFO - [2020-05-31 21:36:14,697] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:36:14,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:36:14,838] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.146 seconds
[2020-05-31 21:37:02,680] {scheduler_job.py:153} INFO - Started process (PID=7441) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:02,685] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:37:02,686] {logging_mixin.py:112} INFO - [2020-05-31 21:37:02,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:02,695] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:02,843] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:37:50,702] {scheduler_job.py:153} INFO - Started process (PID=7469) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:50,707] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:37:50,708] {logging_mixin.py:112} INFO - [2020-05-31 21:37:50,708] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:50,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:37:50,831] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:38:38,724] {scheduler_job.py:153} INFO - Started process (PID=7501) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:38:38,729] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:38:38,730] {logging_mixin.py:112} INFO - [2020-05-31 21:38:38,730] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:38:38,739] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:38:38,886] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:39:26,755] {scheduler_job.py:153} INFO - Started process (PID=7533) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:39:26,760] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:39:26,761] {logging_mixin.py:112} INFO - [2020-05-31 21:39:26,761] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:39:26,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:39:26,916] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.162 seconds
[2020-05-31 21:40:14,771] {scheduler_job.py:153} INFO - Started process (PID=7561) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:40:14,778] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:40:14,779] {logging_mixin.py:112} INFO - [2020-05-31 21:40:14,779] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:40:14,787] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:40:14,897] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:02,794] {scheduler_job.py:153} INFO - Started process (PID=7593) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:02,800] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:41:02,801] {logging_mixin.py:112} INFO - [2020-05-31 21:41:02,801] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:02,809] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:02,953] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:41:50,815] {scheduler_job.py:153} INFO - Started process (PID=7621) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:50,821] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:41:50,822] {logging_mixin.py:112} INFO - [2020-05-31 21:41:50,822] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:50,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:41:50,963] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:42:38,838] {scheduler_job.py:153} INFO - Started process (PID=7653) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:42:38,843] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:42:38,843] {logging_mixin.py:112} INFO - [2020-05-31 21:42:38,843] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:42:38,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:42:38,974] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:43:26,862] {scheduler_job.py:153} INFO - Started process (PID=7681) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:43:26,867] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:43:26,867] {logging_mixin.py:112} INFO - [2020-05-31 21:43:26,867] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:43:26,876] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:43:27,002] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.140 seconds
[2020-05-31 21:44:14,885] {scheduler_job.py:153} INFO - Started process (PID=7713) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:44:14,890] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:44:14,891] {logging_mixin.py:112} INFO - [2020-05-31 21:44:14,891] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:44:14,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:44:15,063] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:45:02,909] {scheduler_job.py:153} INFO - Started process (PID=7741) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:02,914] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:45:02,915] {logging_mixin.py:112} INFO - [2020-05-31 21:45:02,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:02,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:03,085] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:45:50,930] {scheduler_job.py:153} INFO - Started process (PID=7773) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:50,936] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:45:50,937] {logging_mixin.py:112} INFO - [2020-05-31 21:45:50,937] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:50,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:45:51,084] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:46:38,953] {scheduler_job.py:153} INFO - Started process (PID=7801) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:46:38,958] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:46:38,959] {logging_mixin.py:112} INFO - [2020-05-31 21:46:38,959] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:46:38,967] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:46:39,150] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:47:26,975] {scheduler_job.py:153} INFO - Started process (PID=7833) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:47:26,981] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:47:26,981] {logging_mixin.py:112} INFO - [2020-05-31 21:47:26,981] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:47:26,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:47:27,150] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:48:15,007] {scheduler_job.py:153} INFO - Started process (PID=7861) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:48:15,012] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:48:15,013] {logging_mixin.py:112} INFO - [2020-05-31 21:48:15,012] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:48:15,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:48:15,172] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:03,063] {scheduler_job.py:153} INFO - Started process (PID=7893) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:03,067] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:49:03,068] {logging_mixin.py:112} INFO - [2020-05-31 21:49:03,068] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:03,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:03,239] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:49:51,110] {scheduler_job.py:153} INFO - Started process (PID=7921) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:51,115] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:49:51,116] {logging_mixin.py:112} INFO - [2020-05-31 21:49:51,116] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:51,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:49:51,283] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:50:39,153] {scheduler_job.py:153} INFO - Started process (PID=7953) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:50:39,158] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:50:39,159] {logging_mixin.py:112} INFO - [2020-05-31 21:50:39,159] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:50:39,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:50:39,349] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:51:27,194] {scheduler_job.py:153} INFO - Started process (PID=7981) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:51:27,201] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:51:27,201] {logging_mixin.py:112} INFO - [2020-05-31 21:51:27,201] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:51:27,209] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:51:27,349] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:52:15,237] {scheduler_job.py:153} INFO - Started process (PID=8013) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:52:15,242] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:52:15,243] {logging_mixin.py:112} INFO - [2020-05-31 21:52:15,243] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:52:15,251] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:52:15,382] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:03,285] {scheduler_job.py:153} INFO - Started process (PID=8041) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:03,290] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:53:03,291] {logging_mixin.py:112} INFO - [2020-05-31 21:53:03,291] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:03,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:03,459] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:53:51,325] {scheduler_job.py:153} INFO - Started process (PID=8073) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:51,330] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:53:51,331] {logging_mixin.py:112} INFO - [2020-05-31 21:53:51,331] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:51,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:53:51,482] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:54:39,373] {scheduler_job.py:153} INFO - Started process (PID=8105) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:54:39,378] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:54:39,379] {logging_mixin.py:112} INFO - [2020-05-31 21:54:39,379] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:54:39,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:54:39,681] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:55:27,414] {scheduler_job.py:153} INFO - Started process (PID=8133) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:55:27,419] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:55:27,420] {logging_mixin.py:112} INFO - [2020-05-31 21:55:27,420] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:55:27,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:55:27,570] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:56:15,482] {scheduler_job.py:153} INFO - Started process (PID=8165) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:56:15,487] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:56:15,487] {logging_mixin.py:112} INFO - [2020-05-31 21:56:15,487] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:56:15,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:56:15,632] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.151 seconds
[2020-05-31 21:57:03,503] {scheduler_job.py:153} INFO - Started process (PID=8193) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:03,509] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:57:03,510] {logging_mixin.py:112} INFO - [2020-05-31 21:57:03,510] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:03,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:03,714] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:57:51,549] {scheduler_job.py:153} INFO - Started process (PID=8225) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:51,555] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:57:51,555] {logging_mixin.py:112} INFO - [2020-05-31 21:57:51,555] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:51,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:57:51,781] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:58:39,595] {scheduler_job.py:153} INFO - Started process (PID=8253) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:58:39,600] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:58:39,601] {logging_mixin.py:112} INFO - [2020-05-31 21:58:39,601] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:58:39,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:58:39,813] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 21:59:27,638] {scheduler_job.py:153} INFO - Started process (PID=8285) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:59:27,643] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 21:59:27,643] {logging_mixin.py:112} INFO - [2020-05-31 21:59:27,643] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:59:27,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 21:59:27,836] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:00:15,681] {scheduler_job.py:153} INFO - Started process (PID=8313) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:00:15,686] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 22:00:15,687] {logging_mixin.py:112} INFO - [2020-05-31 22:00:15,686] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:00:15,695] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:00:15,858] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:01:03,738] {scheduler_job.py:153} INFO - Started process (PID=8345) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:03,743] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 22:01:03,744] {logging_mixin.py:112} INFO - [2020-05-31 22:01:03,744] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:03,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:03,888] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.150 seconds
[2020-05-31 22:01:51,784] {scheduler_job.py:153} INFO - Started process (PID=8373) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:51,791] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 22:01:51,791] {logging_mixin.py:112} INFO - [2020-05-31 22:01:51,791] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:51,799] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:01:51,925] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:02:39,828] {scheduler_job.py:153} INFO - Started process (PID=8405) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:02:39,834] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 22:02:39,835] {logging_mixin.py:112} INFO - [2020-05-31 22:02:39,835] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:02:39,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:02:39,991] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-05-31 22:03:28,020] {scheduler_job.py:153} INFO - Started process (PID=8433) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:03:28,026] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-05-31 22:03:28,027] {logging_mixin.py:112} INFO - [2020-05-31 22:03:28,027] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:03:28,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-05-31 22:03:28,302] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 14:33:04,710] {scheduler_job.py:153} INFO - Started process (PID=82) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:04,739] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:33:04,739] {logging_mixin.py:112} INFO - [2020-06-01 14:33:04,739] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:04,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:05,080] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.371 seconds
[2020-06-01 14:33:52,712] {scheduler_job.py:153} INFO - Started process (PID=110) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:52,717] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:33:52,718] {logging_mixin.py:112} INFO - [2020-06-01 14:33:52,718] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:52,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:33:53,015] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.303 seconds
[2020-06-01 14:34:40,833] {scheduler_job.py:153} INFO - Started process (PID=142) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:34:40,873] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:34:40,874] {logging_mixin.py:112} INFO - [2020-06-01 14:34:40,874] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:34:40,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:34:41,265] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.432 seconds
[2020-06-01 14:35:28,973] {scheduler_job.py:153} INFO - Started process (PID=170) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:35:28,978] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:35:28,979] {logging_mixin.py:112} INFO - [2020-06-01 14:35:28,979] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:35:28,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:35:29,515] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.542 seconds
[2020-06-01 14:36:18,540] {scheduler_job.py:153} INFO - Started process (PID=198) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:36:18,548] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:36:18,551] {logging_mixin.py:112} INFO - [2020-06-01 14:36:18,550] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:36:18,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:36:19,360] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.820 seconds
[2020-06-01 14:37:07,247] {scheduler_job.py:153} INFO - Started process (PID=226) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:07,254] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:37:07,254] {logging_mixin.py:112} INFO - [2020-06-01 14:37:07,254] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:07,265] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:07,469] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.222 seconds
[2020-06-01 14:37:55,254] {scheduler_job.py:153} INFO - Started process (PID=258) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:55,260] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:37:55,261] {logging_mixin.py:112} INFO - [2020-06-01 14:37:55,261] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:55,271] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:37:55,443] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.189 seconds
[2020-06-01 14:38:43,355] {scheduler_job.py:153} INFO - Started process (PID=286) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:38:43,361] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:38:43,361] {logging_mixin.py:112} INFO - [2020-06-01 14:38:43,361] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:38:43,372] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:38:43,697] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.342 seconds
[2020-06-01 14:39:31,410] {scheduler_job.py:153} INFO - Started process (PID=318) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:39:31,415] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 14:39:31,415] {logging_mixin.py:112} INFO - [2020-06-01 14:39:31,415] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:39:31,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 14:39:31,597] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.188 seconds
[2020-06-01 15:16:03,691] {scheduler_job.py:153} INFO - Started process (PID=1136) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:03,760] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:16:03,761] {logging_mixin.py:112} INFO - [2020-06-01 15:16:03,760] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:03,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:03,896] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.206 seconds
[2020-06-01 15:16:53,737] {scheduler_job.py:153} INFO - Started process (PID=1169) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:53,742] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:16:53,743] {logging_mixin.py:112} INFO - [2020-06-01 15:16:53,743] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:53,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:16:53,886] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.148 seconds
[2020-06-01 15:17:43,798] {scheduler_job.py:153} INFO - Started process (PID=1198) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:17:43,804] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:17:43,804] {logging_mixin.py:112} INFO - [2020-06-01 15:17:43,804] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:17:43,814] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:17:43,976] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:18:33,851] {scheduler_job.py:153} INFO - Started process (PID=1231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:18:33,856] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:18:33,857] {logging_mixin.py:112} INFO - [2020-06-01 15:18:33,857] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:18:33,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:18:34,015] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.164 seconds
[2020-06-01 15:19:23,875] {scheduler_job.py:153} INFO - Started process (PID=1264) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:19:23,880] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:19:23,881] {logging_mixin.py:112} INFO - [2020-06-01 15:19:23,881] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:19:23,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:19:24,048] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.173 seconds
[2020-06-01 15:20:13,899] {scheduler_job.py:153} INFO - Started process (PID=1293) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:20:13,905] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:20:13,905] {logging_mixin.py:112} INFO - [2020-06-01 15:20:13,905] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:20:13,914] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:20:14,064] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 15:21:03,924] {scheduler_job.py:153} INFO - Started process (PID=1326) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:03,929] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:21:03,930] {logging_mixin.py:112} INFO - [2020-06-01 15:21:03,930] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:03,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:04,103] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.179 seconds
[2020-06-01 15:21:53,965] {scheduler_job.py:153} INFO - Started process (PID=1355) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:53,970] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:21:53,971] {logging_mixin.py:112} INFO - [2020-06-01 15:21:53,971] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:53,979] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:21:54,114] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.149 seconds
[2020-06-01 15:26:48,395] {scheduler_job.py:153} INFO - Started process (PID=1412) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:26:48,403] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 15:26:48,404] {logging_mixin.py:112} INFO - [2020-06-01 15:26:48,403] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:26:48,422] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 15:26:49,038] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.643 seconds
[2020-06-01 17:42:38,275] {scheduler_job.py:153} INFO - Started process (PID=95) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:42:38,299] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:42:38,300] {logging_mixin.py:112} INFO - [2020-06-01 17:42:38,300] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:42:38,309] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:42:38,503] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.229 seconds
[2020-06-01 17:43:28,298] {scheduler_job.py:153} INFO - Started process (PID=124) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:43:28,303] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:43:28,303] {logging_mixin.py:112} INFO - [2020-06-01 17:43:28,303] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:43:28,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:43:28,439] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.142 seconds
[2020-06-01 17:44:18,354] {scheduler_job.py:153} INFO - Started process (PID=157) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:44:18,359] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:44:18,360] {logging_mixin.py:112} INFO - [2020-06-01 17:44:18,360] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:44:18,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:44:18,516] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:45:08,401] {scheduler_job.py:153} INFO - Started process (PID=187) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:08,406] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:45:08,407] {logging_mixin.py:112} INFO - [2020-06-01 17:45:08,407] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:08,417] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:08,567] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.166 seconds
[2020-06-01 17:45:58,435] {scheduler_job.py:153} INFO - Started process (PID=219) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:58,440] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:45:58,440] {logging_mixin.py:112} INFO - [2020-06-01 17:45:58,440] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:58,449] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:45:58,600] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.165 seconds
[2020-06-01 17:46:48,457] {scheduler_job.py:153} INFO - Started process (PID=252) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:46:48,462] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:46:48,463] {logging_mixin.py:112} INFO - [2020-06-01 17:46:48,463] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:46:48,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:46:48,659] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:47:38,512] {scheduler_job.py:153} INFO - Started process (PID=281) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:47:38,517] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:47:38,518] {logging_mixin.py:112} INFO - [2020-06-01 17:47:38,518] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:47:38,526] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:47:38,755] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.243 seconds
[2020-06-01 17:48:28,546] {scheduler_job.py:153} INFO - Started process (PID=314) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:48:28,551] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:48:28,552] {logging_mixin.py:112} INFO - [2020-06-01 17:48:28,552] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:48:28,560] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:48:28,676] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.130 seconds
[2020-06-01 17:49:18,633] {scheduler_job.py:153} INFO - Started process (PID=343) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:49:18,638] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:49:18,639] {logging_mixin.py:112} INFO - [2020-06-01 17:49:18,639] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:49:18,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:49:18,825] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:50:08,746] {scheduler_job.py:153} INFO - Started process (PID=376) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:08,751] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:50:08,751] {logging_mixin.py:112} INFO - [2020-06-01 17:50:08,751] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:08,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:08,958] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.212 seconds
[2020-06-01 17:50:58,839] {scheduler_job.py:153} INFO - Started process (PID=409) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:58,845] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:50:58,846] {logging_mixin.py:112} INFO - [2020-06-01 17:50:58,846] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:58,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:50:59,032] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.193 seconds
[2020-06-01 17:51:48,875] {scheduler_job.py:153} INFO - Started process (PID=438) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:51:48,880] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:51:48,880] {logging_mixin.py:112} INFO - [2020-06-01 17:51:48,880] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:51:48,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:51:49,069] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:52:38,956] {scheduler_job.py:153} INFO - Started process (PID=471) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:52:38,963] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:52:38,964] {logging_mixin.py:112} INFO - [2020-06-01 17:52:38,963] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:52:38,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:52:39,106] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.150 seconds
[2020-06-01 17:53:29,060] {scheduler_job.py:153} INFO - Started process (PID=500) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:53:29,069] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:53:29,069] {logging_mixin.py:112} INFO - [2020-06-01 17:53:29,069] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:53:29,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:53:29,222] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.162 seconds
[2020-06-01 17:54:19,162] {scheduler_job.py:153} INFO - Started process (PID=533) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:54:19,168] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:54:19,168] {logging_mixin.py:112} INFO - [2020-06-01 17:54:19,168] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:54:19,178] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:54:19,346] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:55:09,273] {scheduler_job.py:153} INFO - Started process (PID=562) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:09,278] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:55:09,279] {logging_mixin.py:112} INFO - [2020-06-01 17:55:09,279] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:09,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:09,396] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.123 seconds
[2020-06-01 17:55:59,336] {scheduler_job.py:153} INFO - Started process (PID=595) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:59,342] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:55:59,342] {logging_mixin.py:112} INFO - [2020-06-01 17:55:59,342] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:59,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:55:59,554] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.218 seconds
[2020-06-01 17:56:49,429] {scheduler_job.py:153} INFO - Started process (PID=624) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:56:49,434] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:56:49,435] {logging_mixin.py:112} INFO - [2020-06-01 17:56:49,435] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:56:49,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:56:49,578] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 17:57:39,503] {scheduler_job.py:153} INFO - Started process (PID=657) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:57:39,508] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:57:39,509] {logging_mixin.py:112} INFO - [2020-06-01 17:57:39,509] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:57:39,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:57:39,674] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.171 seconds
[2020-06-01 17:58:29,597] {scheduler_job.py:153} INFO - Started process (PID=690) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:58:29,602] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:58:29,603] {logging_mixin.py:112} INFO - [2020-06-01 17:58:29,603] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:58:29,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:58:29,750] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.153 seconds
[2020-06-01 17:59:19,709] {scheduler_job.py:153} INFO - Started process (PID=719) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:59:19,715] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 17:59:19,716] {logging_mixin.py:112} INFO - [2020-06-01 17:59:19,715] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:59:19,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 17:59:19,921] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:00:09,860] {scheduler_job.py:153} INFO - Started process (PID=752) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:00:09,865] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:00:09,866] {logging_mixin.py:112} INFO - [2020-06-01 18:00:09,865] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:00:09,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:00:10,015] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.156 seconds
[2020-06-01 18:00:59,931] {scheduler_job.py:153} INFO - Started process (PID=781) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:00:59,936] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:00:59,936] {logging_mixin.py:112} INFO - [2020-06-01 18:00:59,936] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:00:59,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:01:00,071] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.140 seconds
[2020-06-01 18:01:50,004] {scheduler_job.py:153} INFO - Started process (PID=814) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:01:50,009] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:01:50,010] {logging_mixin.py:112} INFO - [2020-06-01 18:01:50,010] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:01:50,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:01:50,210] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:02:40,038] {scheduler_job.py:153} INFO - Started process (PID=843) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:02:40,043] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:02:40,043] {logging_mixin.py:112} INFO - [2020-06-01 18:02:40,043] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:02:40,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:02:40,204] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.166 seconds
[2020-06-01 18:03:30,060] {scheduler_job.py:153} INFO - Started process (PID=876) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:03:30,066] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:03:30,066] {logging_mixin.py:112} INFO - [2020-06-01 18:03:30,066] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:03:30,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:03:30,303] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.242 seconds
[2020-06-01 18:04:20,086] {scheduler_job.py:153} INFO - Started process (PID=909) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:04:20,092] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:04:20,092] {logging_mixin.py:112} INFO - [2020-06-01 18:04:20,092] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:04:20,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:04:20,294] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.208 seconds
[2020-06-01 18:05:10,139] {scheduler_job.py:153} INFO - Started process (PID=938) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:05:10,146] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:05:10,147] {logging_mixin.py:112} INFO - [2020-06-01 18:05:10,146] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:05:10,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:05:10,295] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.156 seconds
[2020-06-01 18:06:37,019] {scheduler_job.py:153} INFO - Started process (PID=993) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:06:37,024] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:06:37,024] {logging_mixin.py:112} INFO - [2020-06-01 18:06:37,024] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:06:37,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:06:37,215] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.196 seconds
[2020-06-01 18:08:06,430] {scheduler_job.py:153} INFO - Started process (PID=1061) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:06,436] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:08:06,437] {logging_mixin.py:112} INFO - [2020-06-01 18:08:06,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:06,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:06,571] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.141 seconds
[2020-06-01 18:08:56,473] {scheduler_job.py:153} INFO - Started process (PID=1094) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:56,485] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:08:56,489] {logging_mixin.py:112} INFO - [2020-06-01 18:08:56,489] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:56,510] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:08:56,660] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.187 seconds
[2020-06-01 18:09:46,915] {scheduler_job.py:153} INFO - Started process (PID=1123) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:09:46,921] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:09:46,921] {logging_mixin.py:112} INFO - [2020-06-01 18:09:46,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:09:46,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:09:47,081] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.166 seconds
[2020-06-01 18:10:36,890] {scheduler_job.py:153} INFO - Started process (PID=1156) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:10:36,895] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:10:36,896] {logging_mixin.py:112} INFO - [2020-06-01 18:10:36,895] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:10:36,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:10:37,100] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.210 seconds
[2020-06-01 18:11:26,910] {scheduler_job.py:153} INFO - Started process (PID=1185) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:11:26,916] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:11:26,916] {logging_mixin.py:112} INFO - [2020-06-01 18:11:26,916] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:11:26,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:11:27,105] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:12:16,939] {scheduler_job.py:153} INFO - Started process (PID=1218) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:12:16,944] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:12:16,945] {logging_mixin.py:112} INFO - [2020-06-01 18:12:16,945] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:12:16,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:12:17,124] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.185 seconds
[2020-06-01 18:13:06,968] {scheduler_job.py:153} INFO - Started process (PID=1251) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:06,974] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:13:06,974] {logging_mixin.py:112} INFO - [2020-06-01 18:13:06,974] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:06,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:07,140] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.172 seconds
[2020-06-01 18:13:56,986] {scheduler_job.py:153} INFO - Started process (PID=1280) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:56,993] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:13:56,994] {logging_mixin.py:112} INFO - [2020-06-01 18:13:56,994] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:57,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:13:57,147] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:14:47,023] {scheduler_job.py:153} INFO - Started process (PID=1313) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:14:47,028] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:14:47,028] {logging_mixin.py:112} INFO - [2020-06-01 18:14:47,028] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:14:47,037] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:14:47,200] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.178 seconds
[2020-06-01 18:15:37,037] {scheduler_job.py:153} INFO - Started process (PID=1342) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:15:37,043] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:15:37,043] {logging_mixin.py:112} INFO - [2020-06-01 18:15:37,043] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:15:37,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:15:37,211] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.174 seconds
[2020-06-01 18:16:27,074] {scheduler_job.py:153} INFO - Started process (PID=1375) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:16:27,082] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:16:27,083] {logging_mixin.py:112} INFO - [2020-06-01 18:16:27,083] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:16:27,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:16:27,227] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.153 seconds
[2020-06-01 18:17:17,106] {scheduler_job.py:153} INFO - Started process (PID=1404) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:17:17,111] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:17:17,112] {logging_mixin.py:112} INFO - [2020-06-01 18:17:17,112] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:17:17,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:17:17,528] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.422 seconds
[2020-06-01 18:18:07,129] {scheduler_job.py:153} INFO - Started process (PID=1437) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:07,135] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:18:07,135] {logging_mixin.py:112} INFO - [2020-06-01 18:18:07,135] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:07,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:07,289] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.161 seconds
[2020-06-01 18:18:57,349] {scheduler_job.py:153} INFO - Started process (PID=1467) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:57,363] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:18:57,372] {logging_mixin.py:112} INFO - [2020-06-01 18:18:57,371] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:57,407] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:18:57,565] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.216 seconds
[2020-06-01 18:19:47,236] {scheduler_job.py:153} INFO - Started process (PID=1500) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:19:47,245] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:19:47,245] {logging_mixin.py:112} INFO - [2020-06-01 18:19:47,245] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:19:47,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:19:47,411] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.175 seconds
[2020-06-01 18:20:37,385] {scheduler_job.py:153} INFO - Started process (PID=1529) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:20:37,396] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:20:37,398] {logging_mixin.py:112} INFO - [2020-06-01 18:20:37,398] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:20:37,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:20:37,636] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.251 seconds
[2020-06-01 18:21:27,613] {scheduler_job.py:153} INFO - Started process (PID=1564) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:21:27,619] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:21:27,620] {logging_mixin.py:112} INFO - [2020-06-01 18:21:27,620] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:21:27,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:21:28,023] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:22:17,648] {scheduler_job.py:153} INFO - Started process (PID=1598) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:22:17,654] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:22:17,655] {logging_mixin.py:112} INFO - [2020-06-01 18:22:17,654] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:22:17,664] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:22:17,864] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.216 seconds
[2020-06-01 18:23:07,707] {scheduler_job.py:153} INFO - Started process (PID=1627) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:07,719] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:23:07,721] {logging_mixin.py:112} INFO - [2020-06-01 18:23:07,720] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:07,735] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:07,920] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.213 seconds
[2020-06-01 18:23:57,702] {scheduler_job.py:153} INFO - Started process (PID=1660) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:57,708] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:23:57,708] {logging_mixin.py:112} INFO - [2020-06-01 18:23:57,708] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:57,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:23:57,944] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:24:47,759] {scheduler_job.py:153} INFO - Started process (PID=1689) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:24:47,764] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:24:47,765] {logging_mixin.py:112} INFO - [2020-06-01 18:24:47,765] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:24:47,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:24:47,988] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.229 seconds
[2020-06-01 18:25:37,762] {scheduler_job.py:153} INFO - Started process (PID=1726) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:25:37,769] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:25:37,769] {logging_mixin.py:112} INFO - [2020-06-01 18:25:37,769] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:25:37,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:25:37,952] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.190 seconds
[2020-06-01 18:26:27,787] {scheduler_job.py:153} INFO - Started process (PID=1771) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:26:27,794] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:26:27,794] {logging_mixin.py:112} INFO - [2020-06-01 18:26:27,794] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:26:27,804] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:26:27,965] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:27:17,809] {scheduler_job.py:153} INFO - Started process (PID=1813) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:27:17,815] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:27:17,815] {logging_mixin.py:112} INFO - [2020-06-01 18:27:17,815] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:27:17,826] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:27:18,035] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.225 seconds
[2020-06-01 18:28:07,982] {scheduler_job.py:153} INFO - Started process (PID=1842) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:07,987] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:28:07,988] {logging_mixin.py:112} INFO - [2020-06-01 18:28:07,988] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:07,998] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:08,222] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.240 seconds
[2020-06-01 18:28:58,005] {scheduler_job.py:153} INFO - Started process (PID=1875) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:58,010] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:28:58,011] {logging_mixin.py:112} INFO - [2020-06-01 18:28:58,011] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:58,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:28:58,320] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:29:48,053] {scheduler_job.py:153} INFO - Started process (PID=1904) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:29:48,059] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:29:48,060] {logging_mixin.py:112} INFO - [2020-06-01 18:29:48,060] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:29:48,069] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:29:48,275] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.223 seconds
[2020-06-01 18:30:38,103] {scheduler_job.py:153} INFO - Started process (PID=1937) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:30:38,111] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:30:38,112] {logging_mixin.py:112} INFO - [2020-06-01 18:30:38,112] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:30:38,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:30:38,237] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.134 seconds
[2020-06-01 18:31:28,139] {scheduler_job.py:153} INFO - Started process (PID=1966) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:31:28,146] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:31:28,147] {logging_mixin.py:112} INFO - [2020-06-01 18:31:28,147] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:31:28,155] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:31:28,508] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:32:18,144] {scheduler_job.py:153} INFO - Started process (PID=1999) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:32:18,150] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:32:18,151] {logging_mixin.py:112} INFO - [2020-06-01 18:32:18,151] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:32:18,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:32:18,324] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.180 seconds
[2020-06-01 18:33:08,176] {scheduler_job.py:153} INFO - Started process (PID=2032) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:08,181] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:33:08,182] {logging_mixin.py:112} INFO - [2020-06-01 18:33:08,182] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:08,190] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:08,336] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.160 seconds
[2020-06-01 18:33:58,208] {scheduler_job.py:153} INFO - Started process (PID=2061) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:58,215] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:33:58,216] {logging_mixin.py:112} INFO - [2020-06-01 18:33:58,216] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:58,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:33:58,607] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:34:48,226] {scheduler_job.py:153} INFO - Started process (PID=2094) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:34:48,232] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:34:48,232] {logging_mixin.py:112} INFO - [2020-06-01 18:34:48,232] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:34:48,242] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:34:48,391] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.165 seconds
[2020-06-01 18:35:38,274] {scheduler_job.py:153} INFO - Started process (PID=2123) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:35:38,286] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:35:38,287] {logging_mixin.py:112} INFO - [2020-06-01 18:35:38,287] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:35:38,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:35:38,480] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.206 seconds
[2020-06-01 18:36:28,297] {scheduler_job.py:153} INFO - Started process (PID=2156) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:36:28,303] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:36:28,304] {logging_mixin.py:112} INFO - [2020-06-01 18:36:28,304] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:36:28,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:36:28,528] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:37:18,329] {scheduler_job.py:153} INFO - Started process (PID=2185) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:37:18,337] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:37:18,337] {logging_mixin.py:112} INFO - [2020-06-01 18:37:18,337] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:37:18,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:37:18,545] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.216 seconds
[2020-06-01 18:38:08,368] {scheduler_job.py:153} INFO - Started process (PID=2218) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:08,373] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:38:08,374] {logging_mixin.py:112} INFO - [2020-06-01 18:38:08,374] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:08,385] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:08,919] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.551 seconds
[2020-06-01 18:38:58,385] {scheduler_job.py:153} INFO - Started process (PID=2247) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:58,391] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:38:58,392] {logging_mixin.py:112} INFO - [2020-06-01 18:38:58,392] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:58,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:38:58,772] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:39:48,419] {scheduler_job.py:153} INFO - Started process (PID=2280) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:39:48,428] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:39:48,429] {logging_mixin.py:112} INFO - [2020-06-01 18:39:48,428] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:39:48,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:39:48,668] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.249 seconds
[2020-06-01 18:40:38,451] {scheduler_job.py:153} INFO - Started process (PID=2309) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:40:38,457] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:40:38,457] {logging_mixin.py:112} INFO - [2020-06-01 18:40:38,457] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:40:38,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:40:38,600] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.149 seconds
[2020-06-01 18:41:28,478] {scheduler_job.py:153} INFO - Started process (PID=2342) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:41:28,484] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:41:28,484] {logging_mixin.py:112} INFO - [2020-06-01 18:41:28,484] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:41:28,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:41:28,838] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:42:18,509] {scheduler_job.py:153} INFO - Started process (PID=2372) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:42:18,516] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:42:18,519] {logging_mixin.py:112} INFO - [2020-06-01 18:42:18,517] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:42:18,531] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:42:18,889] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.381 seconds
[2020-06-01 18:43:08,551] {scheduler_job.py:153} INFO - Started process (PID=2404) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:08,557] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:43:08,557] {logging_mixin.py:112} INFO - [2020-06-01 18:43:08,557] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:08,566] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:08,811] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.260 seconds
[2020-06-01 18:43:58,571] {scheduler_job.py:153} INFO - Started process (PID=2437) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:58,616] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:43:58,617] {logging_mixin.py:112} INFO - [2020-06-01 18:43:58,617] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:58,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:43:59,613] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:44:48,693] {scheduler_job.py:153} INFO - Started process (PID=2466) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:44:48,699] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:44:48,700] {logging_mixin.py:112} INFO - [2020-06-01 18:44:48,700] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:44:48,708] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:44:49,056] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.363 seconds
[2020-06-01 18:45:39,048] {scheduler_job.py:153} INFO - Started process (PID=2499) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:45:39,053] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:45:39,054] {logging_mixin.py:112} INFO - [2020-06-01 18:45:39,054] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:45:39,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:45:39,468] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.420 seconds
[2020-06-01 18:46:29,069] {scheduler_job.py:153} INFO - Started process (PID=2528) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:46:29,075] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:46:29,076] {logging_mixin.py:112} INFO - [2020-06-01 18:46:29,076] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:46:29,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:46:29,380] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:47:19,093] {scheduler_job.py:153} INFO - Started process (PID=2561) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:47:19,099] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:47:19,099] {logging_mixin.py:112} INFO - [2020-06-01 18:47:19,099] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:47:19,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:47:19,353] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.260 seconds
[2020-06-01 18:48:09,120] {scheduler_job.py:153} INFO - Started process (PID=2590) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:48:09,127] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:48:09,128] {logging_mixin.py:112} INFO - [2020-06-01 18:48:09,128] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:48:09,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:48:09,309] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.189 seconds
[2020-06-01 18:49:08,880] {scheduler_job.py:153} INFO - Started process (PID=2623) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:08,886] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:49:08,886] {logging_mixin.py:112} INFO - [2020-06-01 18:49:08,886] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:08,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:09,245] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:49:58,909] {scheduler_job.py:153} INFO - Started process (PID=2656) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:58,914] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:49:58,915] {logging_mixin.py:112} INFO - [2020-06-01 18:49:58,915] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:58,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:49:59,390] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.481 seconds
[2020-06-01 18:50:48,939] {scheduler_job.py:153} INFO - Started process (PID=2685) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:50:48,944] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:50:48,945] {logging_mixin.py:112} INFO - [2020-06-01 18:50:48,945] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:50:48,955] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:50:49,396] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.457 seconds
[2020-06-01 18:51:44,716] {scheduler_job.py:153} INFO - Started process (PID=2718) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:51:44,721] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:51:44,722] {logging_mixin.py:112} INFO - [2020-06-01 18:51:44,722] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:51:44,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:51:45,445] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:52:35,471] {scheduler_job.py:153} INFO - Started process (PID=2747) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:52:35,476] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:52:35,477] {logging_mixin.py:112} INFO - [2020-06-01 18:52:35,477] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:52:35,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:52:36,480] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 1.010 seconds
[2020-06-01 18:53:25,872] {scheduler_job.py:153} INFO - Started process (PID=2780) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:53:25,880] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:53:25,880] {logging_mixin.py:112} INFO - [2020-06-01 18:53:25,880] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:53:25,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:53:26,175] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.303 seconds
[2020-06-01 18:54:15,906] {scheduler_job.py:153} INFO - Started process (PID=2813) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:54:15,913] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:54:15,914] {logging_mixin.py:112} INFO - [2020-06-01 18:54:15,913] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:54:15,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:54:16,156] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 18:55:05,927] {scheduler_job.py:153} INFO - Started process (PID=2842) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:05,933] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:55:05,933] {logging_mixin.py:112} INFO - [2020-06-01 18:55:05,933] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:05,942] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:06,583] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.656 seconds
[2020-06-01 18:55:57,007] {scheduler_job.py:153} INFO - Started process (PID=2875) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:57,013] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:55:57,014] {logging_mixin.py:112} INFO - [2020-06-01 18:55:57,014] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:57,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:55:57,439] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.432 seconds
[2020-06-01 18:56:48,546] {scheduler_job.py:153} INFO - Started process (PID=2904) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:56:48,553] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:56:48,553] {logging_mixin.py:112} INFO - [2020-06-01 18:56:48,553] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:56:48,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:56:48,965] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.418 seconds
[2020-06-01 18:57:46,997] {scheduler_job.py:153} INFO - Started process (PID=2937) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:57:47,003] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:57:47,004] {logging_mixin.py:112} INFO - [2020-06-01 18:57:47,004] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:57:47,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:57:47,272] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.275 seconds
[2020-06-01 18:58:37,022] {scheduler_job.py:153} INFO - Started process (PID=2966) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:58:37,027] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:58:37,029] {logging_mixin.py:112} INFO - [2020-06-01 18:58:37,028] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:58:37,038] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:58:37,310] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.289 seconds
[2020-06-01 18:59:27,047] {scheduler_job.py:153} INFO - Started process (PID=2999) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:59:27,057] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 18:59:27,057] {logging_mixin.py:112} INFO - [2020-06-01 18:59:27,057] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:59:27,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 18:59:27,275] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:00:17,070] {scheduler_job.py:153} INFO - Started process (PID=3028) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:00:17,075] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:00:17,076] {logging_mixin.py:112} INFO - [2020-06-01 19:00:17,076] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:00:17,085] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:00:17,226] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.156 seconds
[2020-06-01 19:01:07,103] {scheduler_job.py:153} INFO - Started process (PID=3061) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:07,109] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:01:07,109] {logging_mixin.py:112} INFO - [2020-06-01 19:01:07,109] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:07,118] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:07,294] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.191 seconds
[2020-06-01 19:01:57,133] {scheduler_job.py:153} INFO - Started process (PID=3090) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:57,139] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:01:57,139] {logging_mixin.py:112} INFO - [2020-06-01 19:01:57,139] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:57,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:01:57,330] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:02:47,158] {scheduler_job.py:153} INFO - Started process (PID=3123) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:02:47,164] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:02:47,164] {logging_mixin.py:112} INFO - [2020-06-01 19:02:47,164] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:02:47,174] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:02:47,359] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.201 seconds
[2020-06-01 19:03:37,198] {scheduler_job.py:153} INFO - Started process (PID=3152) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:03:37,203] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:03:37,204] {logging_mixin.py:112} INFO - [2020-06-01 19:03:37,204] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:03:37,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:03:37,337] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.139 seconds
[2020-06-01 19:04:27,214] {scheduler_job.py:153} INFO - Started process (PID=3185) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:04:27,221] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:04:27,221] {logging_mixin.py:112} INFO - [2020-06-01 19:04:27,221] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:04:27,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:04:27,381] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.167 seconds
[2020-06-01 19:05:17,243] {scheduler_job.py:153} INFO - Started process (PID=3214) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:05:17,250] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:05:17,251] {logging_mixin.py:112} INFO - [2020-06-01 19:05:17,251] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:05:17,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:05:17,473] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.230 seconds
[2020-06-01 19:06:07,274] {scheduler_job.py:153} INFO - Started process (PID=3247) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:07,279] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:06:07,280] {logging_mixin.py:112} INFO - [2020-06-01 19:06:07,280] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:07,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:07,474] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.200 seconds
[2020-06-01 19:06:57,303] {scheduler_job.py:153} INFO - Started process (PID=3280) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:57,309] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:06:57,309] {logging_mixin.py:112} INFO - [2020-06-01 19:06:57,309] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:57,318] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:06:57,641] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:07:47,328] {scheduler_job.py:153} INFO - Started process (PID=3309) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:07:47,334] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:07:47,334] {logging_mixin.py:112} INFO - [2020-06-01 19:07:47,334] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:07:47,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:07:47,514] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.186 seconds
[2020-06-01 19:51:03,458] {scheduler_job.py:153} INFO - Started process (PID=3358) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:03,469] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:51:03,470] {logging_mixin.py:112} INFO - [2020-06-01 19:51:03,470] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:03,482] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:04,776] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 1.318 seconds
[2020-06-01 19:51:51,359] {scheduler_job.py:153} INFO - Started process (PID=3383) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:51,365] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:51:51,366] {logging_mixin.py:112} INFO - [2020-06-01 19:51:51,366] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:51,376] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:51:52,076] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:52:41,373] {scheduler_job.py:153} INFO - Started process (PID=3408) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:52:41,378] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:52:41,379] {logging_mixin.py:112} INFO - [2020-06-01 19:52:41,379] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:52:41,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:52:41,682] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.310 seconds
[2020-06-01 19:53:31,401] {scheduler_job.py:153} INFO - Started process (PID=3433) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:53:31,407] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:53:31,407] {logging_mixin.py:112} INFO - [2020-06-01 19:53:31,407] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:53:31,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:53:31,549] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.148 seconds
[2020-06-01 19:54:21,430] {scheduler_job.py:153} INFO - Started process (PID=3458) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:54:21,437] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:54:21,437] {logging_mixin.py:112} INFO - [2020-06-01 19:54:21,437] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:54:21,446] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:54:21,620] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:55:11,459] {scheduler_job.py:153} INFO - Started process (PID=3483) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:55:11,465] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:55:11,465] {logging_mixin.py:112} INFO - [2020-06-01 19:55:11,465] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:55:11,474] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:55:11,592] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.134 seconds
[2020-06-01 19:56:01,513] {scheduler_job.py:153} INFO - Started process (PID=3509) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:01,518] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:56:01,519] {logging_mixin.py:112} INFO - [2020-06-01 19:56:01,519] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:01,528] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:01,681] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.169 seconds
[2020-06-01 19:56:51,552] {scheduler_job.py:153} INFO - Started process (PID=3534) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:51,565] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:56:51,566] {logging_mixin.py:112} INFO - [2020-06-01 19:56:51,566] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:51,582] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:56:51,897] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 19:57:41,577] {scheduler_job.py:153} INFO - Started process (PID=3559) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:57:41,584] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:57:41,585] {logging_mixin.py:112} INFO - [2020-06-01 19:57:41,585] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:57:41,595] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:57:41,748] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.171 seconds
[2020-06-01 19:58:31,607] {scheduler_job.py:153} INFO - Started process (PID=3584) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:58:31,613] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:58:31,614] {logging_mixin.py:112} INFO - [2020-06-01 19:58:31,614] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:58:31,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:58:31,761] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.154 seconds
[2020-06-01 19:59:21,634] {scheduler_job.py:153} INFO - Started process (PID=3609) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:59:21,640] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 19:59:21,641] {logging_mixin.py:112} INFO - [2020-06-01 19:59:21,641] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:59:21,650] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 19:59:21,884] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-01 20:00:11,691] {scheduler_job.py:153} INFO - Started process (PID=3634) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:00:11,696] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 20:00:11,697] {logging_mixin.py:112} INFO - [2020-06-01 20:00:11,697] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:00:11,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:00:11,924] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.234 seconds
[2020-06-01 20:01:01,691] {scheduler_job.py:153} INFO - Started process (PID=3660) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:01:01,697] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-01 20:01:01,698] {logging_mixin.py:112} INFO - [2020-06-01 20:01:01,697] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:01:01,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-01 20:01:01,903] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.212 seconds
[2020-06-02 15:16:14,271] {scheduler_job.py:153} INFO - Started process (PID=256) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:16:14,284] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:16:14,285] {logging_mixin.py:112} INFO - [2020-06-02 15:16:14,285] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:16:14,295] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:16:14,567] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.297 seconds
[2020-06-02 15:17:28,869] {scheduler_job.py:153} INFO - Started process (PID=296) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:17:28,874] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:17:28,875] {logging_mixin.py:112} INFO - [2020-06-02 15:17:28,875] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:17:28,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:17:29,131] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.262 seconds
[2020-06-02 15:18:18,888] {scheduler_job.py:153} INFO - Started process (PID=322) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:18:18,893] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:18:18,894] {logging_mixin.py:112} INFO - [2020-06-02 15:18:18,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:18:18,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:18:19,164] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.276 seconds
[2020-06-02 15:19:08,915] {scheduler_job.py:153} INFO - Started process (PID=371) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:08,921] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:19:08,921] {logging_mixin.py:112} INFO - [2020-06-02 15:19:08,921] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:09,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:09,196] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.281 seconds
[2020-06-02 15:19:58,935] {scheduler_job.py:153} INFO - Started process (PID=412) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:58,941] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:19:58,941] {logging_mixin.py:112} INFO - [2020-06-02 15:19:58,941] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:59,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:19:59,198] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.263 seconds
[2020-06-02 15:20:48,973] {scheduler_job.py:153} INFO - Started process (PID=439) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:20:48,978] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:20:48,978] {logging_mixin.py:112} INFO - [2020-06-02 15:20:48,978] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:20:48,987] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:20:49,186] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.213 seconds
[2020-06-02 15:21:38,987] {scheduler_job.py:153} INFO - Started process (PID=466) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:21:38,992] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:21:38,993] {logging_mixin.py:112} INFO - [2020-06-02 15:21:38,993] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:21:39,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:21:39,141] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.155 seconds
[2020-06-02 15:22:53,526] {scheduler_job.py:153} INFO - Started process (PID=505) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:22:53,532] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:22:53,533] {logging_mixin.py:112} INFO - [2020-06-02 15:22:53,533] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:22:53,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:22:53,669] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:23:43,549] {scheduler_job.py:153} INFO - Started process (PID=532) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:23:43,556] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:23:43,556] {logging_mixin.py:112} INFO - [2020-06-02 15:23:43,556] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:23:43,565] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:23:43,674] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.124 seconds
[2020-06-02 15:24:33,585] {scheduler_job.py:153} INFO - Started process (PID=558) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:24:33,590] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:24:33,591] {logging_mixin.py:112} INFO - [2020-06-02 15:24:33,591] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:24:33,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:24:33,844] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.259 seconds
[2020-06-02 15:25:54,230] {scheduler_job.py:153} INFO - Started process (PID=607) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:25:54,236] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:25:54,237] {logging_mixin.py:112} INFO - [2020-06-02 15:25:54,237] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:25:54,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:25:54,504] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.276 seconds
[2020-06-02 15:26:56,470] {scheduler_job.py:153} INFO - Started process (PID=638) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:26:56,476] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:26:56,477] {logging_mixin.py:112} INFO - [2020-06-02 15:26:56,477] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:26:56,490] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:26:56,738] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.269 seconds
[2020-06-02 15:27:46,499] {scheduler_job.py:153} INFO - Started process (PID=663) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:27:46,504] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:27:46,504] {logging_mixin.py:112} INFO - [2020-06-02 15:27:46,504] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:27:46,514] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:27:46,748] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.249 seconds
[2020-06-02 15:28:36,508] {scheduler_job.py:153} INFO - Started process (PID=688) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:28:36,513] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:28:36,514] {logging_mixin.py:112} INFO - [2020-06-02 15:28:36,513] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:28:36,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:28:36,779] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.272 seconds
[2020-06-02 15:29:26,528] {scheduler_job.py:153} INFO - Started process (PID=713) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:29:26,533] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:29:26,534] {logging_mixin.py:112} INFO - [2020-06-02 15:29:26,534] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:29:26,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:29:26,790] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.262 seconds
[2020-06-02 15:30:16,573] {scheduler_job.py:153} INFO - Started process (PID=738) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:30:16,578] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:30:16,578] {logging_mixin.py:112} INFO - [2020-06-02 15:30:16,578] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:30:16,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:30:16,813] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.240 seconds
[2020-06-02 15:31:06,607] {scheduler_job.py:153} INFO - Started process (PID=763) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:31:06,612] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:31:06,613] {logging_mixin.py:112} INFO - [2020-06-02 15:31:06,612] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:31:06,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:31:06,735] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.128 seconds
[2020-06-02 15:32:08,305] {scheduler_job.py:153} INFO - Started process (PID=794) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:08,310] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:32:08,311] {logging_mixin.py:112} INFO - [2020-06-02 15:32:08,311] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:08,320] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:08,464] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:32:58,341] {scheduler_job.py:153} INFO - Started process (PID=819) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:58,348] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:32:58,348] {logging_mixin.py:112} INFO - [2020-06-02 15:32:58,348] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:58,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:32:58,502] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.161 seconds
[2020-06-02 15:33:48,351] {scheduler_job.py:153} INFO - Started process (PID=844) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:33:48,356] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:33:48,356] {logging_mixin.py:112} INFO - [2020-06-02 15:33:48,356] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:33:48,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:33:48,482] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.131 seconds
[2020-06-02 15:34:38,374] {scheduler_job.py:153} INFO - Started process (PID=869) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:34:38,380] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:34:38,380] {logging_mixin.py:112} INFO - [2020-06-02 15:34:38,380] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:34:38,389] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:34:38,541] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:35:28,400] {scheduler_job.py:153} INFO - Started process (PID=912) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:35:28,405] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:35:28,406] {logging_mixin.py:112} INFO - [2020-06-02 15:35:28,406] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:35:28,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:35:28,559] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.159 seconds
[2020-06-02 15:36:18,421] {scheduler_job.py:153} INFO - Started process (PID=939) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:36:18,426] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:36:18,427] {logging_mixin.py:112} INFO - [2020-06-02 15:36:18,427] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:36:18,436] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:36:18,594] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.174 seconds
[2020-06-02 15:37:08,458] {scheduler_job.py:153} INFO - Started process (PID=964) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:08,463] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:37:08,463] {logging_mixin.py:112} INFO - [2020-06-02 15:37:08,463] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:08,472] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:08,629] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:37:58,472] {scheduler_job.py:153} INFO - Started process (PID=989) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:58,478] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:37:58,479] {logging_mixin.py:112} INFO - [2020-06-02 15:37:58,479] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:58,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:37:58,612] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.141 seconds
[2020-06-02 15:38:48,491] {scheduler_job.py:153} INFO - Started process (PID=1025) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:38:48,497] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:38:48,498] {logging_mixin.py:112} INFO - [2020-06-02 15:38:48,498] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:38:48,506] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:38:48,658] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.167 seconds
[2020-06-02 15:39:38,515] {scheduler_job.py:153} INFO - Started process (PID=1050) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:39:38,521] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:39:38,522] {logging_mixin.py:112} INFO - [2020-06-02 15:39:38,522] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:39:38,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:39:38,694] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:40:28,540] {scheduler_job.py:153} INFO - Started process (PID=1075) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:40:28,546] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:40:28,546] {logging_mixin.py:112} INFO - [2020-06-02 15:40:28,546] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:40:28,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:40:28,714] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.174 seconds
[2020-06-02 15:41:18,566] {scheduler_job.py:153} INFO - Started process (PID=1100) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:41:18,572] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:41:18,572] {logging_mixin.py:112} INFO - [2020-06-02 15:41:18,572] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:41:18,581] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:41:18,701] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.134 seconds
[2020-06-02 15:43:18,354] {scheduler_job.py:153} INFO - Started process (PID=1175) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:43:18,359] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:43:18,360] {logging_mixin.py:112} INFO - [2020-06-02 15:43:18,360] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:43:18,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:43:18,621] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.267 seconds
[2020-06-02 15:44:08,391] {scheduler_job.py:153} INFO - Started process (PID=1200) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:44:08,396] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:44:08,397] {logging_mixin.py:112} INFO - [2020-06-02 15:44:08,397] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:44:08,405] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:44:08,651] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.260 seconds
[2020-06-02 15:45:10,168] {scheduler_job.py:153} INFO - Started process (PID=1231) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:45:10,173] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:45:10,174] {logging_mixin.py:112} INFO - [2020-06-02 15:45:10,174] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:45:10,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:45:10,418] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.250 seconds
[2020-06-02 15:46:17,517] {scheduler_job.py:153} INFO - Started process (PID=1262) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:46:17,522] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:46:17,522] {logging_mixin.py:112} INFO - [2020-06-02 15:46:17,522] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:46:17,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:46:17,762] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.246 seconds
[2020-06-02 15:47:19,379] {scheduler_job.py:153} INFO - Started process (PID=1293) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:47:19,384] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:47:19,385] {logging_mixin.py:112} INFO - [2020-06-02 15:47:19,385] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:47:19,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:47:19,674] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.296 seconds
[2020-06-02 15:48:09,416] {scheduler_job.py:153} INFO - Started process (PID=1318) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:09,422] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:48:09,422] {logging_mixin.py:112} INFO - [2020-06-02 15:48:09,422] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:09,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:09,731] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.314 seconds
[2020-06-02 15:48:59,428] {scheduler_job.py:153} INFO - Started process (PID=1343) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:59,433] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:48:59,434] {logging_mixin.py:112} INFO - [2020-06-02 15:48:59,434] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:59,443] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:48:59,597] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.170 seconds
[2020-06-02 15:49:49,451] {scheduler_job.py:153} INFO - Started process (PID=1368) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:49:49,457] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:49:49,457] {logging_mixin.py:112} INFO - [2020-06-02 15:49:49,457] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:49:49,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:49:49,622] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:50:39,502] {scheduler_job.py:153} INFO - Started process (PID=1393) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:50:39,507] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:50:39,508] {logging_mixin.py:112} INFO - [2020-06-02 15:50:39,508] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:50:39,516] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:50:39,630] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.128 seconds
[2020-06-02 15:51:29,525] {scheduler_job.py:153} INFO - Started process (PID=1418) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:51:29,532] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:51:29,532] {logging_mixin.py:112} INFO - [2020-06-02 15:51:29,532] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:51:29,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:51:29,673] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.148 seconds
[2020-06-02 15:52:19,547] {scheduler_job.py:153} INFO - Started process (PID=1443) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:52:19,552] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:52:19,553] {logging_mixin.py:112} INFO - [2020-06-02 15:52:19,553] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:52:19,562] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:52:19,755] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:53:09,583] {scheduler_job.py:153} INFO - Started process (PID=1468) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:09,588] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:53:09,589] {logging_mixin.py:112} INFO - [2020-06-02 15:53:09,589] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:09,597] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:09,706] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.123 seconds
[2020-06-02 15:53:59,595] {scheduler_job.py:153} INFO - Started process (PID=1493) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:59,602] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:53:59,603] {logging_mixin.py:112} INFO - [2020-06-02 15:53:59,603] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:59,612] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:53:59,730] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.134 seconds
[2020-06-02 15:54:49,620] {scheduler_job.py:153} INFO - Started process (PID=1518) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:54:49,625] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:54:49,626] {logging_mixin.py:112} INFO - [2020-06-02 15:54:49,626] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:54:49,635] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:54:49,975] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:55:39,644] {scheduler_job.py:153} INFO - Started process (PID=1543) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:55:39,649] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:55:39,650] {logging_mixin.py:112} INFO - [2020-06-02 15:55:39,650] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:55:39,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:55:39,827] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.183 seconds
[2020-06-02 15:56:29,668] {scheduler_job.py:153} INFO - Started process (PID=1568) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:56:29,675] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:56:29,675] {logging_mixin.py:112} INFO - [2020-06-02 15:56:29,675] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:56:29,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:56:29,849] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.181 seconds
[2020-06-02 15:57:19,690] {scheduler_job.py:153} INFO - Started process (PID=1593) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:57:19,695] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:57:19,696] {logging_mixin.py:112} INFO - [2020-06-02 15:57:19,696] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:57:19,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:57:19,885] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 15:58:09,727] {scheduler_job.py:153} INFO - Started process (PID=1618) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:09,732] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:58:09,732] {logging_mixin.py:112} INFO - [2020-06-02 15:58:09,732] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:09,741] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:09,848] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.121 seconds
[2020-06-02 15:58:59,739] {scheduler_job.py:153} INFO - Started process (PID=1643) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:59,745] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:58:59,746] {logging_mixin.py:112} INFO - [2020-06-02 15:58:59,745] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:59,756] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:58:59,929] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.191 seconds
[2020-06-02 15:59:49,760] {scheduler_job.py:153} INFO - Started process (PID=1668) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:59:49,765] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 15:59:49,766] {logging_mixin.py:112} INFO - [2020-06-02 15:59:49,766] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:59:49,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 15:59:49,974] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:00:39,888] {scheduler_job.py:153} INFO - Started process (PID=1693) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:00:39,893] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:00:39,894] {logging_mixin.py:112} INFO - [2020-06-02 16:00:39,894] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:00:39,903] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:00:40,058] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.171 seconds
[2020-06-02 16:01:29,911] {scheduler_job.py:153} INFO - Started process (PID=1718) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:01:29,917] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:01:29,918] {logging_mixin.py:112} INFO - [2020-06-02 16:01:29,917] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:01:29,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:01:30,024] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.114 seconds
[2020-06-02 16:02:19,948] {scheduler_job.py:153} INFO - Started process (PID=1743) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:02:19,955] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:02:19,955] {logging_mixin.py:112} INFO - [2020-06-02 16:02:19,955] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:02:19,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:02:20,139] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:03:09,960] {scheduler_job.py:153} INFO - Started process (PID=1768) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:03:09,966] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:03:09,966] {logging_mixin.py:112} INFO - [2020-06-02 16:03:09,966] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:03:09,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:03:10,090] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.130 seconds
[2020-06-02 16:03:59,982] {scheduler_job.py:153} INFO - Started process (PID=1793) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:03:59,988] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:03:59,988] {logging_mixin.py:112} INFO - [2020-06-02 16:03:59,988] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:03:59,996] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:04:00,113] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.131 seconds
[2020-06-02 16:04:50,006] {scheduler_job.py:153} INFO - Started process (PID=1818) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:04:50,012] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:04:50,012] {logging_mixin.py:112} INFO - [2020-06-02 16:04:50,012] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:04:50,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:04:50,182] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:05:40,032] {scheduler_job.py:153} INFO - Started process (PID=1843) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:05:40,037] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:05:40,038] {logging_mixin.py:112} INFO - [2020-06-02 16:05:40,038] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:05:40,047] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:05:40,179] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.147 seconds
[2020-06-02 16:06:30,058] {scheduler_job.py:153} INFO - Started process (PID=1868) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:06:30,063] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:06:30,064] {logging_mixin.py:112} INFO - [2020-06-02 16:06:30,064] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:06:30,073] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:06:30,222] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.164 seconds
[2020-06-02 16:07:20,097] {scheduler_job.py:153} INFO - Started process (PID=1893) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:07:20,102] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:07:20,103] {logging_mixin.py:112} INFO - [2020-06-02 16:07:20,103] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:07:20,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:07:20,248] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:08:10,109] {scheduler_job.py:153} INFO - Started process (PID=1918) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:08:10,115] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:08:10,116] {logging_mixin.py:112} INFO - [2020-06-02 16:08:10,116] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:08:10,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:08:10,243] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.135 seconds
[2020-06-02 16:09:00,139] {scheduler_job.py:153} INFO - Started process (PID=1943) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:00,144] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:09:00,145] {logging_mixin.py:112} INFO - [2020-06-02 16:09:00,145] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:00,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:00,277] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.138 seconds
[2020-06-02 16:09:50,177] {scheduler_job.py:153} INFO - Started process (PID=1968) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:50,188] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:09:50,190] {logging_mixin.py:112} INFO - [2020-06-02 16:09:50,190] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:50,200] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:09:50,373] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:10:40,220] {scheduler_job.py:153} INFO - Started process (PID=1993) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:10:40,229] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:10:40,230] {logging_mixin.py:112} INFO - [2020-06-02 16:10:40,230] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:10:40,243] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:10:40,429] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.209 seconds
[2020-06-02 16:11:30,254] {scheduler_job.py:153} INFO - Started process (PID=2018) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:11:30,259] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:11:30,260] {logging_mixin.py:112} INFO - [2020-06-02 16:11:30,260] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:11:30,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:11:30,399] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.145 seconds
[2020-06-02 16:12:20,281] {scheduler_job.py:153} INFO - Started process (PID=2043) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:12:20,287] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:12:20,287] {logging_mixin.py:112} INFO - [2020-06-02 16:12:20,287] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:12:20,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:12:20,478] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:13:10,323] {scheduler_job.py:153} INFO - Started process (PID=2068) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:13:10,332] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:13:10,333] {logging_mixin.py:112} INFO - [2020-06-02 16:13:10,333] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:13:10,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:13:10,476] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.154 seconds
[2020-06-02 16:14:00,341] {scheduler_job.py:153} INFO - Started process (PID=2093) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:00,347] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:14:00,347] {logging_mixin.py:112} INFO - [2020-06-02 16:14:00,347] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:00,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:00,486] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.145 seconds
[2020-06-02 16:14:50,368] {scheduler_job.py:153} INFO - Started process (PID=2118) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:50,373] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:14:50,374] {logging_mixin.py:112} INFO - [2020-06-02 16:14:50,374] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:50,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:14:50,566] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:15:40,412] {scheduler_job.py:153} INFO - Started process (PID=2143) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:15:40,417] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:15:40,418] {logging_mixin.py:112} INFO - [2020-06-02 16:15:40,418] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:15:40,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:15:40,542] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.130 seconds
[2020-06-02 16:16:30,426] {scheduler_job.py:153} INFO - Started process (PID=2168) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:16:30,432] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:16:30,433] {logging_mixin.py:112} INFO - [2020-06-02 16:16:30,433] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:16:30,443] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:16:30,596] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.170 seconds
[2020-06-02 16:17:20,453] {scheduler_job.py:153} INFO - Started process (PID=2193) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:17:20,459] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:17:20,459] {logging_mixin.py:112} INFO - [2020-06-02 16:17:20,459] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:17:20,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:17:20,654] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:18:10,482] {scheduler_job.py:153} INFO - Started process (PID=2218) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:18:10,487] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:18:10,488] {logging_mixin.py:112} INFO - [2020-06-02 16:18:10,488] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:18:10,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:18:10,651] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.169 seconds
[2020-06-02 16:19:00,510] {scheduler_job.py:153} INFO - Started process (PID=2243) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:00,517] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:19:00,518] {logging_mixin.py:112} INFO - [2020-06-02 16:19:00,518] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:00,526] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:00,709] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.199 seconds
[2020-06-02 16:19:50,538] {scheduler_job.py:153} INFO - Started process (PID=2268) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:50,543] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:19:50,544] {logging_mixin.py:112} INFO - [2020-06-02 16:19:50,544] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:50,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:19:50,741] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:20:40,579] {scheduler_job.py:153} INFO - Started process (PID=2293) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:20:40,585] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:20:40,585] {logging_mixin.py:112} INFO - [2020-06-02 16:20:40,585] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:20:40,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:20:40,728] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.149 seconds
[2020-06-02 16:21:30,597] {scheduler_job.py:153} INFO - Started process (PID=2318) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:21:30,603] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:21:30,604] {logging_mixin.py:112} INFO - [2020-06-02 16:21:30,604] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:21:30,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:21:30,727] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.130 seconds
[2020-06-02 16:22:20,623] {scheduler_job.py:153} INFO - Started process (PID=2343) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:22:20,629] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:22:20,630] {logging_mixin.py:112} INFO - [2020-06-02 16:22:20,630] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:22:20,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:22:20,807] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:23:10,652] {scheduler_job.py:153} INFO - Started process (PID=2368) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:23:10,658] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:23:10,659] {logging_mixin.py:112} INFO - [2020-06-02 16:23:10,659] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:23:10,668] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:23:10,783] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.130 seconds
[2020-06-02 16:24:00,678] {scheduler_job.py:153} INFO - Started process (PID=2393) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:00,684] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:24:00,684] {logging_mixin.py:112} INFO - [2020-06-02 16:24:00,684] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:00,694] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:00,810] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.132 seconds
[2020-06-02 16:24:50,705] {scheduler_job.py:153} INFO - Started process (PID=2418) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:50,713] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:24:50,713] {logging_mixin.py:112} INFO - [2020-06-02 16:24:50,713] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:50,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:24:50,884] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:25:40,747] {scheduler_job.py:153} INFO - Started process (PID=2443) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:25:40,752] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:25:40,753] {logging_mixin.py:112} INFO - [2020-06-02 16:25:40,753] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:25:40,762] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:25:40,881] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.134 seconds
[2020-06-02 16:26:30,762] {scheduler_job.py:153} INFO - Started process (PID=2468) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:26:30,768] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:26:30,768] {logging_mixin.py:112} INFO - [2020-06-02 16:26:30,768] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:26:30,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:26:30,917] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.155 seconds
[2020-06-02 16:27:20,788] {scheduler_job.py:153} INFO - Started process (PID=2493) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:27:20,793] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:27:20,794] {logging_mixin.py:112} INFO - [2020-06-02 16:27:20,794] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:27:20,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:27:20,958] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.170 seconds
[2020-06-02 16:28:10,821] {scheduler_job.py:153} INFO - Started process (PID=2518) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:28:10,827] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:28:10,827] {logging_mixin.py:112} INFO - [2020-06-02 16:28:10,827] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:28:10,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:28:10,982] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.161 seconds
[2020-06-02 16:29:00,846] {scheduler_job.py:153} INFO - Started process (PID=2543) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:00,852] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:29:00,853] {logging_mixin.py:112} INFO - [2020-06-02 16:29:00,852] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:00,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:00,971] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.125 seconds
[2020-06-02 16:29:50,874] {scheduler_job.py:153} INFO - Started process (PID=2568) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:50,881] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:29:50,882] {logging_mixin.py:112} INFO - [2020-06-02 16:29:50,882] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:50,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:29:51,149] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:30:40,918] {scheduler_job.py:153} INFO - Started process (PID=2593) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:30:40,923] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:30:40,924] {logging_mixin.py:112} INFO - [2020-06-02 16:30:40,924] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:30:40,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:30:41,060] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.142 seconds
[2020-06-02 16:31:30,931] {scheduler_job.py:153} INFO - Started process (PID=2618) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:31:30,937] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:31:30,937] {logging_mixin.py:112} INFO - [2020-06-02 16:31:30,937] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:31:30,946] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:31:31,070] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.139 seconds
[2020-06-02 16:32:20,960] {scheduler_job.py:153} INFO - Started process (PID=2643) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:32:20,966] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:32:20,966] {logging_mixin.py:112} INFO - [2020-06-02 16:32:20,966] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:32:20,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:32:21,126] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:33:10,985] {scheduler_job.py:153} INFO - Started process (PID=2668) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:33:10,991] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:33:10,991] {logging_mixin.py:112} INFO - [2020-06-02 16:33:10,991] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:33:11,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:33:11,124] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.139 seconds
[2020-06-02 16:34:01,019] {scheduler_job.py:153} INFO - Started process (PID=2693) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:01,025] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:34:01,026] {logging_mixin.py:112} INFO - [2020-06-02 16:34:01,026] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:01,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:01,157] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.138 seconds
[2020-06-02 16:34:51,045] {scheduler_job.py:153} INFO - Started process (PID=2718) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:51,051] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:34:51,052] {logging_mixin.py:112} INFO - [2020-06-02 16:34:51,052] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:51,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:34:51,201] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.155 seconds
[2020-06-02 16:35:41,092] {scheduler_job.py:153} INFO - Started process (PID=2743) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:35:41,099] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:35:41,099] {logging_mixin.py:112} INFO - [2020-06-02 16:35:41,099] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:35:41,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:35:41,272] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.180 seconds
[2020-06-02 16:36:31,109] {scheduler_job.py:153} INFO - Started process (PID=2768) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:36:31,115] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:36:31,116] {logging_mixin.py:112} INFO - [2020-06-02 16:36:31,115] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:36:31,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:36:31,246] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.137 seconds
[2020-06-02 16:37:21,139] {scheduler_job.py:153} INFO - Started process (PID=2793) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:37:21,145] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:37:21,146] {logging_mixin.py:112} INFO - [2020-06-02 16:37:21,146] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:37:21,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:37:21,302] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:38:11,167] {scheduler_job.py:153} INFO - Started process (PID=2818) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:38:11,173] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:38:11,174] {logging_mixin.py:112} INFO - [2020-06-02 16:38:11,173] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:38:11,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:38:11,312] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.145 seconds
[2020-06-02 16:39:01,191] {scheduler_job.py:153} INFO - Started process (PID=2843) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:01,197] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:39:01,198] {logging_mixin.py:112} INFO - [2020-06-02 16:39:01,197] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:01,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:01,344] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.153 seconds
[2020-06-02 16:39:51,217] {scheduler_job.py:153} INFO - Started process (PID=2868) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:51,223] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:39:51,223] {logging_mixin.py:112} INFO - [2020-06-02 16:39:51,223] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:51,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:39:51,401] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-02 16:40:41,258] {scheduler_job.py:153} INFO - Started process (PID=2893) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:40:41,263] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:40:41,264] {logging_mixin.py:112} INFO - [2020-06-02 16:40:41,263] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:40:41,273] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:40:41,388] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.131 seconds
[2020-06-02 16:41:31,273] {scheduler_job.py:153} INFO - Started process (PID=2918) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:41:31,280] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:41:31,281] {logging_mixin.py:112} INFO - [2020-06-02 16:41:31,281] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:41:31,289] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:41:31,431] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.158 seconds
[2020-06-02 16:44:55,830] {scheduler_job.py:153} INFO - Started process (PID=2947) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:44:55,836] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:44:55,837] {logging_mixin.py:112} INFO - [2020-06-02 16:44:55,837] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:44:55,845] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:44:55,983] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.153 seconds
[2020-06-02 16:45:45,859] {scheduler_job.py:153} INFO - Started process (PID=2972) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:45:45,865] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-02 16:45:45,865] {logging_mixin.py:112} INFO - [2020-06-02 16:45:45,865] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:45:45,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-02 16:45:45,996] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.138 seconds
[2020-06-03 14:51:48,240] {scheduler_job.py:153} INFO - Started process (PID=157) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:51:48,256] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:51:48,257] {logging_mixin.py:112} INFO - [2020-06-03 14:51:48,257] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:51:48,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:51:48,595] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.355 seconds
[2020-06-03 14:52:38,280] {scheduler_job.py:153} INFO - Started process (PID=184) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:52:38,285] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:52:38,286] {logging_mixin.py:112} INFO - [2020-06-03 14:52:38,285] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:52:38,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:52:38,625] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.345 seconds
[2020-06-03 14:53:22,824] {scheduler_job.py:153} INFO - Started process (PID=211) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:53:22,833] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:53:22,834] {logging_mixin.py:112} INFO - [2020-06-03 14:53:22,834] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:53:22,850] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:53:23,320] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.496 seconds
[2020-06-03 14:54:37,600] {scheduler_job.py:153} INFO - Started process (PID=251) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:54:37,605] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:54:37,605] {logging_mixin.py:112} INFO - [2020-06-03 14:54:37,605] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:54:37,615] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:54:37,877] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.278 seconds
[2020-06-03 14:56:02,138] {scheduler_job.py:153} INFO - Started process (PID=290) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:56:02,143] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:56:02,144] {logging_mixin.py:112} INFO - [2020-06-03 14:56:02,144] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:56:02,152] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:56:02,577] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.439 seconds
[2020-06-03 14:57:21,926] {scheduler_job.py:153} INFO - Started process (PID=330) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:57:21,931] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:57:21,931] {logging_mixin.py:112} INFO - [2020-06-03 14:57:21,931] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:57:22,087] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:57:22,191] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.265 seconds
[2020-06-03 14:58:13,541] {scheduler_job.py:153} INFO - Started process (PID=356) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:58:13,553] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:58:13,553] {logging_mixin.py:112} INFO - [2020-06-03 14:58:13,553] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:58:13,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:58:13,956] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.416 seconds
[2020-06-03 14:59:02,825] {scheduler_job.py:153} INFO - Started process (PID=383) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:02,831] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:59:02,831] {logging_mixin.py:112} INFO - [2020-06-03 14:59:02,831] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:02,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:02,971] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.145 seconds
[2020-06-03 14:59:54,532] {scheduler_job.py:153} INFO - Started process (PID=409) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:54,537] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 14:59:54,538] {logging_mixin.py:112} INFO - [2020-06-03 14:59:54,538] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:54,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 14:59:55,028] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:00:44,910] {scheduler_job.py:153} INFO - Started process (PID=436) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:00:44,940] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:00:44,941] {logging_mixin.py:112} INFO - [2020-06-03 15:00:44,941] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:00:44,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:00:45,320] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.410 seconds
[2020-06-03 15:01:35,116] {scheduler_job.py:153} INFO - Started process (PID=462) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:01:35,126] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:01:35,128] {logging_mixin.py:112} INFO - [2020-06-03 15:01:35,127] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:01:35,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:01:35,831] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.715 seconds
[2020-06-03 15:02:26,194] {scheduler_job.py:153} INFO - Started process (PID=488) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:02:26,219] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:02:26,220] {logging_mixin.py:112} INFO - [2020-06-03 15:02:26,220] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:02:26,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:02:26,824] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:03:16,966] {scheduler_job.py:153} INFO - Started process (PID=515) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:03:16,972] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:03:16,973] {logging_mixin.py:112} INFO - [2020-06-03 15:03:16,972] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:03:16,983] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:03:17,314] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.348 seconds
[2020-06-03 15:04:06,965] {scheduler_job.py:153} INFO - Started process (PID=541) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:06,970] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:04:06,971] {logging_mixin.py:112} INFO - [2020-06-03 15:04:06,971] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:06,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:07,106] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.141 seconds
[2020-06-03 15:04:57,098] {scheduler_job.py:153} INFO - Started process (PID=568) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:57,107] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:04:57,117] {logging_mixin.py:112} INFO - [2020-06-03 15:04:57,116] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:57,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:04:57,401] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.303 seconds
[2020-06-03 15:05:47,149] {scheduler_job.py:153} INFO - Started process (PID=594) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:05:47,154] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:05:47,155] {logging_mixin.py:112} INFO - [2020-06-03 15:05:47,155] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:05:47,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:05:47,360] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.212 seconds
[2020-06-03 15:06:37,276] {scheduler_job.py:153} INFO - Started process (PID=621) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:06:37,281] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:06:37,282] {logging_mixin.py:112} INFO - [2020-06-03 15:06:37,282] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:06:37,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:06:37,445] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.170 seconds
[2020-06-03 15:07:27,367] {scheduler_job.py:153} INFO - Started process (PID=648) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:07:27,372] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:07:27,373] {logging_mixin.py:112} INFO - [2020-06-03 15:07:27,373] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:07:27,385] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:07:27,701] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:08:17,482] {scheduler_job.py:153} INFO - Started process (PID=674) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:08:17,488] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:08:17,488] {logging_mixin.py:112} INFO - [2020-06-03 15:08:17,488] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:08:17,499] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:08:17,679] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.197 seconds
[2020-06-03 15:09:07,558] {scheduler_job.py:153} INFO - Started process (PID=701) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:09:07,569] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:09:07,570] {logging_mixin.py:112} INFO - [2020-06-03 15:09:07,570] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:09:07,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:09:07,785] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.227 seconds
[2020-06-03 15:10:45,868] {scheduler_job.py:153} INFO - Started process (PID=744) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:10:45,873] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:10:45,874] {logging_mixin.py:112} INFO - [2020-06-03 15:10:45,874] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:10:45,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:10:46,175] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.307 seconds
[2020-06-03 15:11:35,940] {scheduler_job.py:153} INFO - Started process (PID=770) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:11:35,946] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:11:35,946] {logging_mixin.py:112} INFO - [2020-06-03 15:11:35,946] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:11:35,955] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:11:36,249] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.309 seconds
[2020-06-03 15:12:25,999] {scheduler_job.py:153} INFO - Started process (PID=797) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:12:26,004] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:12:26,005] {logging_mixin.py:112} INFO - [2020-06-03 15:12:26,005] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:12:26,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:12:26,250] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.251 seconds
[2020-06-03 15:13:41,663] {scheduler_job.py:153} INFO - Started process (PID=836) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:13:41,668] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:13:41,669] {logging_mixin.py:112} INFO - [2020-06-03 15:13:41,669] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:13:41,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:13:42,022] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:15:06,542] {scheduler_job.py:153} INFO - Started process (PID=876) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:06,547] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:15:06,547] {logging_mixin.py:112} INFO - [2020-06-03 15:15:06,547] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:06,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:06,819] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.278 seconds
[2020-06-03 15:15:56,573] {scheduler_job.py:153} INFO - Started process (PID=903) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:56,579] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:15:56,579] {logging_mixin.py:112} INFO - [2020-06-03 15:15:56,579] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:56,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:15:56,727] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.154 seconds
[2020-06-03 15:17:20,126] {scheduler_job.py:153} INFO - Started process (PID=942) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:17:20,131] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:17:20,132] {logging_mixin.py:112} INFO - [2020-06-03 15:17:20,132] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:17:20,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:17:20,343] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:18:10,154] {scheduler_job.py:153} INFO - Started process (PID=969) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:18:10,160] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:18:10,161] {logging_mixin.py:112} INFO - [2020-06-03 15:18:10,161] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:18:10,169] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:18:10,283] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.129 seconds
[2020-06-03 15:19:00,187] {scheduler_job.py:153} INFO - Started process (PID=996) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:00,193] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:19:00,194] {logging_mixin.py:112} INFO - [2020-06-03 15:19:00,194] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:00,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:00,362] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.176 seconds
[2020-06-03 15:19:50,215] {scheduler_job.py:153} INFO - Started process (PID=1022) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:50,220] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:19:50,220] {logging_mixin.py:112} INFO - [2020-06-03 15:19:50,220] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:50,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:19:50,398] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:20:40,232] {scheduler_job.py:153} INFO - Started process (PID=1049) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:20:40,240] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:20:40,240] {logging_mixin.py:112} INFO - [2020-06-03 15:20:40,240] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:20:40,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:20:40,394] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.161 seconds
[2020-06-03 15:21:20,411] {scheduler_job.py:153} INFO - Started process (PID=1074) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:21:20,423] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:21:20,424] {logging_mixin.py:112} INFO - [2020-06-03 15:21:20,424] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:21:20,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:21:20,727] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.316 seconds
[2020-06-03 15:22:10,507] {scheduler_job.py:153} INFO - Started process (PID=1101) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:22:10,512] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:22:10,513] {logging_mixin.py:112} INFO - [2020-06-03 15:22:10,513] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:22:10,522] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:22:10,836] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.329 seconds
[2020-06-03 15:23:00,570] {scheduler_job.py:153} INFO - Started process (PID=1127) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:23:00,576] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:23:00,576] {logging_mixin.py:112} INFO - [2020-06-03 15:23:00,576] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:23:00,585] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:23:00,881] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.311 seconds
[2020-06-03 15:24:02,549] {scheduler_job.py:153} INFO - Started process (PID=1160) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:24:02,554] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:24:02,555] {logging_mixin.py:112} INFO - [2020-06-03 15:24:02,554] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:24:02,711] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:24:02,805] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.257 seconds
[2020-06-03 15:25:09,975] {scheduler_job.py:153} INFO - Started process (PID=1193) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:25:09,981] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:25:09,982] {logging_mixin.py:112} INFO - [2020-06-03 15:25:09,982] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:25:10,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:25:10,247] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.273 seconds
[2020-06-03 15:26:12,143] {scheduler_job.py:153} INFO - Started process (PID=1226) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:26:12,148] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:26:12,149] {logging_mixin.py:112} INFO - [2020-06-03 15:26:12,149] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:26:12,310] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:26:12,425] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.283 seconds
[2020-06-03 15:27:02,239] {scheduler_job.py:153} INFO - Started process (PID=1253) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:02,244] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:27:02,245] {logging_mixin.py:112} INFO - [2020-06-03 15:27:02,245] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:02,255] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:02,393] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.155 seconds
[2020-06-03 15:27:52,283] {scheduler_job.py:153} INFO - Started process (PID=1279) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:52,295] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:27:52,296] {logging_mixin.py:112} INFO - [2020-06-03 15:27:52,296] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:52,312] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:27:52,573] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.290 seconds
[2020-06-03 15:28:42,314] {scheduler_job.py:153} INFO - Started process (PID=1306) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:28:42,320] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:28:42,321] {logging_mixin.py:112} INFO - [2020-06-03 15:28:42,321] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:28:42,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:28:42,505] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/dag.py", line 1521, in sync_to_db
    session.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py", line 508, in commit
    t[1].commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1771, in commit
    self._do_commit()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1802, in _do_commit
    self.connection._commit_impl()
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 776, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 1517, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py", line 178, in raise_
    raise exception
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py", line 774, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py", line 543, in do_commit
    dbapi_connection.commit()
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
(Background on this error at: http://sqlalche.me/e/e3q8)
[2020-06-03 15:29:32,366] {scheduler_job.py:153} INFO - Started process (PID=1332) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:29:32,371] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:29:32,372] {logging_mixin.py:112} INFO - [2020-06-03 15:29:32,371] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:29:32,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:29:32,512] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.147 seconds
[2020-06-03 15:30:22,429] {scheduler_job.py:153} INFO - Started process (PID=1359) to work on /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:30:22,434] {scheduler_job.py:1562} INFO - Processing file /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py for tasks to queue
[2020-06-03 15:30:22,435] {logging_mixin.py:112} INFO - [2020-06-03 15:30:22,435] {dagbag.py:396} INFO - Filling up the DagBag from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:30:22,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['tutorial']) retrieved from /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py
[2020-06-03 15:30:22,601] {scheduler_job.py:161} INFO - Processing /usr/local/lib/python3.8/dist-packages/airflow/example_dags/tutorial.py took 0.172 seconds
